# üîß Bestand: generate_definitie.py
# üìç in de root van je project

import os
from typing import Dict, List

from openai import OpenAI, OpenAIError

from web_lookup import zoek_definitie_combinatie              # ‚úÖ extern web‚Äêlookup
from config.config_loader import laad_toetsregels                   # ‚úÖ laad toetsregels
from prompt_builder import (
    PromptBouwer,
    PromptConfiguratie,
    stuur_prompt_naar_gpt,
)
# ‚úÖ Init OpenAI-client (√©√©n keer)
_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


def genereer_definitie(
    begrip: str,
    context_dict: Dict[str, List[str]],
    model: str = "gpt-4",
    temperature: float = 0.01,   # ‚úÖ Verlaagd naar 0.01 voor maximale consistentie en contextfocus
    max_tokens: int = 350
) -> str:
    """
    Genereert via GPT-4 een *ongecorrigeerde* definitie voor het opgegeven begrip:
      ‚Ä¢ haalt achtergrondinformatie op
      ‚Ä¢ laadt en splitst toetsregels
      ‚Ä¢ bouwt de prompt
      ‚Ä¢ voert GPT-aanroep uit (with intelligent caching)

    Retourneert:
        definitie_origineel (str): exact wat GPT-4 teruggeeft
    """
    from utils.cache import cache_definition_generation
    # Use caching for the entire definition generation process
    @cache_definition_generation(ttl=3600)  # Cache for 1 hour
    def _generate_cached_definition(begrip: str, context_dict: Dict[str, List[str]], model: str, temperature: float, max_tokens: int) -> str:
        # 1Ô∏è‚É£ Achtergrond ophalen
        web_uitleg = zoek_definitie_combinatie(begrip)

        # 2Ô∏è‚É£ Toetsregels laden & splitsen
        toetsregels = laad_toetsregels()

        # 3Ô∏è‚É£ Prompt bouwen
        configuratie = PromptConfiguratie(
            begrip=begrip,
            context_dict=context_dict,
            web_uitleg=web_uitleg,
            toetsregels=toetsregels
        )
        bouwer = PromptBouwer(configuratie)
        prompt = bouwer.bouw_prompt()

        # 4Ô∏è‚É£ GPT-aanroep
        try:
            definitie_origineel = stuur_prompt_naar_gpt(
                prompt,
                model=model,
                temperatuur=temperature,  # ‚úÖ let op: 'temperatuur' met 'uur'
                max_tokens=max_tokens
            )
        except OpenAIError as e:
            raise RuntimeError(f"Fout bij definitiegeneratie: {e}") from e

        # 5Ô∏è‚É£ Return alleen ongecorrigeerde definitie
        return definitie_origineel
    
    return _generate_cached_definition(begrip, context_dict, model, temperature, max_tokens)

# ‚úÖ Default temperatuur nu 0.01: minimaliseert willekeur, maximaliseert contextuele precisie.
