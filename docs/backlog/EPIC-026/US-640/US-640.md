---
id: US-640
epic: EPIC-026
titel: "US-640: titel: Set up Test Infrastructure (Phase 0)"
owner: test-engineer
prioriteit: P0
status: pending
estimate: 1 week
sprint: Phase 0 Week 1
created: 2025-10-03
---

# US-640: Set up Test Infrastructure (Phase 0)

**Epic:** EPIC-026 - God Object Refactoring
**Owner:** Test Engineer
**Priority:** P0 (CRITICAL - blocks all refactoring)
**Estimate:** 1 week (5 days)
**Sprint:** Phase 0 Week 1

---

## User Story

**As a** test engineer
**I want to** set up comprehensive test infrastructure for Streamlit
**So that** we can safely refactor 4,318 LOC of god objects with 0% current coverage

---

## Context

**Current State:**
- tabbed_interface.py: 1,793 LOC, **0 tests** (Regression Risk: 3,156 â˜¢ï¸)
- definition_generator_tab.py: 2,525 LOC, **1 test** (Regression Risk: 2,847 ðŸ”´)
- No Streamlit test harness exists
- Cannot safely refactor without tests

**Goal:** Build test infrastructure that enables 436 tests to be created in Phase 0

---

## Acceptance Criteria

### AC1: Streamlit Test Harness Operational
- [ ] pytest-playwright installed and configured
- [ ] Streamlit app can be launched in test mode
- [ ] Basic navigation tests working (5 test scenarios)
- [ ] Session state mocking functional
- [ ] Test runs in CI/CD pipeline

### AC2: Golden Master Framework
- [ ] Golden master testing library integrated
- [ ] Can record current behavior (baseline capture)
- [ ] Can compare post-refactor vs baseline
- [ ] Diff reporting for failures

### AC3: Async Test Patterns
- [ ] async/await test patterns working
- [ ] Can test asyncio.run() bridge (57 files use it)
- [ ] Event loop mocking functional
- [ ] No flaky async tests

### AC4: Mock Infrastructure
- [ ] AIServiceV2 mocking (GPT-4 calls)
- [ ] Database mocking (SQLite)
- [ ] External service mocking (Wikipedia, SRU)
- [ ] Mock fixtures reusable

### AC5: Documentation
- [ ] Test infrastructure guide created (`docs/testing/EPIC-026-test-infrastructure.md`)
- [ ] Example tests for each pattern
- [ ] Troubleshooting guide for common issues

---

## Technical Requirements

### Libraries to Install

```bash
pip install pytest-playwright pytest-asyncio pytest-mock pytest-golden
playwright install chromium
```

### Test Structure

```
tests/epic-026/
â”œâ”€â”€ conftest.py                    # Shared fixtures
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ test_streamlit_harness.py  # Basic harness tests
â”‚   â”œâ”€â”€ test_golden_master.py      # Golden master validation
â”‚   â””â”€â”€ test_async_patterns.py     # Async test patterns
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_generation_flow.py    # 5 integration scenarios (PoC)
â””â”€â”€ fixtures/
    â”œâ”€â”€ mock_ai_service.py
    â”œâ”€â”€ mock_database.py
    â””â”€â”€ golden_baselines/           # Golden master data
```

---

## Dependencies

**Blocks:**
- US-454 (Create Generation Orchestrator Tests) - needs this infrastructure
- US-455 (Create Regeneration Orchestrator Tests) - needs this infrastructure
- US-456 (Create Coverage Gap Tests) - needs this infrastructure

**Depends On:**
- None (first task in Phase 0)

---

## Test Strategy

### Phase 1: Basic Harness (Day 1-2)

**Goal:** Launch Streamlit app in test mode, navigate tabs

```python
# tests/epic-026/infrastructure/test_streamlit_harness.py
def test_app_launches():
    """Streamlit app starts without errors"""
    page = launch_streamlit_app()
    assert page.title == "DefinitieAgent"

def test_navigate_to_generator_tab():
    """Can navigate to definition generator tab"""
    page = launch_streamlit_app()
    page.click("text=Definitie Genereren")
    assert page.is_visible("text=Begrip")
```

---

### Phase 2: Session State (Day 2-3)

**Goal:** Mock and manipulate st.session_state

```python
def test_session_state_mocking():
    """Can mock session state for testing"""
    with mock_session_state({"category": "Toezicht"}):
        result = some_function_using_session_state()
        assert result.category == "Toezicht"
```

**Challenge:** st.session_state is global singleton - need isolation

---

### Phase 3: Golden Master (Day 3-4)

**Goal:** Record current behavior, compare later

```python
def test_definition_generation_golden_master():
    """Definition generation matches golden baseline"""
    result = generate_definition("Toezicht", contexts={"org": ["IGJ"]})

    # First run: records baseline
    # Later runs: compares against baseline
    assert_golden_match(result, "test_generation_toezicht.json")
```

---

### Phase 4: Async Patterns (Day 4-5)

**Goal:** Test async workflows without race conditions

```python
@pytest.mark.asyncio
async def test_async_category_determination():
    """Async category determination works"""
    mock_ai = MockAIService(response="Toezicht")

    result = await determine_category("begrip", mock_ai)

    assert result.category == "Toezicht"
    assert result.confidence > 0.8
```

---

### Phase 5: Integration (Day 5)

**Goal:** 5 end-to-end scenarios as PoC

**Scenarios:**
1. Happy path: Generate definition (Toezicht, org=IGJ)
2. Duplicate found: Show user duplicate check dialog
3. Category change: Trigger regeneration
4. Document upload: Process PDF, extract context
5. Validation failure: Show validation errors

---

## Risks

### Risk 1: Streamlit is Hard to Test
**Likelihood:** HIGH
**Impact:** MEDIUM (slower test creation)
**Mitigation:** Use playwright (browser automation), not pytest-streamlit (too limited)

### Risk 2: Flaky Tests
**Likelihood:** HIGH (async + UI)
**Impact:** HIGH (blocks Phase 0 Gate 1: <5% flakiness required)
**Mitigation:**
- Explicit waits (not implicit sleeps)
- Retry logic for UI interactions
- Isolated test environment

### Risk 3: Golden Master Baseline Drift
**Likelihood:** MEDIUM
**Impact:** MEDIUM (false positives)
**Mitigation:** Version golden baselines, document when to update

---

## Success Metrics

- [ ] Infrastructure complete in 5 days (not 7)
- [ ] 5 integration tests passing (PoC)
- [ ] 0 flaky tests in infrastructure tests
- [ ] CI/CD integration successful
- [ ] Team trained on test patterns (1 hour session)

---

## Documentation Deliverable

**File:** `docs/testing/EPIC-026-test-infrastructure.md`

**Contents:**
1. Architecture overview (test harness + golden master)
2. How to write tests (examples for each pattern)
3. How to run tests (local + CI/CD)
4. Troubleshooting guide (common issues)
5. Golden master maintenance (when to update baselines)

---

## Rollback

**If this US fails:** Cannot proceed with Phase 0
**Abort trigger:** If >7 days without working harness â†’ Reassess Phase 0 feasibility

---

**Status:** Pending
**Next Action:** Assign test engineer, start Day 1 (pytest-playwright setup)
