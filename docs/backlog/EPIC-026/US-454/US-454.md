---
id: US-454
epic: EPIC-026
titel: "US-454: titel: Create Generation Orchestrator Tests (Phase 0)"
owner: test-engineer
prioriteit: P0
status: pending
estimate: 2 weeks
sprint: Phase 0 Week 2-3
created: 2025-10-03
blocked_by: US-640
---

# US-454: Create Generation Orchestrator Tests (Phase 0)

**Epic:** EPIC-026 - God Object Refactoring
**Owner:** Test Engineer
**Priority:** P0 (CRITICAL)
**Estimate:** 2 weeks (10 days)
**Sprint:** Phase 0 Week 2-3

---

## User Story

**As a** test engineer
**I want to** create 368 tests for generation orchestrator workflows
**So that** we can safely extract the 380 LOC god method without breaking core functionality

---

## Context

**The Target: 380 LOC God Method**

Location: `src/ui/tabbed_interface.py::_handle_definition_generation()` (lines 821-1201)

**Complexity:**
- 10-step workflow (context validation → category → duplicate → generation → state mutations)
- 5+ services coordinated (Definition, Regeneration, Document, Category, Checker)
- 15+ state mutations (`st.session_state`)
- 6 early exit paths
- 8 try/except blocks
- Async operations mixed with sync

**This is THE CORE of the application** - if this breaks, app is unusable.

---

## Test Coverage Breakdown

**Total: 368 tests**

### Category A: Generation Orchestrator (150 tests)
- 10-step workflow × 5 scenarios = **50 tests**
- State mutations (15 mutations × 3 states) = **45 tests**
- Error paths (8 exceptions × 3 scenarios) = **24 tests**
- Edge cases = **31 tests**

### Category B: Category Determination (100 tests)
- 6-step protocol tests = **30 tests**
- Quick analyzer fallback = **20 tests**
- Pattern matching (4 categories × 5 patterns) = **20 tests**
- Scoring algorithm = **15 tests**
- Reasoning generation = **15 tests**

### Category C: Document Context (118 tests)
- Document upload & processing = **40 tests**
- Snippet extraction (280 char window) = **30 tests**
- Context aggregation = **28 tests**
- Edge cases (empty docs, large docs) = **20 tests**

---

## Acceptance Criteria

### AC1: Generation Orchestrator Coverage (150 tests)

**10-Step Workflow Tests:**
- [ ] Step 1: Context validation (org/jur/wet minimum 1)
- [ ] Step 2: Category determination (async call)
- [ ] Step 3: Duplicate check (3 outcomes: none, found, multiple)
- [ ] Step 4: Document context retrieval
- [ ] Step 5: Snippet extraction (max 2 docs, 280 char window)
- [ ] Step 6: Regeneration context handling
- [ ] Step 7: Definition service call (async via run_async)
- [ ] Step 8: Result storage (15+ state mutations)
- [ ] Step 9: Edit tab preparation
- [ ] Step 10: Success notification

**Scenarios per step:**
- Happy path (all steps succeed)
- Context validation fails (missing org/jur/wet)
- Category determination times out
- Duplicate found (user chooses: cancel, continue, edit existing)
- Document processing fails

---

### AC2: Category Determination Coverage (100 tests)

**6-Step Protocol:**
- [ ] Full ontological analysis (primary method)
- [ ] Quick analyzer fallback (secondary)
- [ ] Legacy pattern matching (tertiary)
- [ ] Default category (all fallbacks fail)

**Pattern Tests (4 categories):**
- [ ] "Proces": suffixes (atie, eren, ing) + keywords (verificatie, etc.)
- [ ] "Type": keywords (bewijs, document, middel, etc.)
- [ ] "Resultaat": keywords (besluit, uitslag, rapport, etc.)
- [ ] "Exemplaar": keywords (specifiek, individueel, etc.)

**Scoring Algorithm:**
- [ ] Pattern count weighting (more patterns = higher score)
- [ ] Confidence thresholds (high: >0.8, medium: 0.5-0.8, low: <0.5)
- [ ] Tie-breaking logic (equal scores)

---

### AC3: Document Context Coverage (118 tests)

**Upload & Processing:**
- [ ] Single PDF upload
- [ ] Multiple PDF uploads (max 5)
- [ ] Large PDF (>10 pages)
- [ ] Corrupt PDF (error handling)
- [ ] Empty PDF
- [ ] Non-PDF file (reject)

**Snippet Extraction:**
- [ ] Begriff occurs 1x in document
- [ ] Begriff occurs 5x in document (take first 2)
- [ ] Begriff occurs 0x (no snippets)
- [ ] 280 character window (140 chars before + after begriff)
- [ ] Begriff at start of document (<140 chars before)
- [ ] Begriff at end of document (<140 chars after)

**Context Aggregation:**
- [ ] 1 document, 1 snippet
- [ ] 2 documents, 2 snippets each (4 total)
- [ ] 5 documents, 1 snippet each (5 total)
- [ ] Deduplicate identical snippets

---

### AC4: Integration Tests (30 scenarios)

**End-to-End Flows:**
1. Generate definition (Toezicht, org=IGJ) - success
2. Generate definition (duplicate found) - show dialog
3. Generate definition (category change) - trigger regeneration
4. Generate definition (with 2 PDFs) - context included
5. Generate definition (validation fails) - show errors
6-30: Additional scenarios covering edge cases

---

### AC5: Golden Master Baselines

- [ ] Export 42 existing definitions (pre-refactor)
- [ ] Create golden baseline for each definition
- [ ] Test: regenerate all 42, compare outputs
- [ ] Tolerance: 0% for business logic, <5% for LLM variance

---

## Test Implementation Guide

### Example Test: Happy Path

```python
@pytest.mark.asyncio
async def test_generation_orchestrator_happy_path():
    """Full generation workflow succeeds"""
    # Arrange
    mock_ai = MockAIService(
        category_response="Toezicht",
        definition_response="Een vorm van toezicht waarbij..."
    )
    mock_db = MockDatabase()
    mock_docs = MockDocumentProcessor()

    state = MockSessionState({
        "begrip": "Toezicht",
        "org_context": ["IGJ"],
        "jur_context": [],
        "wet_context": []
    })

    orchestrator = GenerationOrchestrator(
        ai_service=mock_ai,
        db=mock_db,
        doc_processor=mock_docs
    )

    # Act
    result = await orchestrator.generate(state)

    # Assert
    assert result.success is True
    assert result.category == "Toezicht"
    assert result.definition.startswith("Een vorm van")
    assert state.get("generated_definition") is not None
    assert state.get("editing_definition_id") is not None
    assert mock_ai.call_count == 2  # Category + Definition
```

---

### Example Test: Duplicate Found

```python
def test_generation_orchestrator_duplicate_found():
    """Duplicate check returns existing definition"""
    # Arrange
    mock_db = MockDatabase(
        duplicate_result=[
            {"id": 123, "definitie": "Existing definition", "begrip": "Toezicht"}
        ]
    )

    state = MockSessionState({"begrip": "Toezicht", "org_context": ["IGJ"]})
    orchestrator = GenerationOrchestrator(db=mock_db)

    # Act
    result = orchestrator.generate(state)

    # Assert
    assert result.duplicate_found is True
    assert result.duplicate_id == 123
    assert state.get("show_duplicate_dialog") is True
```

---

### Example Test: Category Determination

```python
@pytest.mark.asyncio
async def test_category_determination_pattern_matching():
    """Pattern matching correctly identifies 'Proces' category"""
    # Arrange
    mock_ai = MockAIService(timeout=True)  # Force fallback to patterns
    category_service = OntologicalCategoryService(ai_service=mock_ai)

    # Act
    result = await category_service.determine_category(
        begrip="Verificatie",
        definition="Een proces waarbij..."
    )

    # Assert
    assert result.category == "Proces"
    assert result.method == "pattern_matching"  # Not 6-step (timed out)
    assert "atie" in result.matched_patterns  # Suffix match
```

---

## Dependencies

**Depends On:**
- US-640 (Test Infrastructure) - MUST be complete first

**Blocks:**
- US-447 (Extract Generation Orchestrator) - cannot refactor without tests

---

## Risks

### Risk 1: 380 LOC God Method Too Complex to Test
**Likelihood:** MEDIUM
**Impact:** HIGH (cannot achieve 85% coverage)
**Mitigation:**
- Start with characterization tests (record current behavior)
- Break down into 10 steps, test each step independently
- Use golden master for complex workflows

### Risk 2: Async Tests Are Flaky
**Likelihood:** HIGH
**Impact:** HIGH (Gate 1 requires <5% flakiness)
**Mitigation:**
- Use pytest-asyncio properly (no nested event loops)
- Explicit waits, no time.sleep()
- Retry logic for network-dependent tests

### Risk 3: 368 Tests in 10 Days Is Aggressive
**Likelihood:** MEDIUM
**Impact:** MEDIUM (timeline slip)
**Mitigation:**
- Prioritize: 150 orchestrator tests (critical) → 100 category → 118 document
- Can defer document tests to Week 4 if needed
- Minimum viable: 250 tests (70% coverage)

---

## Success Metrics

- [ ] 368 tests created (100% target)
- [ ] 250+ tests minimum (70% target)
- [ ] 85%+ coverage for generation orchestrator
- [ ] <5% flaky tests
- [ ] 30 integration scenarios passing
- [ ] Golden baseline: 42 definitions exported

---

## Timeline

**Week 2 (5 days):**
- Day 6-7: 150 orchestrator tests (30 tests/day)
- Day 8-9: 100 category tests (25 tests/day)
- Day 10: 50 document tests + integration (PoC)

**Week 3 (5 days):**
- Day 11-12: 68 remaining document tests
- Day 13-14: 30 integration scenarios
- Day 15: Golden baseline export + validation

**Contingency:** If behind schedule, Week 4 buffer available

---

## Rollback

**Abort Trigger:** If <250 tests by Day 13 → Extend to Week 4 or reduce scope

---

**Status:** Pending (blocked by US-640)
**Next Action:** Wait for US-640 completion, then start Week 2 Day 6
