# EPIC-026: Technical Risk Heatmap

**Date:** 2025-10-03
**Purpose:** Visual risk assessment for refactoring decision

---

## Risk Matrix

```
IMPACT
  ^
H ‚îÇ  6         2,5        1,3
I ‚îÇ
G ‚îÇ
H ‚îÇ
  ‚îÇ
M ‚îÇ  8         9          4
E ‚îÇ
D ‚îÇ
I ‚îÇ
U ‚îÇ  7         10
M ‚îÇ
  ‚îÇ
L ‚îÇ              11
O ‚îÇ
W ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>
      LOW      MEDIUM     HIGH
           PROBABILITY
```

### Risk Legend

| # | Risk | Probability | Impact | Score |
|---|------|-------------|--------|-------|
| **1** | Break generation flow (Week 4-5) | HIGH | HIGH | üî¥ 9 |
| **2** | State management breaks UI | MEDIUM-HIGH | HIGH | üî¥ 8 |
| **3** | Integration tests reveal unknowns | MEDIUM-HIGH | HIGH | üî¥ 8 |
| **4** | Timeline overrun (9‚Üí11 weeks) | HIGH | MEDIUM | üü° 7 |
| **5** | Async/sync boundary issues | MEDIUM-HIGH | HIGH | üî¥ 8 |
| **6** | Test coverage gaps cause regressions | LOW | HIGH | üü° 6 |
| **7** | Circular dependencies discovered | LOW | MEDIUM | üü¢ 3 |
| **8** | Service initialization failures | LOW | MEDIUM | üü¢ 3 |
| **9** | Hardcoded patterns remain hardcoded | MEDIUM | MEDIUM | üü° 5 |
| **10** | Over-engineering (abstraction debt) | MEDIUM | MEDIUM | üü° 5 |
| **11** | Repository split creates issues | LOW | LOW | üü¢ 2 |

**Risk Score:** Probability √ó Impact (1-9 scale)
- üî¥ **Critical (7-9):** Immediate mitigation required
- üü° **Medium (4-6):** Monitor and mitigate
- üü¢ **Low (1-3):** Accept or defer

---

## Critical Risks (Score 7-9)

### üî¥ Risk #1: Break Generation Flow (Score 9)

**Description:** Extracting `_handle_definition_generation` (385 LOC god method) breaks core business logic

**Probability:** HIGH (70%)
- Complex orchestration across 5+ services
- Async/sync boundary mixing
- 15+ session state mutations
- No current test coverage

**Impact:** HIGH
- Application cannot generate definitions
- Blocks entire user workflow
- Requires major rework or rollback

**Mitigation:**
- ‚úÖ Create 15-20 integration tests BEFORE extraction (Week 1)
- ‚úÖ Incremental extraction (one step at a time)
- ‚úÖ Daily testing after each change
- ‚úÖ Rollback checkpoints every 2 days
- ‚úÖ 2-week contingency buffer

**Owner:** Code Architect (Week 4-5)

---

### üî¥ Risk #2: State Management Breaks UI (Score 8)

**Description:** Session state contract changes break entire UI

**Probability:** MEDIUM-HIGH (50%)
- 50+ `SessionStateManager` calls in `tabbed_interface.py`
- 30+ calls in `definition_generator_tab.py`
- 100+ calls across all tabs
- State contracts span entire application

**Impact:** HIGH
- UI doesn't render
- Tab navigation fails
- Generation results lost
- User data corruption

**Mitigation:**
- ‚úÖ Document state schema (Week 1)
- ‚úÖ Create type-safe state wrappers (Week 1)
- ‚úÖ Schema validation at runtime
- ‚úÖ Incremental migration (don't change all at once)
- ‚úÖ State contract tests

**Owner:** Code Architect (All weeks)

---

### üî¥ Risk #3: Integration Tests Reveal Unknowns (Score 8)

**Description:** Creating integration tests (Week 1) uncovers hidden dependencies

**Probability:** MEDIUM-HIGH (40%)
- Current test coverage: 1 test for 4,318 LOC UI code
- Unknown coupling between components
- Undocumented session state contracts
- Hidden service dependencies

**Impact:** HIGH
- Week 1 takes 2 weeks instead of 1
- +1-2 weeks timeline slip
- May discover blockers for extraction
- Could require plan revision

**Mitigation:**
- ‚úÖ Allocate 7 days for Week 1 (not 5)
- ‚úÖ Focus first 3 days on test creation
- ‚úÖ Early escalation if unknowns found
- ‚úÖ Go/No-Go decision at end of Week 1

**Owner:** Code Architect (Week 1)

---

### üî¥ Risk #5: Async/Sync Boundary Issues (Score 8)

**Description:** Clean async patterns impossible in sync Streamlit framework

**Probability:** MEDIUM-HIGH (50%)
- Streamlit is synchronous
- Category determination is async
- Generation is async (via run_async)
- Cannot eliminate asyncio.run() bridge

**Impact:** HIGH
- Concurrency bugs
- Race conditions
- Error handling complexity
- Performance issues

**Mitigation:**
- ‚úÖ Accept async/sync bridge as architectural constraint
- ‚úÖ Focus on clean boundaries, not elimination
- ‚úÖ Comprehensive async error handling
- ‚úÖ Use existing `run_async()` pattern

**Owner:** Code Architect (Week 4-5)

---

## Medium Risks (Score 4-6)

### üü° Risk #4: Timeline Overrun (Score 7)

**Description:** 9 weeks ‚Üí 11-12 weeks due to complexity

**Probability:** HIGH (60%)
- Proposed plan has tight timeline
- No buffer for unknowns
- Complex orchestrator extraction
- State management migration

**Impact:** MEDIUM
- +2-3 weeks delay
- Budget overrun
- Blocks other work
- Stakeholder frustration

**Mitigation:**
- ‚úÖ **Use 4-5 week alternative plan** (44% faster)
- ‚úÖ Weekly reassessment
- ‚úÖ Parallel work after Week 3
- ‚úÖ Deliver partial if needed

**Owner:** Project Manager

---

### üü° Risk #6: Test Coverage Gaps (Score 6)

**Description:** Insufficient tests allow regressions

**Probability:** LOW (20%)
- Plan includes comprehensive testing
- 15-20 integration tests
- 90%+ coverage for services

**Impact:** HIGH
- Bugs in production
- User-facing errors
- Rollback required

**Mitigation:**
- ‚úÖ Test coverage requirement: 90%+
- ‚úÖ Integration tests must pass
- ‚úÖ Manual QA after each week
- ‚úÖ Smoke tests in CI/CD

**Owner:** Code Architect + QA

---

### üü° Risk #9: Hardcoded Patterns Remain (Score 5)

**Description:** Proposed plan moves patterns to services (still hardcoded)

**Probability:** MEDIUM (40%)
- `OntologicalCategoryService` just moves code
- Patterns not in config
- Not data-driven

**Impact:** MEDIUM
- Maintenance burden remains
- Inconsistency risk
- Not extensible

**Mitigation:**
- ‚úÖ **Use alternative plan** (extract to config)
- ‚úÖ Create `config/ontological_patterns.yaml`
- ‚úÖ Make services read from config

**Owner:** Code Architect (Week 1-2)

---

### üü° Risk #10: Over-Engineering (Score 5)

**Description:** Creating unnecessary abstraction layers

**Probability:** MEDIUM (40%)
- 7 new services (5 unnecessary)
- 4 layers instead of 3
- Orchestrator proliferation

**Impact:** MEDIUM
- Maintenance burden
- Complexity increase
- Slower development
- Technical debt

**Mitigation:**
- ‚úÖ **Use alternative plan** (2 new services, 3 layers)
- ‚úÖ Reuse existing services
- ‚úÖ YAGNI principle
- ‚úÖ Architecture review before Week 2

**Owner:** Technical Architect

---

## Low Risks (Score 1-3)

### üü¢ Risk #7: Circular Dependencies (Score 3)

**Description:** Circular dependencies block refactoring

**Probability:** LOW (10%)
- Only 2 lazy imports in codebase
- No evidence of pervasive circular deps
- Clear service boundaries

**Impact:** MEDIUM
- Requires architectural changes
- Could block extraction

**Mitigation:**
- ‚úÖ Dependency injection
- ‚úÖ Interface-based abstractions
- ‚úÖ Import graph analysis

**Owner:** Code Architect

---

### üü¢ Risk #8: Service Initialization Failures (Score 3)

**Description:** Service initialization fails in production

**Probability:** LOW (10%)
- ServiceContainer pattern already works
- DI well-established
- 89 services already working

**Impact:** MEDIUM
- Application doesn't start
- Fallback to dummy services

**Mitigation:**
- ‚úÖ Initialization tests
- ‚úÖ Graceful fallbacks
- ‚úÖ CI/CD checks

**Owner:** DevOps

---

### üü¢ Risk #11: Repository Split Issues (Score 2)

**Description:** Splitting `definitie_repository.py` causes problems

**Probability:** LOW (5%)
- Not a god object (complexity 4.7)
- 51 tests (excellent coverage)
- Well-structured

**Impact:** LOW
- Easy rollback
- Not critical path

**Mitigation:**
- ‚úÖ **DEFER to later epic** (not in scope)
- ‚úÖ Keep as-is (low priority)

**Owner:** N/A (deferred)

---

## Risk Comparison: Proposed vs Alternative

### Proposed Plan Risk Profile

| Risk Category | Count | Total Score |
|---------------|-------|-------------|
| üî¥ Critical (7-9) | 5 | 41 |
| üü° Medium (4-6) | 4 | 23 |
| üü¢ Low (1-3) | 2 | 5 |
| **TOTAL** | **11** | **69** |

**Overall Risk:** MEDIUM-HIGH

---

### Alternative Plan Risk Profile

| Risk Category | Count | Total Score |
|---------------|-------|-------------|
| üî¥ Critical (7-9) | 3 | 25 |
| üü° Medium (4-6) | 2 | 11 |
| üü¢ Low (1-3) | 2 | 5 |
| **TOTAL** | **7** | **41** |

**Overall Risk:** MEDIUM

**Risk Reduction:** 41% (69 ‚Üí 41 total score)

---

### Mitigated Risks (Alternative Plan)

‚úÖ **Risk #4 (Timeline Overrun)** - Reduced from 60% to 30% probability
  - Reason: 4-5 weeks vs 9 weeks (less time to overrun)

‚úÖ **Risk #9 (Hardcoded Patterns)** - Eliminated (0% probability)
  - Reason: Patterns extracted to config (data-driven)

‚úÖ **Risk #10 (Over-Engineering)** - Reduced from 40% to 10% probability
  - Reason: Only 2 new services, 3 layers (not 4)

‚úÖ **Risk #11 (Repository Split)** - Eliminated (0% probability)
  - Reason: Deferred (not in scope)

---

## Risk Mitigation Strategy

### Week-by-Week Risk Management

**Week 1: Foundation (CRITICAL PHASE)**
- **Primary Risks:** #3 (integration tests reveal unknowns)
- **Mitigation:** 7 days (not 5), early escalation
- **Go/No-Go Decision:** End of Week 1

**Week 2: Business Logic Extraction**
- **Primary Risks:** #9 (hardcoded patterns), #10 (over-engineering)
- **Mitigation:** Extract to config, reuse existing services

**Week 3: UI Component Splitting**
- **Primary Risks:** #2 (state management)
- **Mitigation:** Type-safe wrappers, incremental migration

**Week 4: Orchestration Extraction (CRITICAL PHASE)**
- **Primary Risks:** #1 (break generation), #5 (async/sync)
- **Mitigation:** Comprehensive tests, daily testing, rollback points

**Week 5: Cleanup**
- **Primary Risks:** None (low-risk cleanup work)

---

## Risk Acceptance Criteria

### Go/No-Go Gates

**Week 1 Gate:**
- ‚úÖ 15-20 integration tests created and passing
- ‚úÖ State schema documented
- ‚úÖ No critical unknowns discovered
- ‚ùå **STOP if:** >5 critical unknowns, timeline slip >1 week

**Week 4 Gate:**
- ‚úÖ Orchestrator extraction complete
- ‚úÖ All integration tests passing
- ‚úÖ No functional regressions
- ‚ùå **STOP if:** Tests fail, generation broken, >3 days blocked

**Final Gate:**
- ‚úÖ UI reduced to <1,200 LOC
- ‚úÖ All tests passing (90%+ coverage)
- ‚úÖ No performance degradation
- ‚úÖ Documentation complete

---

## Rollback Strategy

### Rollback Triggers

| Trigger | Action | Owner |
|---------|--------|-------|
| **Integration tests fail (Week 1)** | Reassess plan, add 1 week | PM |
| **Generation broken (Week 4)** | Rollback to Week 3 checkpoint | Code Architect |
| **Timeline slip >2 weeks** | Deliver partial (1-2 files) | PM |
| **<50% progress at Week 3** | Abort, rescope to MVP | Stakeholders |

### Checkpoint Strategy

**Git Tags at End of Each Week:**
- `epic-026-week-1-foundation`
- `epic-026-week-2-business-logic`
- `epic-026-week-3-ui-split`
- `epic-026-week-4-orchestration`
- `epic-026-week-5-cleanup`

**Rollback Command:**
```bash
git checkout epic-026-week-N-<name>
pytest -q  # Verify tests pass
```

**Maximum Rollback Window:** 2 weeks (to previous checkpoint)

---

## Risk Dashboard (For Monitoring)

### KPIs to Track

| KPI | Target | Alert Threshold |
|-----|--------|-----------------|
| **Test Coverage** | >90% | <80% |
| **Integration Tests Passing** | 100% | <95% |
| **Timeline Variance** | ¬±0 weeks | >+1 week |
| **God Method LOC** | <50 LOC | >100 LOC |
| **New Services Created** | 2 | >3 |
| **Hardcoded Patterns** | 0 | >1 |
| **Complexity (Max)** | <15 | >25 |

### Weekly Risk Review

**Questions to Ask:**
1. Are all integration tests passing?
2. Is timeline on track?
3. Are we creating unnecessary services?
4. Are patterns in config (not code)?
5. Is UI getting thinner?

**Escalation Path:**
- Week variance >3 days ‚Üí PM notified
- Critical risk triggered ‚Üí Stakeholders notified
- Rollback needed ‚Üí Architecture review

---

## Recommendation

### Risk-Based Decision

**Proposed Plan:**
- Total Risk Score: 69
- Critical Risks: 5
- Overall Risk: MEDIUM-HIGH

**Alternative Plan:**
- Total Risk Score: 41
- Critical Risks: 3
- Overall Risk: MEDIUM

**Risk Reduction:** 41% with alternative approach

### ‚ö†Ô∏è APPROVE ALTERNATIVE PLAN

**Reasons:**
1. Lower overall risk (41 vs 69)
2. Fewer critical risks (3 vs 5)
3. Mitigates hardcoded patterns (config-driven)
4. Shorter timeline = less time to derail
5. Simpler architecture = less risk surface

---

**Status:** READY FOR DECISION
**Next Action:** Present to stakeholders with risk assessment
**Decision Required:** Accept MEDIUM risk (alternative) vs MEDIUM-HIGH risk (proposed)?

---

**Prepared by:** Technical Architecture Analyst (Agent 2)
**Date:** 2025-10-03
