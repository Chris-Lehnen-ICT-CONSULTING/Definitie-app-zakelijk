---
id: US-422
epic: EPIC-007
titel: "US-422: titel: Advanced Duplicate Detection with ML"
type: feature
status: proposed
prioriteit: LOW
story_points: 13
sprint: backlog
aangemaakt: 2025-01-29
bijgewerkt: 2025-01-29
owner: data-scientist
applies_to: definitie-app@current
canonical: false
last_verified: 2025-01-29
vereisten:
  - REQ-007
  - REQ-095
toegewezen_aan: development-team
---

# US-422: Advanced Duplicate Detection with ML

**Epic:** EPIC-007 - Performance & Scaling

## Gebruikersverhaal

**Als een** data administrator
**wil ik** intelligente duplicate detection met machine learning
**zodat** ik semantisch vergelijkbare definities kan identificeren die niet exact matchen

## Probleembeschrijving

De huidige duplicate detection (placeholder in `ui/components/management_tab.py:1114-1126`) detecteert alleen exacte matches op basis van begrip + context. Dit mist:
- Semantisch vergelijkbare definities met andere bewoordingen
- Definities met typfouten of variaties
- Near-duplicates met kleine verschillen
- Cross-context duplicates die eigenlijk hetzelfde betekenen

Een ML-gebaseerde aanpak kan:
- Embeddings gebruiken voor semantische vergelijking
- Fuzzy matching voor spelling variaties
- Contextual similarity voor cross-domain duplicates
- Automatische merge suggesties genereren

## Acceptatiecriteria

### Functionele Criteria
- [ ] Detecteer semantisch vergelijkbare definities (>85% similarity)
- [ ] Identificeer spelling variaties en typfouten
- [ ] Cross-context duplicate detection
- [ ] Similarity score voor elk paar (0-100%)
- [ ] Merge suggestions met preview
- [ ] Bulk merge capability met undo
- [ ] Whitelist voor false positives
- [ ] Export duplicate rapport

### Technische Criteria
- [ ] Sentence embeddings voor semantische vergelijking
- [ ] Levenshtein distance voor spelling variaties
- [ ] TF-IDF voor keyword similarity
- [ ] Async processing voor grote datasets
- [ ] Caching van embeddings voor performance
- [ ] Incremental updates bij nieuwe definities

### ML Criteria
- [ ] Pre-trained Dutch language model (bijv. BERTje)
- [ ] Fine-tuning op juridische terminologie
- [ ] Threshold configuratie per categorie
- [ ] Confidence scores voor suggestions
- [ ] Active learning van user feedback

## Implementatie Details

### Duplicate Detection Service
```python
class AdvancedDuplicateDetector:
    """ML-powered duplicate detection."""

    def __init__(self):
        self.embedder = DutchEmbedder()  # BERTje of vergelijkbaar
        self.fuzzy_matcher = FuzzyMatcher()
        self.cache = EmbeddingCache()

    async def find_duplicates(self,
                             threshold: float = 0.85) -> List[DuplicateCluster]:
        """Find duplicate clusters using ML."""
        definitions = await self._get_all_definitions()
        embeddings = await self._compute_embeddings(definitions)

        clusters = []
        for i, def1 in enumerate(definitions):
            similar = self._find_similar(
                def1,
                embeddings[i],
                definitions[i+1:],
                embeddings[i+1:],
                threshold
            )
            if similar:
                clusters.append(DuplicateCluster(def1, similar))

        return clusters

    async def _compute_embeddings(self,
                                 definitions: List[Definition]) -> np.ndarray:
        """Compute or retrieve cached embeddings."""
        embeddings = []
        for definition in definitions:
            cache_key = f"emb_{definition.id}_{definition.version}"

            if cached := self.cache.get(cache_key):
                embeddings.append(cached)
            else:
                embedding = await self.embedder.encode(
                    definition.begrip + " " + definition.definitie
                )
                self.cache.set(cache_key, embedding)
                embeddings.append(embedding)

        return np.array(embeddings)

    def _find_similar(self,
                     target: Definition,
                     target_embedding: np.ndarray,
                     candidates: List[Definition],
                     candidate_embeddings: np.ndarray,
                     threshold: float) -> List[SimilarDefinition]:
        """Find similar definitions above threshold."""
        similarities = cosine_similarity(
            target_embedding.reshape(1, -1),
            candidate_embeddings
        )[0]

        similar = []
        for idx, score in enumerate(similarities):
            if score >= threshold:
                # Additional checks
                fuzzy_score = self.fuzzy_matcher.ratio(
                    target.definitie,
                    candidates[idx].definitie
                )

                similar.append(SimilarDefinition(
                    definition=candidates[idx],
                    semantic_score=score,
                    fuzzy_score=fuzzy_score,
                    overall_score=(score + fuzzy_score) / 2
                ))

        return sorted(similar, key=lambda x: x.overall_score, reverse=True)

    async def suggest_merge(self,
                          cluster: DuplicateCluster) -> MergeSuggestion:
        """Generate intelligent merge suggestion."""
        # Bepaal beste versie als master
        master = self._select_master(cluster)

        # Combineer beste eigenschappen
        merged = Definition(
            begrip=master.begrip,
            definitie=self._merge_definitions(cluster),
            categorie=self._most_common_category(cluster),
            organisatorische_context=self._merge_contexts(cluster),
            validation_score=max(d.validation_score for d in cluster.definitions)
        )

        return MergeSuggestion(
            master=master,
            merged=merged,
            confidence=self._calculate_merge_confidence(cluster)
        )
```

### Fuzzy Matching
```python
class FuzzyMatcher:
    """Fuzzy string matching for variations."""

    def ratio(self, str1: str, str2: str) -> float:
        """Calculate similarity ratio."""
        # Normaliseer strings
        s1 = self._normalize(str1)
        s2 = self._normalize(str2)

        # Combineer verschillende metrics
        levenshtein = 1 - (editdistance.eval(s1, s2) / max(len(s1), len(s2)))
        jaccard = self._jaccard_similarity(s1.split(), s2.split())
        ngram = self._ngram_similarity(s1, s2, n=3)

        return (levenshtein + jaccard + ngram) / 3

    def _normalize(self, text: str) -> str:
        """Normalize text for comparison."""
        return text.lower().strip()

    def _jaccard_similarity(self, set1: set, set2: set) -> float:
        """Jaccard similarity tussen word sets."""
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        return intersection / union if union > 0 else 0

    def _ngram_similarity(self, str1: str, str2: str, n: int = 3) -> float:
        """N-gram similarity."""
        ngrams1 = set(str1[i:i+n] for i in range(len(str1) - n + 1))
        ngrams2 = set(str2[i:i+n] for i in range(len(str2) - n + 1))
        return self._jaccard_similarity(ngrams1, ngrams2)
```

### ML Model Configuration
```yaml
# config/ml_duplicate_detection.yaml
model:
  type: "sentence-transformers"
  name: "GroNLP/bert-base-dutch-cased"
  max_sequence_length: 512

thresholds:
  semantic_similarity: 0.85
  fuzzy_matching: 0.80
  overall_score: 0.82

categories:
  # Different thresholds per category
  proces:
    semantic: 0.87
    fuzzy: 0.83
  type:
    semantic: 0.85
    fuzzy: 0.80
  resultaat:
    semantic: 0.88
    fuzzy: 0.85

cache:
  embedding_ttl: 86400  # 24 hours
  max_size: 10000

active_learning:
  enabled: true
  feedback_threshold: 10  # Retrain after 10 feedback items
```

## Definition of Done

- [ ] ML duplicate detection service geÃ¯mplementeerd
- [ ] Embedding cache voor performance
- [ ] Fuzzy matching algorithms
- [ ] Merge suggestion engine
- [ ] UI voor duplicate review
- [ ] Bulk merge functionaliteit
- [ ] Undo capability voor merges
- [ ] Whitelist management
- [ ] Unit tests (>85% coverage)
- [ ] Performance test met 10k+ definities
- [ ] A/B test met users (ML vs exact matching)
- [ ] Documentation voor configuratie
- [ ] Training data voor fine-tuning

## Risico's

| Risico | Impact | Kans | Mitigatie |
|--------|--------|------|-----------|
| False positives | Medium | Medium | Configureerbare thresholds, whitelist |
| Performance met grote datasets | High | Medium | Caching, async processing |
| Model accuracy juridische termen | High | Low | Fine-tuning op domain data |
| Memory gebruik embeddings | Medium | Low | Incremental processing |
| User acceptance auto-merge | Medium | Medium | Preview, undo, confidence scores |

## Dependencies

- Sentence transformers library
- Pre-trained Dutch language model
- Vector similarity libraries (faiss/annoy)
- Fuzzy matching libraries (fuzzywuzzy/rapidfuzz)
- Async processing framework

## Notes

- Start met pre-trained model, fine-tune later
- Begin met conservative thresholds (meer false negatives dan positives)
- Implementeer feedback loop voor model verbetering
- Consider offline batch processing voor grote datasets
- Mogelijk toekomstige integratie met externe knowledge bases

## Mockups

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Duplicate Detection Results          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ Found 3 duplicate clusters             â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Cluster 1 (95% confidence)      â”‚    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ â”‚ âš¡ "Authenticatie" (DJI)         â”‚    â”‚
â”‚ â”‚ âš¡ "Authentificatie" (OM)        â”‚    â”‚
â”‚ â”‚    â†’ Spelling variation detected â”‚    â”‚
â”‚ â”‚                                  â”‚    â”‚
â”‚ â”‚ [ğŸ‘ï¸ Preview Merge] [âœ… Merge]   â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Cluster 2 (87% confidence)      â”‚    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ â”‚ ğŸ“„ "Vonnis" (Strafrecht)         â”‚    â”‚
â”‚ â”‚ ğŸ“„ "Uitspraak" (Strafrecht)      â”‚    â”‚
â”‚ â”‚    â†’ Semantic similarity         â”‚    â”‚
â”‚ â”‚                                  â”‚    â”‚
â”‚ â”‚ [ğŸ‘ï¸ Preview] [â• Whitelist]     â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ [â¬‡ï¸ Export Report] [âš™ï¸ Settings]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```