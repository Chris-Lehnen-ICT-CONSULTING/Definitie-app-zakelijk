---
id: US-423
epic: EPIC-005
titel: "US-423: titel: Background Export Queue Management"
type: feature
status: proposed
prioriteit: LOW
story_points: 8
sprint: backlog
aangemaakt: 2025-01-29
bijgewerkt: 2025-01-29
owner: backend-developer
applies_to: definitie-app@current
canonical: false
last_verified: 2025-01-29
vereisten:
  - REQ-022
  - REQ-042
  - REQ-084
toegewezen_aan: development-team
---

# US-423: Background Export Queue Management

**Epic:** EPIC-005 - Export & Import

## Gebruikersverhaal

**Als een** juridisch professional met grote datasets
**wil ik** exports in de achtergrond kunnen laten uitvoeren
**zodat** ik door kan werken terwijl grote exports worden verwerkt

## Probleembeschrijving

Momenteel blokkeren grote exports (>1000 definities) de UI tijdens verwerking. Dit leidt tot:
- UI freeze bij exports > 30 seconden
- WebSocket timeouts bij zeer grote datasets
- Geen mogelijkheid om export te annuleren
- Geen progress feedback tijdens export
- Verloren werk als browser crasht

Een queue-based aanpak biedt:
- Non-blocking export processing
- Progress tracking
- Cancel/retry mogelijkheden
- Crash recovery
- Parallelle export jobs

## Acceptatiecriteria

### Functionele Criteria
- [ ] Export jobs worden in background queue geplaatst
- [ ] Real-time progress indicator (percentage + items)
- [ ] Cancel running export mogelijk
- [ ] Retry failed exports
- [ ] Queue status overview (pending/running/completed/failed)
- [ ] Download notification wanneer klaar
- [ ] Automatische cleanup oude exports (>7 dagen)
- [ ] Maximum 5 gelijktijdige export jobs

### Technische Criteria
- [ ] Async queue processing met Celery/RQ of asyncio
- [ ] WebSocket/SSE voor real-time updates
- [ ] Persistent queue storage (SQLite/Redis)
- [ ] Graceful shutdown (jobs worden hervat)
- [ ] Memory-efficient streaming voor grote datasets
- [ ] Compression voor storage efficiency

### UI Criteria
- [ ] Export queue status indicator in header
- [ ] Dedicated queue management sectie
- [ ] Progress bars voor active jobs
- [ ] One-click download voor completed jobs
- [ ] Clear error messages voor failed jobs
- [ ] Bulk actions (cancel all, retry all failed)

## Implementatie Details

### Export Queue Service
```python
class ExportQueueService:
    """Manage background export jobs."""

    def __init__(self):
        self.queue = AsyncQueue()
        self.active_jobs = {}
        self.max_concurrent = 5

    async def enqueue_export(self,
                            export_request: ExportRequest,
                            user_id: str) -> str:
        """Add export job to queue."""
        job = ExportJob(
            id=str(uuid.uuid4()),
            request=export_request,
            user_id=user_id,
            status=JobStatus.PENDING,
            created_at=datetime.now(UTC),
            progress=0
        )

        await self.queue.put(job)
        await self._persist_job(job)

        # Start worker if not running
        if len(self.active_jobs) < self.max_concurrent:
            asyncio.create_task(self._process_queue())

        return job.id

    async def _process_queue(self):
        """Process jobs from queue."""
        while not self.queue.empty():
            job = await self.queue.get()

            if job.id in self.active_jobs:
                continue  # Already processing

            self.active_jobs[job.id] = job
            job.status = JobStatus.RUNNING

            try:
                await self._execute_export(job)
                job.status = JobStatus.COMPLETED
            except Exception as e:
                job.status = JobStatus.FAILED
                job.error = str(e)
            finally:
                del self.active_jobs[job.id]
                await self._persist_job(job)

    async def _execute_export(self, job: ExportJob):
        """Execute export with progress tracking."""
        total_items = await self._count_items(job.request)
        processed = 0

        async for batch in self._export_batches(job.request):
            if job.cancelled:
                raise ExportCancelledException()

            await self._write_batch(job, batch)
            processed += len(batch)

            # Update progress
            job.progress = int((processed / total_items) * 100)
            await self._notify_progress(job)

        # Generate final file
        job.output_path = await self._finalize_export(job)

    async def cancel_job(self, job_id: str) -> bool:
        """Cancel a running or pending job."""
        if job_id in self.active_jobs:
            self.active_jobs[job_id].cancelled = True
            return True

        # Remove from queue if pending
        return await self._remove_from_queue(job_id)

    async def get_job_status(self, job_id: str) -> JobStatus:
        """Get current job status."""
        if job_id in self.active_jobs:
            return self.active_jobs[job_id]

        return await self._load_job(job_id)

    async def retry_job(self, job_id: str) -> str:
        """Retry a failed job."""
        original_job = await self._load_job(job_id)

        if original_job.status != JobStatus.FAILED:
            raise ValueError("Can only retry failed jobs")

        # Create new job with same parameters
        return await self.enqueue_export(
            original_job.request,
            original_job.user_id
        )
```

### Progress Notification
```python
class ExportProgressNotifier:
    """Real-time progress notifications."""

    def __init__(self):
        self.connections = {}  # WebSocket connections

    async def notify_progress(self, job: ExportJob):
        """Send progress update to client."""
        message = {
            "type": "export_progress",
            "job_id": job.id,
            "progress": job.progress,
            "status": job.status.value,
            "eta": self._estimate_completion(job)
        }

        if job.user_id in self.connections:
            await self.connections[job.user_id].send_json(message)

    def _estimate_completion(self, job: ExportJob) -> Optional[datetime]:
        """Estimate completion time based on progress."""
        if job.progress == 0:
            return None

        elapsed = (datetime.now(UTC) - job.started_at).total_seconds()
        rate = job.progress / elapsed
        remaining = (100 - job.progress) / rate

        return datetime.now(UTC) + timedelta(seconds=remaining)
```

### Queue Storage Schema
```sql
-- Queue persistence table
CREATE TABLE export_queue (
    id TEXT PRIMARY KEY,
    user_id TEXT NOT NULL,
    request_json TEXT NOT NULL,
    status TEXT NOT NULL,
    progress INTEGER DEFAULT 0,
    output_path TEXT,
    error_message TEXT,
    created_at TIMESTAMP NOT NULL,
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    cancelled BOOLEAN DEFAULT FALSE,

    INDEX idx_user_status (user_id, status),
    INDEX idx_created (created_at)
);

-- Cleanup old jobs
DELETE FROM export_queue
WHERE completed_at < datetime('now', '-7 days')
  AND status IN ('COMPLETED', 'FAILED');
```

### UI Component
```python
def render_export_queue():
    """Render export queue status."""
    st.markdown("### ğŸ“Š Export Queue")

    queue_service = st.session_state.get('export_queue_service')
    jobs = queue_service.get_user_jobs(st.session_state.user_id)

    if not jobs:
        st.info("No export jobs in queue")
        return

    for job in jobs:
        col1, col2, col3, col4 = st.columns([3, 2, 1, 1])

        with col1:
            st.write(f"**{job.request.description}**")
            if job.status == JobStatus.RUNNING:
                st.progress(job.progress / 100)
            elif job.status == JobStatus.COMPLETED:
                st.success("âœ… Completed")
            elif job.status == JobStatus.FAILED:
                st.error(f"âŒ Failed: {job.error}")

        with col2:
            st.caption(f"Status: {job.status.value}")
            if job.eta:
                st.caption(f"ETA: {job.eta.strftime('%H:%M')}")

        with col3:
            if job.status == JobStatus.COMPLETED:
                st.download_button(
                    "ğŸ“¥ Download",
                    data=job.get_file_data(),
                    file_name=job.output_filename
                )
            elif job.status == JobStatus.RUNNING:
                if st.button("âŒ Cancel", key=f"cancel_{job.id}"):
                    queue_service.cancel_job(job.id)

        with col4:
            if job.status == JobStatus.FAILED:
                if st.button("ğŸ”„ Retry", key=f"retry_{job.id}"):
                    queue_service.retry_job(job.id)
```

## Definition of Done

- [ ] Export queue service geÃ¯mplementeerd
- [ ] Background job processing
- [ ] Real-time progress notifications
- [ ] Queue persistence in database
- [ ] UI queue management component
- [ ] Cancel/retry functionaliteit
- [ ] Automatic cleanup oude jobs
- [ ] WebSocket/SSE integratie
- [ ] Unit tests (>90% coverage)
- [ ] Integration tests met mock exports
- [ ] Performance test (100 concurrent jobs)
- [ ] Error recovery scenarios getest
- [ ] Gebruikersdocumentatie

## Risico's

| Risico | Impact | Kans | Mitigatie |
|--------|--------|------|-----------|
| Memory overflow grote exports | High | Low | Streaming, chunked processing |
| Queue persistence failure | High | Low | Fallback naar in-memory queue |
| WebSocket disconnects | Medium | Medium | Reconnect logic, polling fallback |
| Orphaned jobs | Low | Medium | Timeout + cleanup routine |
| Race conditions | Medium | Low | Proper locking, atomic operations |

## Dependencies

- AsyncIO of Celery voor queue management
- WebSocket/SSE library voor notifications
- Background job framework
- File compression library
- Progress tracking utilities

## Notes

- Start met in-memory queue, voeg persistence later toe
- Implementeer eerst basis queue, dan advanced features
- Consider Redis voor productie queue storage
- Mogelijk toekomstige email notifications bij completion
- Integratie met cloud storage voor grote exports

## Mockups

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“Š Export Queue (2 active, 1 pending)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ All definitions Q1 2025          â”‚    â”‚
â”‚ â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 65%           â”‚    â”‚
â”‚ â”‚ Status: Running | ETA: 14:32     â”‚    â”‚
â”‚ â”‚                    [âŒ Cancel]    â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Established only - Excel         â”‚    â”‚
â”‚ â”‚ â–“â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 23%            â”‚    â”‚
â”‚ â”‚ Status: Running | ETA: 14:45     â”‚    â”‚
â”‚ â”‚                    [âŒ Cancel]    â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Archive 2024                     â”‚    â”‚
â”‚ â”‚ â³ Pending in queue...            â”‚    â”‚
â”‚ â”‚ Status: Pending | Position: 1    â”‚    â”‚
â”‚ â”‚                    [âŒ Cancel]    â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ [ğŸ”„ Refresh] [ğŸ“‹ History]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```