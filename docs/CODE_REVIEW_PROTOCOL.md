# ğŸ” Code Review Protocol - Systematische Verificatie

**Doel**: VerifiÃ«ren wat werkelijk functioneert vs wat alleen bestaat/geclaimd wordt  
**Gebruik**: Dit protocol voor ELKE component/feature uitvoeren

---

## ğŸ“‹ Standaard Review Checklist

### Phase 1: Quick Existence Check (5 min)
```bash
â–¡ Bestaat het bestand/de module?
â–¡ Kan het geÃ¯mporteerd worden zonder errors?
â–¡ Zijn er obvious syntax errors?
â–¡ Bestaat de documentatie?
```

### Phase 2: Dependency Analysis (10 min)
```bash
â–¡ Lijst alle imports
â–¡ Verifieer dat alle dependencies bestaan
â–¡ Check of import namen kloppen
â–¡ Identificeer circulaire dependencies
â–¡ Controleer versie compatibiliteit
```

### Phase 3: Functionality Test (20 min)
```bash
â–¡ Start de functionaliteit op
â–¡ Voer happy path test uit
â–¡ Test edge cases
â–¡ Test error handling
â–¡ Verifieer output format
```

### Phase 4: Integration Check (15 min)
```bash
â–¡ Hoe integreert het met andere componenten?
â–¡ Worden interfaces correct gebruikt?
â–¡ Data flow verificatie
â–¡ Side effects check
```

### Phase 5: Test Suite Verification (10 min)
```bash
â–¡ Draaien de tests echt?
â–¡ Wat is de werkelijke coverage?
â–¡ Zijn er skipped tests?
â–¡ Mock vs echte functionaliteit
```

---

## ğŸ¯ Component-Specifieke Reviews

### 1. Service Review Template
```python
# VOOR ELKE SERVICE (Generator, Validator, Repository, etc.)

## Stap 1: Import Test
try:
    from services.{service_name} import {ServiceClass}
    print("âœ… Import succesvol")
except ImportError as e:
    print(f"âŒ Import failed: {e}")
    # STOP - service bestaat niet/kan niet laden

## Stap 2: Instantiation Test  
try:
    service = {ServiceClass}()
    print("âœ… Instantiatie succesvol")
except Exception as e:
    print(f"âŒ Instantiatie failed: {e}")
    # Documenteer missing dependencies

## Stap 3: Method Test
# Test ELKE publieke methode
methods_to_test = [
    ("method_name", test_args, expected_output),
    # ... voor elke methode
]

for method, args, expected in methods_to_test:
    try:
        result = getattr(service, method)(*args)
        print(f"âœ… {method} werkt")
        # Verifieer output
    except Exception as e:
        print(f"âŒ {method} failed: {e}")

## Stap 4: Integration Test
# Test met echte dependencies
# Documenteer welke andere services nodig zijn
# Test data flow
```

### 2. Database/Repository Review
```python
## Stap 1: Connection Test
â–¡ Kan verbinding maken?
â–¡ Correct schema?
â–¡ UTF-8 encoding werkt?

## Stap 2: CRUD Operations
â–¡ Create - nieuw record
â–¡ Read - ophalen data
â–¡ Update - wijzigen record  
â–¡ Delete - verwijderen record

## Stap 3: Concurrent Access
# Start 5 parallelle processen
â–¡ Geen deadlocks?
â–¡ Data integrity behouden?
â–¡ Performance acceptabel?

## Stap 4: Migration Check
â–¡ Alle migraties uitgevoerd?
â–¡ Rollback mogelijk?
â–¡ Data loss risico's?
```

### 3. API/Interface Review
```python
## Stap 1: Contract Verification
â–¡ Alle methodes geÃ¯mplementeerd?
â–¡ Correct return types?
â–¡ Parameters match interface?

## Stap 2: Behavior Test
â–¡ Expected behavior matches actual
â–¡ Error cases handled
â–¡ Async/sync correctheid

## Stap 3: Version Compatibility
â–¡ Backwards compatible?
â–¡ Breaking changes gedocumenteerd?
```

### 4. UI Component Review
```python
## Stap 1: Render Test
â–¡ Component rendert zonder errors?
â–¡ Alle UI elementen zichtbaar?
â–¡ Correct styling?

## Stap 2: Interaction Test
â–¡ Click handlers werken?
â–¡ Forms submitten correct?
â–¡ Validatie werkt?

## Stap 3: State Management
â–¡ State updates correct?
â–¡ No infinite loops?
â–¡ Performance OK?

## Stap 4: Integration
â–¡ Data komt aan van backend?
â–¡ Updates worden gepersist?
â–¡ Error states handled?
```

---

## ğŸ“Š Review Output Template

Voor elk gereviewd item, documenteer:

```markdown
# Component: [Naam]
**Review Datum**: [YYYY-MM-DD]
**Reviewer**: [Naam/Tool]
**Claimed Status**: [Wat wordt beweerd]
**Actual Status**: [Wat werkelijk werkt]

## Bevindingen

### âœ… Wat Werkt
- [Lijst van werkende functionaliteit]

### âŒ Wat Niet Werkt  
- [Lijst van kapotte functionaliteit]
- [Root cause per probleem]

### âš ï¸ Gedeeltelijk Werkend
- [Functionaliteit die partly werkt]
- [Onder welke condities faalt het]

## Dependencies
- **Werkend**: [lijst]
- **Ontbrekend**: [lijst]
- **Incorrect**: [lijst]

## Test Coverage
- **Claimed**: X%
- **Actual**: Y%
- **Tests die falen**: [lijst]

## Integratie Status
- **Component A**: âœ…/âŒ [details]
- **Component B**: âœ…/âŒ [details]

## Geschatte Reparatietijd
- **Quick fixes** (< 1 dag): [lijst]
- **Medium fixes** (1-3 dagen): [lijst]  
- **Major fixes** (> 3 dagen): [lijst]

## Prioriteit
ğŸ”´ KRITIEK / ğŸŸ¡ BELANGRIJK / ğŸŸ¢ NICE TO HAVE

## Aanbevelingen
1. [Concrete actie 1]
2. [Concrete actie 2]
```

---

## ğŸš€ Uitvoering Strategie

### Week 1, Dag 1-2: Batch Review
```bash
Maandag Ochtend:
09:00-10:00: Service Architecture overview
10:00-11:00: DefinitionGenerator deep dive  
11:00-12:00: DefinitionValidator + regels
13:00-14:00: DefinitionRepository + DB
14:00-15:00: DefinitionOrchestrator
15:00-16:00: WebLookupService (al gedaan)
16:00-17:00: Documenteer findings

Dinsdag:
09:00-10:00: Feature flags system
10:00-11:00: UI Components (alle tabs)
11:00-12:00: Test infrastructure
13:00-14:00: Database/migrations
14:00-15:00: Integration points
15:00-17:00: Prioriteit matrix maken
```

### Output: Priority Matrix
```
         Urgent  | Not Urgent
        ---------|----------
Broken  | FIX NOW | Schedule
        |   ğŸ”´    |    ğŸŸ¡
        ---------|----------
Works   | Verify  | Document  
        |   ğŸŸ¡    |    ğŸŸ¢
```

---

## ğŸ”§ Tools & Commands

### Automated Checks
```bash
# Import check
python -c "from services.xyz import XYZ; print('âœ…')"

# Test runner
pytest tests/test_xyz.py -v --tb=short

# Coverage check
pytest --cov=services.xyz --cov-report=term-missing

# Lint check
pylint services/xyz.py

# Type check
mypy services/xyz.py
```

### Manual Verification
```python
# Quick service test script
def verify_service(service_class, test_method, test_args):
    try:
        service = service_class()
        result = getattr(service, test_method)(*test_args)
        return True, result
    except Exception as e:
        return False, str(e)

# Database test
def verify_concurrent_access():
    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(db_operation) for _ in range(5)]
        results = [f.result() for f in futures]
    return all(results)
```

---

## âš¡ Quick Decision Tree

```
Kan het geÃ¯mporteerd worden?
â”œâ”€ NEE â†’ Component bestaat niet/syntax error
â”‚   â””â”€ Actie: Volledige rebuild nodig
â”œâ”€ JA â†’ Kan het geÃ¯nstantieerd worden?
    â”œâ”€ NEE â†’ Dependencies missing/incorrect
    â”‚   â””â”€ Actie: Fix dependencies eerst
    â”œâ”€ JA â†’ Werken de methodes?
        â”œâ”€ NEE â†’ Implementation bugs
        â”‚   â””â”€ Actie: Debug & fix methods
        â”œâ”€ JA â†’ Integreert het correct?
            â”œâ”€ NEE â†’ Interface mismatch
            â”‚   â””â”€ Actie: Update interfaces
            â””â”€ JA â†’ Component werkt! âœ…
```

---

## ğŸ“ Review Log Template

Houd een log bij tijdens review:

```
[09:15] Starting review of DefinitionGenerator
[09:16] âœ… Import successful
[09:18] âŒ Missing dependency: OpenAI client not configured  
[09:20] âŒ Method generate_definition fails with: "api_key required"
[09:25] âš ï¸ Tests exist but skip due to missing API key
[09:30] Priority: ğŸ”´ KRITIEK - core functionaliteit
[09:32] Est. fix time: 2 hours (config setup)
```

---

Dit protocol geeft een systematische aanpak voor het reviewen van elke component. Het belangrijkste is:
1. **Wees methodisch** - sla geen stappen over
2. **Documenteer alles** - ook kleine problemen
3. **Test echt** - vertrouw niet op bestaande tests
4. **Prioriteer** - niet alles hoeft perfect