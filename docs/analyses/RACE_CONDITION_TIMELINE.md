# @cached Decorator Race Condition - Visual Timeline

## The Race Condition Visualized

### Production Scenario: 4 Threads Call get_all_rules() Simultaneously

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ @cached Decorator Execution Timeline                                        â”‚
â”‚ File: src/utils/cache.py lines 260-271                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Time    Thread-1              Thread-2              Thread-3              Thread-4
â•â•â•â•    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

0ms     wrapper() called      wrapper() called      wrapper() called      wrapper() called
        â†“                     â†“                     â†“                     â†“
        cache_key =           cache_key =           cache_key =           cache_key =
        "load_all_rules"      "load_all_rules"      "load_all_rules"      "load_all_rules"


1ms     ğŸ”’ Lock acquired      ğŸ”’ Lock acquired      ğŸ”’ Lock acquired      ğŸ”’ Lock acquired
        backend_get(key)      backend_get(key)      backend_get(key)      backend_get(key)
        â†“                     â†“                     â†“                     â†“
        Returns: None         Returns: None         Returns: None         Returns: None
        ğŸ”“ Lock released      ğŸ”“ Lock released      ğŸ”“ Lock released      ğŸ”“ Lock released


2ms     âš ï¸  UNPROTECTED GAP   âš ï¸  UNPROTECTED GAP   âš ï¸  UNPROTECTED GAP   âš ï¸  UNPROTECTED GAP
        â†“                     â†“                     â†“                     â†“
        if None: âœ—            if None: âœ—            if None: âœ—            if None: âœ—
        Skip return           Skip return           Skip return           Skip return


3ms     ğŸ”´ Execute func()     ğŸ”´ Execute func()     ğŸ”´ Execute func()     ğŸ”´ Execute func()
        â†“                     â†“                     â†“                     â†“
        Load 53 JSON files    Load 53 JSON files    Load 53 JSON files    Load 53 JSON files
        â†“                     â†“                     â†“                     â†“
        Read disk...          Read disk...          Read disk...          Read disk...
        Parse JSON...         Parse JSON...         Parse JSON...         Parse JSON...
        Build dict...         Build dict...         Build dict...         Build dict...


13ms    âœ… Done               âœ… Done               âœ… Done               âœ… Done
        result = {...}        result = {...}        result = {...}        result = {...}


14ms    ğŸ”’ Lock acquired      ğŸ”’ Lock acquired      ğŸ”’ Lock acquired      ğŸ”’ Lock acquired
        backend_set(key, {})  backend_set(key, {})  backend_set(key, {})  backend_set(key, {})
        ğŸ”“ Lock released      ğŸ”“ Lock released      ğŸ”“ Lock released      ğŸ”“ Lock released
        (Last write wins!)    (Discarded!)          (Discarded!)          (Discarded!)


15ms    return result         return result         return result         return result
```

## The Problem: Check-Then-Act Race Condition

### The Unprotected Gap (Lines 260-271)

```python
# Line 260: CHECK (protected by lock)
cached_result = backend_get(cache_key)  # ğŸ”’ Lock acquired â†’ None â†’ ğŸ”“ Lock released

# Lines 261-266: Conditional logic (NO LOCK)
if cached_result is not None:           # âš ï¸  UNPROTECTED - All threads see None
    return cached_result

# Lines 267-270: Cache miss logic (NO LOCK)
logger.debug(f"Cache miss for {fn}")    # âš ï¸  UNPROTECTED - All threads log this
_stats["misses"] += 1

# Line 271: ACT (NO LOCK)
result = func(*args, **kwargs)          # âš ï¸  UNPROTECTED - All threads execute!
```

### Why the Gap is Dangerous

```
Thread-1 checks cache â†’ None                    â”
Thread-2 checks cache â†’ None                    â”‚
Thread-3 checks cache â†’ None                    â”œâ”€ ALL happen before ANY set()
Thread-4 checks cache â†’ None                    â”˜

        â†“ All threads in unprotected gap â†“

Thread-1 executes func()  â”€â”
Thread-2 executes func()  â”€â”¤
Thread-3 executes func()  â”€â”œâ”€ PARALLEL EXECUTION (4x waste)
Thread-4 executes func()  â”€â”˜

        â†“ All threads try to set cache â†“

Thread-1 sets cache       â”€â”
Thread-2 sets cache       â”€â”¤
Thread-3 sets cache       â”€â”œâ”€ LAST WRITE WINS (3 results discarded)
Thread-4 sets cache       â”€â”˜
```

## Production Evidence Matches Timeline

### Production Logs

```
12:26:06,561 - Loading 53 regel files  â† Thread 1 at 3ms
12:26:06,561 - Loading 53 regel files  â† Thread 2 at 3ms (0ms difference!)
12:26:06,562 - Loading 53 regel files  â† Thread 3 at 3ms (1ms difference)
12:26:06,562 - Loading 53 regel files  â† Thread 4 at 3ms (1ms difference)

12:26:06,574 - âœ… 53 regels geladen    â† Thread 1 done (13ms later)
12:26:06,574 - âœ… 53 regels geladen    â† Thread 2 done (13ms later)
12:26:06,574 - âœ… 53 regels geladen    â† Thread 3 done (12ms later)
12:26:06,575 - âœ… 53 regels geladen    â† Thread 4 done (13ms later)
```

**Analysis:**
- All start within 1ms â†’ All threads in unprotected gap simultaneously âœ“
- All take ~13ms â†’ All threads doing actual I/O work âœ“
- No instant cache hits â†’ No thread benefited from cache âœ“

## What Thread-Safe Would Look Like

### With Proper Locking

```
Time    Thread-1              Thread-2              Thread-3              Thread-4
â•â•â•â•    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•     â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

0ms     ğŸ”’ Acquire per-key    â³ Wait for lock...   â³ Wait for lock...   â³ Wait for lock...
        lock on "load_all"
        â†“
        Check cache â†’ None
        â†“
1ms     Execute func()        â³ Still waiting...   â³ Still waiting...   â³ Still waiting...
        Load 53 files...
        â†“


13ms    Set cache             â³ Still waiting...   â³ Still waiting...   â³ Still waiting...
        ğŸ”“ Release lock
        â†“
        return result


14ms                          ğŸ”’ Acquire lock       â³ Wait for lock...   â³ Wait for lock...
                              Check cache â†’ HIT!
                              ğŸ”“ Release lock
                              â†“
                              return cached


15ms                                                ğŸ”’ Acquire lock       â³ Wait for lock...
                                                    Check cache â†’ HIT!
                                                    ğŸ”“ Release lock
                                                    â†“
                                                    return cached


16ms                                                                      ğŸ”’ Acquire lock
                                                                          Check cache â†’ HIT!
                                                                          ğŸ”“ Release lock
                                                                          â†“
                                                                          return cached
```

**Expected production logs for thread-safe:**
```
12:26:06,561 - Loading 53 regel files  â† Thread 1 only
12:26:06,574 - âœ… 53 regels geladen    â† Thread 1 done (13ms)

(Threads 2-4 get instant cache hits - no logs!)
```

## The Fix Required

### Current Code (BROKEN)

```python
@wraps(func)
def wrapper(*args, **kwargs):
    cache_key = _generate_key_from_args(...)

    cached_result = backend_get(cache_key)  # â† CHECK
    if cached_result is not None:
        return cached_result

    # âš ï¸  UNPROTECTED GAP - Multiple threads can be here!

    result = func(*args, **kwargs)          # â† ACT (4x execution!)

    backend_set(cache_key, result, ttl)
    return result
```

### Thread-Safe Pattern (SOLUTION)

```python
@wraps(func)
def wrapper(*args, **kwargs):
    cache_key = _generate_key_from_args(...)

    # Fast path: check cache without lock
    cached_result = backend_get(cache_key)
    if cached_result is not None:
        return cached_result

    # Get per-key computation lock
    with _get_computation_lock(cache_key):  # â† PROTECT THE GAP!
        # Double-check pattern
        cached_result = backend_get(cache_key)
        if cached_result is not None:
            return cached_result  # Another thread computed it

        # ONLY FIRST THREAD GETS HERE
        result = func(*args, **kwargs)  # â† 1x execution!

        backend_set(cache_key, result, ttl)
        return result
```

**Key difference:** Per-key lock protects the check-then-act gap

## Performance Impact Visualization

### Current (Race Condition)

```
Total Work = 4 threads Ã— 13ms = 52ms CPU time
Total I/O = 4 threads Ã— 53 files = 212 file reads

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Thread1 â”‚ Thread2 â”‚ Thread3 â”‚ Thread4 â”‚
â”‚ 13ms â–ˆâ–ˆ â”‚ 13ms â–ˆâ–ˆ â”‚ 13ms â–ˆâ–ˆ â”‚ 13ms â–ˆâ–ˆ â”‚ â† All threads work
â”‚ 53 read â”‚ 53 read â”‚ 53 read â”‚ 53 read â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cache hit rate: 0% (0/4 threads)
Wasted work: 75% (3/4 executions discarded)
```

### Thread-Safe (Expected)

```
Total Work = 1 thread Ã— 13ms = 13ms CPU time
Total I/O = 1 thread Ã— 53 files = 53 file reads

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Thread1 â”‚ Thread2 â”‚ Thread3 â”‚ Thread4 â”‚
â”‚ 13ms â–ˆâ–ˆ â”‚ 0ms     â”‚ 0ms     â”‚ 0ms     â”‚ â† Only first thread works
â”‚ 53 read â”‚ cached  â”‚ cached  â”‚ cached  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cache hit rate: 75% (3/4 threads)
Wasted work: 0% (all results used)
```

### Improvement

| Metric | Current | Thread-Safe | Improvement |
|--------|---------|-------------|-------------|
| CPU time | 52ms | 13ms | **75% faster** |
| File reads | 212 | 53 | **75% less I/O** |
| Cache hits | 0/4 (0%) | 3/4 (75%) | **âˆ better** |
| Memory waste | 3Ã— results | 0Ã— results | **100% efficient** |

## Conclusion

The timeline visualization clearly shows:

1. **Root cause:** 11-line unprotected gap between cache check and function execution
2. **Symptom:** All 4 threads enter the gap simultaneously and all execute func()
3. **Evidence:** Production logs match the parallel execution pattern exactly
4. **Impact:** 4x CPU, 4x I/O, 4x memory, 0% cache hit rate
5. **Solution:** Per-key lock to protect check-then-act sequence

**The race condition is real and confirmed.**
