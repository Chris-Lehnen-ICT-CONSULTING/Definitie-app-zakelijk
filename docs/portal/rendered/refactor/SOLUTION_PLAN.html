<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Test Suite Recovery Solution Plan</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">‚Üê Terug naar Portal</a>
    <h1>Test Suite Recovery Solution Plan</h1>

<p><strong>Status</strong>: üî¥ ACTIEF</p>
<p><strong>Datum</strong>: 2025-09-19</p>
<p><strong>Scope</strong>: Test suite reparatie en architectuur verbetering</p>
<p><strong>Impact</strong>: 31 gefaalde tests, architectuur inconsistenties</p>

<h2>Executive Summary</h2>

<p>Dit document beschrijft een incrementele oplossing voor de test suite problemen in de DefinitieAgent applicatie. De hoofdoorzaak is een inconsistente ValidationResult interface tussen verschillende modules, gecombineerd met architecturele schendingen (Streamlit dependencies in service layer) en ontbrekende test utilities.</p>

<h2>1. SOLUTION ARCHITECTURE</h2>

<h3>1.1 ValidationResult Interface Standaardisatie</h3>

<p><strong>Probleem</strong>: Meerdere incompatibele ValidationResult implementaties:</p>
<ul>
<li>`src/services/validation/interfaces.py`: TypedDict implementatie (modern)</li>
<li>`src/services/interfaces.py`: @dataclass implementatie (legacy)</li>
<li>`src/validation/`: Aparte result classes per validator type</li>
<li>`src/services/validation/astra_validator.py`: Eigen ValidationResult class</li>
</ul>

<p><strong>Oplossing</strong>: Unificeer naar single source of truth met adapter pattern</p>

<pre><code># Centraal interface contract (TypedDict-based)
ValidationResult = services.validation.interfaces.ValidationResult

# Legacy adapter voor backward compatibility tijdens refactor
class ValidationResultAdapter:
    """Converts between TypedDict and dataclass representations"""

    @staticmethod
    def from_dataclass(dc_result) -&gt; ValidationResult:
        """Convert dataclass to TypedDict format"""

    @staticmethod
    def to_dataclass(dict_result) -&gt; DataclassValidationResult:
        """Convert TypedDict to dataclass format"""</code></pre>

<h3>1.2 Streamlit Dependency Isolation</h3>

<p><strong>Probleem</strong>: Service layer importeert Streamlit direct:</p>
<ul>
<li>`src/services/service_factory.py`: gebruikt st.cache_data</li>
<li>Tests falen omdat MockStreamlit cache_data niet implementeert</li>
</ul>

<p><strong>Oplossing</strong>: Abstract caching naar cache utilities layer</p>

<pre><code># utils/cache.py uitbreiden met service caching
@cache_service_instance
def get_cached_service(service_class, *args, **kwargs):
    """Cache service instances zonder Streamlit dependency"""
    return service_class(*args, **kwargs)

# services/service_factory.py refactoren
from utils.cache import cache_service_instance
# NIET: import streamlit as st</code></pre>

<h3>1.3 Import Path Restructuring</h3>

<p><strong>Probleem</strong>: ModernWebLookupService niet vindbaar in tests</p>

<p><strong>Oplossing</strong>: Centraliseer service exports</p>

<pre><code># src/services/__init__.py
from .web_lookup.modern_web_lookup_service import ModernWebLookupService
__all__ = [..., "ModernWebLookupService"]</code></pre>

<h2>2. IMPLEMENTATION ROADMAP</h2>

<h3>Fase 1: Quick Wins (2-4 uur) ‚úÖ</h3>

<p><strong>Doel</strong>: Krijg test suite weer werkend met minimale wijzigingen</p>

<ol>
<li>**MockStreamlit cache_data toevoegen** [30 min]</li>
<pre><code>   # tests/mocks/streamlit_mock.py
   def cache_data(func):
       return func  # Simple passthrough for tests</code></pre>
</ol>

<ol>
<li>**ValidationResult wrapper fix** [1 uur]</li>
<pre><code>   # src/services/validation/modular_validation_service.py
   class ValidationResultWrapper:
       @property
       def status(self):
           return "valid" if self.is_valid else "invalid"</code></pre>
</ol>

<ol>
<li>**Import paths fixen** [30 min]</li>
</ol>
<ul>
<li>  - Update `src/services/__init__.py` met alle service exports</li>
<li>  - Fix relative imports in test files</li>
</ul>

<ol>
<li>**Ontbrekende test files toevoegen** [1 uur]</li>
</ol>
<ul>
<li>  - `tests/unit/test_modern_web_lookup_service.py`</li>
<li>  - `tests/unit/test_validation_result_wrapper.py`</li>
</ul>

<p><strong>Verificatie</strong>: <code>pytest -x</code> moet zonder fatale errors draaien</p>

<h3>Fase 2: Structural Fixes (1-2 dagen) üîÑ</h3>

<p><strong>Doel</strong>: Elimineer architecturele schendingen en verenig interfaces</p>

<ol>
<li>**Service Factory Refactoring** [4 uur]</li>
</ol>
<ul>
<li>  - Verwijder alle Streamlit imports uit service layer</li>
<li>  - Migreer naar utils.cache voor caching</li>
<li>  - Implementeer proper dependency injection</li>
</ul>

<ol>
<li>**ValidationResult Unificatie** [4 uur]</li>
</ol>
<ul>
<li>  - Maak centrale ValidationResult TypedDict leading</li>
<li>  - Implementeer adapters voor legacy code</li>
<li>  - Update alle validators om consistent interface te gebruiken</li>
</ul>

<ol>
<li>**Test Infrastructure** [2 uur]</li>
</ol>
<ul>
<li>  - Centraliseer test fixtures in `tests/fixtures/`</li>
<li>  - Maak reusable mock factories</li>
<li>  - Documenteer test patterns</li>
</ul>

<p><strong>Verificatie</strong>:</p>
<ul>
<li>`pytest --cov=src` > 60% coverage</li>
<li>Geen Streamlit imports buiten UI layer</li>
</ul>

<h3>Fase 3: Quality Improvements (2-3 dagen) üéØ</h3>

<p><strong>Doel</strong>: Robuuste test suite met goede coverage</p>

<ol>
<li>**Comprehensive Test Coverage** [8 uur]</li>
</ol>
<ul>
<li>  - Schrijf missende unit tests voor alle services</li>
<li>  - Voeg integration tests toe voor orchestrators</li>
<li>  - Implementeer property-based testing voor validators</li>
</ul>

<ol>
<li>**Test Performance** [4 uur]</li>
</ol>
<ul>
<li>  - Parallelliseer test execution met pytest-xdist</li>
<li>  - Implementeer test result caching</li>
<li>  - Optimaliseer slow tests met mocking</li>
</ul>

<ol>
<li>**Documentation & Standards** [4 uur]</li>
</ol>
<ul>
<li>  - Documenteer test patterns in `docs/testing/TEST_PATTERNS.md`</li>
<li>  - Voeg test writing guidelines toe</li>
<li>  - Maak test coverage dashboard</li>
</ul>

<p><strong>Verificatie</strong>:</p>
<ul>
<li>`pytest` < 30 seconden voor volledige suite</li>
<li>Coverage > 75%</li>
<li>Alle tests groen</li>
</ul>

<h2>3. TECHNICAL SPECIFICATIONS</h2>

<h3>3.1 Concrete Interface Designs</h3>

<pre><code># src/services/validation/unified_interface.py
from typing import Protocol, TypedDict, runtime_checkable

class ValidationResult(TypedDict):
    """Canonical ValidationResult interface"""
    version: str
    overall_score: float
    is_acceptable: bool
    violations: list[dict]
    # ... full spec from interfaces.py

@runtime_checkable
class ValidationResultLike(Protocol):
    """Protocol for duck-typed validation results"""
    @property
    def is_valid(self) -&gt; bool: ...
    @property
    def violations(self) -&gt; list: ...</code></pre>

<h3>3.2 Mock Implementations</h3>

<pre><code># tests/mocks/validation_mocks.py
class MockValidationResult:
    """Test-friendly validation result"""
    def __init__(self, is_valid=True, violations=None):
        self._data = {
            'is_acceptable': is_valid,
            'violations': violations or [],
            'overall_score': 1.0 if is_valid else 0.0
        }

    @property
    def status(self):
        return "valid" if self._data['is_acceptable'] else "invalid"

    def __getitem__(self, key):
        return self._data[key]</code></pre>

<h3>3.3 Directory Structure Changes</h3>

<pre><code>tests/
‚îú‚îÄ‚îÄ fixtures/              # NEW: Centralized test fixtures
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ validation.py     # Validation result fixtures
‚îÇ   ‚îú‚îÄ‚îÄ services.py       # Service mocks
‚îÇ   ‚îî‚îÄ‚îÄ data.py          # Test data generators
‚îú‚îÄ‚îÄ mocks/
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_mock.py # UPDATED: Add cache_data
‚îÇ   ‚îî‚îÄ‚îÄ validation_mocks.py # NEW: Validation mocks
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_modern_web_lookup_service.py # NEW
‚îÇ   ‚îî‚îÄ‚îÄ validation/
‚îÇ       ‚îî‚îÄ‚îÄ test_validation_result_wrapper.py # NEW
‚îî‚îÄ‚îÄ integration/
    ‚îî‚îÄ‚îÄ test_validation_flow.py # NEW: E2E validation test</code></pre>

<h2>4. MIGRATION STRATEGY</h2>

<h3>4.1 Incremental Migration Approach</h3>

<p>Deze applicatie is NIET in productie - geen backwards compatibility nodig!</p>

<ol>
<li>**Direct Refactor** (AANBEVOLEN)</li>
</ol>
<ul>
<li>  - Pas interfaces direct aan</li>
<li>  - Update alle consumers tegelijk</li>
<li>  - Geen migration paths of feature flags</li>
</ul>

<ol>
<li>**Test-First Migration**</li>
</ol>
<ul>
<li>  - Fix tests eerst met minimal changes</li>
<li>  - Refactor code met werkende tests als safety net</li>
<li>  - Verwijder legacy code zodra nieuwe implementatie werkt</li>
</ul>

<h3>4.2 Test Suite Update Plan</h3>

<pre><code># Stap 1: Fix immediate blockers
pytest -x  # Stop bij eerste failure
# Fix MockStreamlit
# Fix ValidationResult.status

# Stap 2: Identificeer remaining failures
pytest --tb=short &gt; test_failures.txt
# Categoriseer per root cause

# Stap 3: Fix per category
pytest tests/unit/services/ -x  # Fix service tests
pytest tests/unit/validation/ -x # Fix validation tests

# Stap 4: Verify full suite
pytest --cov=src --cov-report=term-missing</code></pre>

<h3>4.3 Validation Approach</h3>

<p><strong>Automated Validation</strong>:</p>
<pre><code># scripts/validate_refactor.sh
#!/bin/bash
echo "Checking for Streamlit imports in service layer..."
grep -r "import streamlit" src/services/ &amp;&amp; exit 1

echo "Verifying ValidationResult consistency..."
python scripts/check_validation_interfaces.py

echo "Running test suite..."
pytest -q

echo "Checking coverage..."
pytest --cov=src --cov-fail-under=60</code></pre>

<h2>5. RISK MITIGATION</h2>

<h3>5.1 Potential Breaking Changes</h3>

<p>| Risk | Impact | Mitigation |</p>
<p>|------|--------|------------|</p>
<p>| ValidationResult interface change | HIGH | Use adapter pattern tijdens transitie |</p>
<p>| Service caching verandering | MEDIUM | Test performance voor/na |</p>
<p>| Import path wijzigingen | LOW | Update all imports atomically |</p>

<h3>5.2 Rollback Procedures</h3>

<p><strong>Git-based Rollback</strong> (Single-user app):</p>
<pre><code># Tag current state
git tag pre-refactor-$(date +%Y%m%d)

# If rollback needed
git reset --hard pre-refactor-20250119</code></pre>

<h3>5.3 Test Verification Steps</h3>

<p><strong>Pre-refactor Baseline</strong>:</p>
<pre><code># Capture current state
pytest --json-report --json-report-file=baseline.json
python scripts/analyze_test_failures.py &gt; baseline_analysis.txt</code></pre>

<p><strong>Post-refactor Verification</strong>:</p>
<pre><code># Verify improvements
pytest --json-report --json-report-file=post_refactor.json
python scripts/compare_test_results.py baseline.json post_refactor.json

# Expected outcomes:
# - Failed tests: 31 -&gt; 0
# - Coverage: &gt;60%
# - No Streamlit imports in services/</code></pre>

<h2>6. IMPLEMENTATION CHECKLIST</h2>

<h3>Phase 1: Quick Wins ‚úÖ</h3>
<ul>
<li>[ ] Add cache_data to MockStreamlit</li>
<li>[ ] Fix ValidationResult.status property</li>
<li>[ ] Update import paths in __init__ files</li>
<li>[ ] Create missing test files</li>
<li>[ ] Run `pytest -x` successfully</li>
</ul>

<h3>Phase 2: Structural Fixes üîÑ</h3>
<ul>
<li>[ ] Remove Streamlit from service_factory.py</li>
<li>[ ] Implement ValidationResultAdapter</li>
<li>[ ] Unify ValidationResult interfaces</li>
<li>[ ] Create test fixtures directory</li>
<li>[ ] Achieve 60% test coverage</li>
</ul>

<h3>Phase 3: Quality Improvements üéØ</h3>
<ul>
<li>[ ] Write comprehensive unit tests</li>
<li>[ ] Add integration tests</li>
<li>[ ] Optimize test performance</li>
<li>[ ] Document test patterns</li>
<li>[ ] Achieve 75% coverage</li>
</ul>

<h2>7. SUCCESS CRITERIA</h2>

<p>‚úÖ <strong>Immediate Success</strong> (Fase 1):</p>
<ul>
<li>Test suite draait zonder fatale errors</li>
<li>MockStreamlit volledig functioneel</li>
<li>ValidationResult.status werkt overal</li>
</ul>

<p>‚úÖ <strong>Structural Success</strong> (Fase 2):</p>
<ul>
<li>Geen Streamlit dependencies in service layer</li>
<li>Single ValidationResult interface</li>
<li>60% test coverage</li>
</ul>

<p>‚úÖ <strong>Quality Success</strong> (Fase 3):</p>
<ul>
<li>75% test coverage</li>
<li>Test suite < 30 seconden</li>
<li>Alle architectuur violations opgelost</li>
</ul>

<h2>APPENDICES</h2>

<h3>A. Affected Files List</h3>

<p><strong>Critical Files</strong> (moet direct gefixed):</p>
<ul>
<li>`tests/mocks/streamlit_mock.py`</li>
<li>`src/services/validation/modular_validation_service.py`</li>
<li>`src/services/service_factory.py`</li>
</ul>

<p><strong>Refactor Targets</strong> (fase 2):</p>
<ul>
<li>`src/services/interfaces.py`</li>
<li>`src/services/validation/interfaces.py`</li>
<li>`src/validation/*.py`</li>
</ul>

<h3>B. Command Reference</h3>

<pre><code># Quick test commands
make test                    # Run full test suite
pytest -x                   # Stop on first failure
pytest --lf                 # Run last failed
pytest -k "validation"      # Run validation tests only

# Coverage analysis
pytest --cov=src --cov-report=html
open htmlcov/index.html

# Performance profiling
pytest --profile-svg</code></pre>

<h3>C. Related Documentation</h3>

<ul>
<li>`docs/architectuur/TECHNICAL_ARCHITECTURE.md` - System architecture</li>
<li>`docs/testing/validation_orchestrator_testplan.md` - Test strategy</li>
<li>`~/.ai-agents/UNIFIED_INSTRUCTIONS.md` - Development guidelines</li>
<li>`~/.ai-agents/quality-gates.yaml` - Quality requirements</li>
</ul>

<p>---</p>

<p><strong>Next Steps</strong>: Begin met Fase 1 Quick Wins om test suite direct werkend te krijgen, daarna incrementeel verbeteren volgens dit plan.</p>
  </div>
</body>
</html>