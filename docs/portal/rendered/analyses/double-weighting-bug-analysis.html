<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Double-Weighting Bug Analysis - Quality Gate Implementation</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">← Terug naar Portal</a>
    <h1>Double-Weighting Bug Analysis - Quality Gate Implementation</h1>

<p><strong>Date</strong>: 2025-10-09</p>
<p><strong>Author</strong>: Claude Code</p>
<p><strong>Status</strong>: RESOLVED</p>
<p><strong>Severity</strong>: HIGH (Test Failure)</p>

<h2>Executive Summary</h2>

<p>After implementing quality-gated juridical boost (FASE 3), the test <code>test_ranking_relevance_based</code> failed. The root cause was <strong>double-weighting of provider weights</strong> - confidence scores were being multiplied by provider weights twice: once during lookup and once during ranking. This caused Wikipedia (weighted 0.85) to be unfairly penalized compared to Overheid.nl (weighted 1.0).</p>

<h2>Problem Statement</h2>

<h3>Expected Behavior</h3>
<pre><code>Wikipedia:   0.8 (base) × 0.85 (weight) = 0.68 final score
Overheid.nl: 0.6 (base) × 1.10 (boost) × 1.0 (weight) = 0.66 final score
Result: Wikipedia wins (0.68 &gt; 0.66) ✅</code></pre>

<h3>Actual Behavior</h3>
<pre><code>Wikipedia:   0.8 × 0.85 (in lookup) × 0.85 (in ranking) = 0.578 ❌
Overheid.nl: 0.6 × 1.10 (boost) × 1.0 (in ranking) = 0.66
Result: Overheid.nl wins (0.66 &gt; 0.578) ❌</code></pre>

<h2>Root Cause Analysis</h2>

<h3>Data Flow Trace</h3>

<ol>
<li>**Step 1: Lookup** (`_lookup_mediawiki`, `_lookup_sru`, etc.)</li>
</ol>
<ul>
<li>  - Raw Wikipedia result: confidence = 0.8</li>
<li>  - **FIRST WEIGHT APPLICATION**: `result.source.confidence *= source.confidence_weight`</li>
<li>  - Wikipedia confidence becomes: 0.8 × 0.85 = **0.68** ❌</li>
</ul>

<ol>
<li>**Step 2: Juridical Boost** (`boost_juridische_resultaten`)</li>
</ol>
<ul>
<li>  - Wikipedia: 0.68 (no boost, not juridical)</li>
<li>  - Overheid.nl: 0.6 × 1.10 = **0.66** (quality gate applied correctly)</li>
</ul>

<ol>
<li>**Step 3: Contract Conversion** (`_to_contract_dict`)</li>
</ol>
<ul>
<li>  - Wikipedia: score = 0.68 (already weighted once)</li>
<li>  - Overheid.nl: score = 0.66</li>
</ul>

<ol>
<li>**Step 4: Ranking** (`rank_and_dedup` → `_final_score`)</li>
</ol>
<ul>
<li>  - **SECOND WEIGHT APPLICATION**: `final = provider_weight × base_score`</li>
<li>  - Wikipedia: 0.68 × 0.85 = **0.578** ❌ (double-weighted!)</li>
<li>  - Overheid.nl: 0.66 × 1.0 = **0.66** ✅</li>
</ul>

<ol>
<li>**Result**: Overheid.nl wins despite lower relevance</li>
</ol>

<h3>The Bug</h3>

<p>Provider weights were applied in <strong>two separate places</strong>:</p>

<pre><code># LOCATION 1: In lookup methods (modern_web_lookup_service.py)
async def _lookup_mediawiki(...):
    # ... fetch result ...
    if result and result.success:
        result.source.confidence *= source.confidence_weight  # ❌ FIRST WEIGHT
        return result

# LOCATION 2: In ranking (ranking.py)
def _final_score(item, provider_weights):
    w = provider_weights.get(item.get("provider", ""), 1.0)
    base = float(item.get("score", 0.0))
    return w * base  # ❌ SECOND WEIGHT (using same weights!)</code></pre>

<h3>Why This Happened</h3>

<p>The system evolved organically:</p>
<ul>
<li>Originally, lookup methods applied weights (single-source use case)</li>
<li>Later, ranking module was added with cross-source comparison (multi-source use case)</li>
<li>Both used the same `provider_weights` mapping</li>
<li>No one noticed the double application because tests didn't compare weighted vs non-weighted sources</li>
</ul>

<h2>Solution</h2>

<h3>Design Decision: Weight Only in Ranking</h3>

<p>We removed weight application from <strong>all lookup methods</strong> and applied weights <strong>only in ranking</strong>:</p>

<p><strong>Rationale</strong>:</p>
<ul>
<li>Ranking is the natural place for cross-source comparison</li>
<li>Lookup methods return "pure" confidence scores (easier to debug)</li>
<li>Single responsibility: lookup = fetch, ranking = compare</li>
<li>Easier to test (mocks can return simple confidence values)</li>
</ul>

<h3>Code Changes</h3>

<h4>File: `src/services/modern_web_lookup_service.py`</h4>

<p><strong>Changed 6 locations</strong> (all lookup methods):</p>

<pre><code># BEFORE (wrong - double weight)
if result and result.success:
    result.source.confidence *= source.confidence_weight  # ❌
    return result

# AFTER (correct - no weight in lookup)
if result and result.success:
    # NOTE: Provider weight applied in ranking, not here
    # to avoid double-weighting (Oct 2025)
    return result</code></pre>

<p><strong>Locations changed</strong>:</p>
<ol>
<li>`_lookup_mediawiki` - Wikipedia branch (line ~602)</li>
<li>`_lookup_mediawiki` - Wiktionary branch (line ~680)</li>
<li>`_lookup_sru` - Main stage loop (line ~758)</li>
<li>`_lookup_sru` - Fallback loop (line ~785, kept 0.95 penalty)</li>
<li>`_lookup_rest` - Rechtspraak lookup (line ~828)</li>
<li>`_lookup_brave` - Brave Search lookup (line ~906)</li>
</ol>

<p><strong>Note</strong>: In <code>_lookup_sru</code> fallback (line 789), we kept the 0.95 penalty but removed the provider weight:</p>
<pre><code># Fallback penalty (intrinsic quality reduction)
r.source.confidence *= 0.95  # ✅ Keep (not provider weight)
return r</code></pre>

<h2>Verification</h2>

<h3>Debug Test Output</h3>

<p>Created temporary debug test (<code>tests/debug_ranking_test.py</code>) that traced complete flow:</p>

<pre><code>================================================================================
STEP 1: LOOKUP RAW RESULTS
================================================================================
Wikipedia raw result:
  confidence: 0.8     ✅ No provider weight applied

Overheid.nl raw result:
  confidence: 0.6     ✅ No provider weight applied

================================================================================
STEP 2: JURIDICAL BOOST APPLICATION
================================================================================
Before boost:
  Wikipedia: confidence=0.800
  Overheid.nl: confidence=0.600

After boost:
  Wikipedia: confidence=0.800    ✅ No boost (not juridical)
  Overheid.nl: confidence=0.660  ✅ Quality gate: 0.6 × 1.10 = 0.66

================================================================================
STEP 4: APPLY PROVIDER WEIGHTS &amp; RANKING
================================================================================
Final scores (before ranking):
  Wikipedia:
    base_score: 0.800
    weight: 0.850
    final_score: 0.680 (= 0.800 × 0.850)  ✅ Single weight application

  Overheid.nl:
    base_score: 0.660
    weight: 1.000
    final_score: 0.660 (= 0.660 × 1.000)  ✅ Single weight application

================================================================================
RESULT: Wikipedia wins (0.68 &gt; 0.66) ✅
================================================================================</code></pre>

<h3>Test Results</h3>

<pre><code>$ pytest tests/services/test_modern_web_lookup_service_unit.py::test_ranking_relevance_based -v

============================== 1 passed in 0.11s ===============================</code></pre>

<p>All 3 tests in the file pass:</p>
<ul>
<li>`test_parallel_lookup_concurrency_and_timeout` ✅</li>
<li>`test_error_handling_returns_empty_results` ✅</li>
<li>`test_ranking_relevance_based` ✅ (was failing, now passes)</li>
</ul>

<h2>Impact Analysis</h2>

<h3>Changed Behavior</h3>

<p><strong>Before Fix</strong> (double-weighted):</p>
<ul>
<li>Wikipedia results: confidence × 0.85 × 0.85 = **0.7225×** original</li>
<li>Overheid.nl results: confidence × 1.0 × 1.0 = **1.0×** original</li>
<li>Bias: 38% penalty for Wikipedia!</li>
</ul>

<p><strong>After Fix</strong> (single-weighted):</p>
<ul>
<li>Wikipedia results: confidence × 0.85 = **0.85×** original</li>
<li>Overheid.nl results: confidence × 1.0 = **1.0×** original</li>
<li>Bias: 15% penalty for Wikipedia (as intended)</li>
</ul>

<h3>Affected Components</h3>

<ol>
<li>**All provider lookups** - Now return pure confidence scores</li>
<li>**Ranking module** - Single source of truth for provider weighting</li>
<li>**Tests** - Updated mocks to return realistic data</li>
</ol>

<h3>Backward Compatibility</h3>

<p><strong>Breaking change</strong>: Yes, but acceptable because:</p>
<ul>
<li>This is a single-user application (not in production)</li>
<li>Bug caused incorrect behavior (high-quality sources were unfairly penalized)</li>
<li>Quality gate implementation depends on correct weighting</li>
<li>No backwards compatibility required per project policy</li>
</ul>

<h2>Lessons Learned</h2>

<h3>Design Principles Violated</h3>

<ol>
<li>**DRY with hidden coupling**: `provider_weights` used in 2 places, but coupling not documented</li>
<li>**Single Responsibility**: Lookup methods both fetched AND scored results</li>
<li>**Lack of integration tests**: No test compared weighted vs non-weighted sources</li>
<li>**Implicit contracts**: Weight application not clearly documented in interfaces</li>
</ol>

<h3>Prevention Strategies</h3>

<ol>
<li>**Document data flow** - Add comments about where transformations happen</li>
<li>**Integration tests** - Test cross-provider ranking with different weights</li>
<li>**Explicit contracts** - Clearly document whether returned confidence is "raw" or "weighted"</li>
<li>**Single transformation location** - Apply transformations (like weighting) in exactly ONE place</li>
</ol>

<h3>Code Quality Improvements</h3>

<p>Added clear documentation in code:</p>
<pre><code># NOTE: Provider weight applied in ranking, not here
# to avoid double-weighting (Oct 2025)</code></pre>

<p>This prevents future developers from "fixing" the "missing" weight application.</p>

<h2>Related Work</h2>

<ul>
<li>**EPIC-003**: Web Lookup Phase 2 - Provider prioritization</li>
<li>**US-151**: Quality-gated juridical boost (triggered this bug)</li>
<li>**Issue**: `test_ranking_relevance_based` failure (resolved)</li>
</ul>

<h2>Recommendations</h2>

<h3>Short-term (Completed)</h3>

<ol>
<li>✅ Remove weight application from all lookup methods</li>
<li>✅ Update tests to verify single-weight application</li>
<li>✅ Document weight application location in code comments</li>
<li>✅ Verify quality gate works correctly with fix</li>
</ol>

<h3>Long-term</h3>

<ol>
<li>**Refactor confidence scoring** - Create explicit `RawConfidence` vs `WeightedScore` types</li>
<li>**Add property tests** - Verify score transformations are monotonic and bounded</li>
<li>**Integration test suite** - Test ranking across all provider combinations</li>
<li>**Architecture documentation** - Document data flow from lookup → boost → ranking</li>
</ol>

<h2>Appendix: Full Test Scenario</h2>

<h3>Test Setup</h3>
<pre><code># Wikipedia: High-quality relevant non-juridical
make_result(
    "Wikipedia",
    "https://nl.wikipedia.org/wiki/Kracht_van_gewijsde",
    0.8,      # Good base score
    False,    # Not juridical, but relevant
    "Kracht van gewijsde betekent onherroepelijk"
)

# Overheid.nl: Low-quality irrelevant juridical
make_result(
    "Overheid.nl",
    "https://wetten.overheid.nl/BES-wetgeving",
    0.6,      # Lower score (low relevance)
    True,     # Juridical, but not relevant
    "BES wetgeving paragraaf 3.2"
)</code></pre>

<h3>Expected Flow</h3>
<ol>
<li>**Lookup**: Wikipedia 0.8, Overheid.nl 0.6 (raw scores)</li>
<li>**Boost**: Wikipedia 0.8 (no boost), Overheid.nl 0.66 (quality-gated 1.10×)</li>
<li>**Ranking**: Wikipedia 0.68 (0.8 × 0.85), Overheid.nl 0.66 (0.66 × 1.0)</li>
<li>**Result**: Wikipedia wins ✅</li>
</ol>

<h3>Config Dependencies</h3>
<pre><code># config/web_lookup_defaults.yaml
providers:
  wikipedia:
    weight: 0.85  # Slightly penalized (not authoritative)
  sru_overheid:
    weight: 1.0   # Full authority weight

juridical_boost:
  quality_gate:
    enabled: true
    min_base_score: 0.65        # Only boost high-quality sources
    reduced_boost_factor: 0.5   # 50% boost if below threshold</code></pre>

<h2>Conclusion</h2>

<p>The double-weighting bug was a subtle but critical issue caused by applying provider weights in multiple locations. By centralizing weight application to the ranking module, we:</p>

<ol>
<li>Fixed the immediate test failure ✅</li>
<li>Simplified the codebase (single responsibility) ✅</li>
<li>Made debugging easier (pure confidence in lookups) ✅</li>
<li>Enabled quality gate to work correctly ✅</li>
</ol>

<p>The fix aligns with the principle: <strong>"Autoriteit moet verdient worden met kwaliteit"</strong> - provider weights now correctly compare sources without unfair double-penalty.</p>

  </div>
</body>
</html>