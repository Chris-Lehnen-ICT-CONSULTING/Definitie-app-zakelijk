<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DEF-126: Context Injection Consolidation - Implementation Plan</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>DEF-126: Context Injection Consolidation - Implementation Plan</h1>

<h2>Executive Summary</h2>

<p><strong>Problem:</strong> Context instructions are scattered across 3 modules (ContextAwarenessModule, ErrorPreventionModule, DefinitionTaskModule), resulting in ~380 tokens of redundancy and inconsistent data access patterns.</p>

<p><strong>Solution:</strong> Consolidate ALL context-related output into a single <code>ContextInstructionModule</code> that serves as the Single Source of Truth for context guidance.</p>

<p><strong>Expected Impact:</strong></p>
<ul>
<li>50-65% token reduction (~200-250 tokens saved)</li>
<li>Single source of truth for context instructions</li>
<li>Consistent data access pattern</li>
<li>Improved maintainability</li>
</ul>

<p><strong>Implementation Effort:</strong> 4-5 hours</p>

<p>---</p>

<h2>1. PROBLEM ANALYSIS âœ…</h2>

<h3>Current State - 3 Modules Handling Context</h3>

<p>| Module | File | Lines | Responsibility | Token Cost | Data Access |</p>
<p>|--------|------|-------|----------------|------------|-------------|</p>
<p>| <strong>ContextAwarenessModule</strong> | <code>context_awareness_module.py</code> | 186-280, 368-395 | Context formatting & sharing | ~200 | enriched_context |</p>
<p>| <strong>ErrorPreventionModule</strong> | <code>error_prevention_module.py</code> | 75-79, 95-100, 193-245 | Context-specific forbidden patterns | ~100 | shared_state |</p>
<p>| <strong>DefinitionTaskModule</strong> | <code>definition_task_module.py</code> | 84-104, 204, 206-299 | Context metadata & checklist | ~80 | base_context (DIRECT) |</p>
<p>| <strong>TOTAL</strong> | 3 files | ~150 lines | Scattered responsibility | <strong>~380 tokens</strong> | <strong>Inconsistent</strong> |</p>

<h3>Key Issues</h3>

<ol>
<li>**No Single Source of Truth**</li>
</ol>
<ul>
<li>  - Context instructions generated in 3 different places</li>
<li>  - Same context data listed 2-3 times in prompt</li>
<li>  - No coordination between modules</li>
</ul>

<ol>
<li>**Inconsistent Data Access Patterns**</li>
</ol>
<ul>
<li>  - ContextAwarenessModule: Reads `enriched_context`, writes `shared_state`</li>
<li>  - ErrorPreventionModule: Reads `shared_state` (depends on context_awareness)</li>
<li>  - DefinitionTaskModule: Reads `base_context` DIRECTLY (ignores shared_state!)</li>
</ul>

<ol>
<li>**Underutilized Context Richness Score**</li>
</ol>
<ul>
<li>  - ContextAwarenessModule calculates `context_richness_score` (0.0-1.0)</li>
<li>  - Score is stored in shared_state but ONLY used by ContextAwarenessModule itself</li>
<li>  - Other modules don't adapt output based on context quality</li>
</ul>

<ol>
<li>**Hardcoded Organization Mappings**</li>
</ol>
<ul>
<li>  - ErrorPreventionModule has hardcoded org mappings (lines 209-219)</li>
<li>  - Not reusable, not centralized</li>
<li>  - Difficult to maintain</li>
</ul>

<h3>Evidence from Code Analysis</h3>

<p><strong>ContextAwarenessModule (lines 368-395):</strong></p>
<pre><code>def _share_traditional_context(self, context: ModuleContext) -&gt; None:
    """Deel alle actieve context types voor andere modules."""
    # Shares: organization_contexts, juridical_contexts, legal_basis_contexts
    context.set_shared("organization_contexts", org_contexts)
    context.set_shared("juridical_contexts", jur_contexts)
    context.set_shared("legal_basis_contexts", wet_contexts)</code></pre>

<p><strong>ErrorPreventionModule (lines 75-79):</strong></p>
<pre><code># Haal context informatie op van ContextAwarenessModule
org_contexts = context.get_shared("organization_contexts", [])
jur_contexts = context.get_shared("juridical_contexts", [])
wet_contexts = context.get_shared("legal_basis_contexts", [])</code></pre>

<p><strong>DefinitionTaskModule (lines 84-98):</strong></p>
<pre><code># Derive juridical and legal-basis contexts from enriched base_context
base_ctx = context.enriched_context.base_context if context and context.enriched_context else {}
jur_contexts = base_ctx.get("juridische_context") or base_ctx.get("juridisch") or []
wet_basis = base_ctx.get("wettelijke_basis") or base_ctx.get("wettelijk") or []
# âš ï¸ INCONSISTENT: Reads directly from base_context, ignores shared_state!</code></pre>

<p>---</p>

<h2>2. SOLUTION ARCHITECTURE</h2>

<h3>Design: Single Source of Truth Pattern</h3>

<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   NEW: ContextInstructionModule              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ SINGLE SOURCE OF TRUTH for ALL context instructions  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  Responsibilities:                                          â”‚
â”‚  âœ“ Calculate context_richness_score (from ContextAwareness)â”‚
â”‚  âœ“ Generate adaptive context instructions                  â”‚
â”‚  âœ“ Generate context-specific forbidden patterns           â”‚
â”‚  âœ“ Generate context metadata                              â”‚
â”‚  âœ“ Centralize organization mappings                       â”‚
â”‚  âœ“ Share via shared_state for other modules              â”‚
â”‚                                                              â”‚
â”‚  Priority: 75 (high - context is foundational)             â”‚
â”‚  Dependencies: NONE (reads enriched_context directly)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â†“
                    Shares via shared_state:
                    - context_richness_score
                    - organization_contexts
                    - juridical_contexts
                    - legal_basis_contexts
                                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            OTHER MODULES (simplified)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ContextAwarenessModule: DELETED (logic moved)        â”‚  â”‚
â”‚  â”‚ ErrorPreventionModule: Context logic REMOVED         â”‚  â”‚
â”‚  â”‚ DefinitionTaskModule: Context metadata REMOVED       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>

<h3>Module Responsibilities After Refactor</h3>

<h4>ContextInstructionModule (NEW) âœ¨</h4>
<p><strong>Single responsibility:</strong> Generate ALL context-related prompt content</p>

<p><strong>What it does:</strong></p>
<ol>
<li>**Context Richness Scoring** (from ContextAwarenessModule)</li>
</ol>
<ul>
<li>  - Calculate score: 0.0-1.0 based on base_context, sources, expanded_terms</li>
<li>  - Adaptive output based on score</li>
</ul>

<ol>
<li>**Context Instructions** (from ContextAwarenessModule)</li>
</ol>
<ul>
<li>  - Rich (â‰¥0.8): "ğŸ“Š UITGEBREIDE CONTEXT ANALYSE"</li>
<li>  - Moderate (0.5-0.8): "ğŸ“Œ VERPLICHTE CONTEXT INFORMATIE"</li>
<li>  - Minimal (<0.5): "ğŸ“ VERPLICHTE CONTEXT"</li>
</ul>

<ol>
<li>**Context-Specific Forbidden Patterns** (from ErrorPreventionModule)</li>
</ol>
<ul>
<li>  - Organization mappings (NP â†’ Nederlands Politie)</li>
<li>  - Generate "ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN" section</li>
</ul>

<ol>
<li>**Context Metadata** (from DefinitionTaskModule)</li>
</ol>
<ul>
<li>  - Prompt metadata footer with context listings</li>
</ul>

<p><strong>What it shares:</strong></p>
<ul>
<li>`context_richness_score` (float)</li>
<li>`organization_contexts` (list)</li>
<li>`juridical_contexts` (list)</li>
<li>`legal_basis_contexts` (list)</li>
</ul>

<h4>ContextAwarenessModule (DELETED) âŒ</h4>
<p><strong>Action:</strong> DELETE entire file - logic moved to ContextInstructionModule</p>

<p><strong>Rationale:</strong></p>
<ul>
<li>All business logic migrated to ContextInstructionModule</li>
<li>No remaining purpose after consolidation</li>
<li>Simplifies architecture (one less module)</li>
</ul>

<h4>ErrorPreventionModule (REFACTORED) ğŸ”§</h4>
<p><strong>Keep:</strong> General error prevention (forbidden starters, validation matrix)</p>
<p><strong>Remove:</strong> All context-specific logic (lines 75-79, 95-100, 193-245)</p>

<p><strong>What remains:</strong></p>
<ul>
<li>`_build_basic_errors()` - âŒ "Begin niet met lidwoorden", etc.</li>
<li>`_build_forbidden_starters()` - âŒ "Start niet met 'is', 'betreft'", etc.</li>
<li>`_build_validation_matrix()` - Validation table</li>
<li>Final warning: "ğŸš« Let op: context en bronnen mogen niet letterlijk..."</li>
</ul>

<p><strong>What is removed:</strong></p>
<ul>
<li>Context retrieval from shared_state (lines 75-79)</li>
<li>`_build_context_forbidden()` method (lines 193-245)</li>
<li>Organization mappings (lines 209-219)</li>
<li>Context-specific verboden section (lines 95-100)</li>
</ul>

<h4>DefinitionTaskModule (REFACTORED) ğŸ”§</h4>
<p><strong>Keep:</strong> Final instructions, checklist, quality control</p>
<p><strong>Remove:</strong> Context metadata, context-aware adaptations (lines 84-104, 259-299)</p>

<p><strong>What remains:</strong></p>
<ul>
<li>`_build_task_assignment()` - âœï¸ Definitieopdracht</li>
<li>`_build_checklist()` - ğŸ“‹ CONSTRUCTIE GUIDE (simplified, no context mention)</li>
<li>`_build_quality_control()` - ğŸ” KWALITEITSCONTROLE (generic version)</li>
<li>`_build_ontological_marker()` - ğŸ“‹ Ontologische marker</li>
<li>`_build_final_instruction()` - âœï¸ Geef nu de definitie</li>
</ul>

<p><strong>What is removed:</strong></p>
<ul>
<li>Context detection logic (lines 84-104)</li>
<li>Context-aware quality control adaptation (lines 206-223)</li>
<li>`_build_metadata()` method (lines 225-246)</li>
<li>`_build_prompt_metadata()` method (lines 259-299)</li>
<li>Checklist line "Context verwerkt zonder..." (line 204)</li>
</ul>

<p>---</p>

<h2>3. DATA ACCESS PATTERN - UNIFIED APPROACH</h2>

<h3>Decision: Use shared_state as Single Channel</h3>

<p><strong>Rationale:</strong></p>
<ul>
<li>âœ… Enforces module boundaries (no direct access to enriched_context)</li>
<li>âœ… Clear dependency graph (ContextInstructionModule has no deps)</li>
<li>âœ… Testable (mock shared_state for unit tests)</li>
<li>âœ… Consistent across all modules</li>
</ul>

<h3>Data Flow (After Refactor)</h3>

<pre><code>EnrichedContext (input)
    â†“
ContextInstructionModule
    â”œâ”€ Reads: enriched_context.base_context
    â”œâ”€ Calculates: context_richness_score = 0.65
    â”œâ”€ Generates: ALL context output (~180 tokens)
    â””â”€ Shares:
        - context_richness_score: 0.65
        - organization_contexts: ["NP", "OM"]
        - juridical_contexts: ["Strafrecht"]
        - legal_basis_contexts: ["Wetboek van Strafrecht"]
    â†“
ErrorPreventionModule (refactored)
    â”œâ”€ Reads: NOTHING from shared_state
    â””â”€ Generates: Generic forbidden patterns only
    â†“
DefinitionTaskModule (refactored)
    â”œâ”€ Reads: NOTHING from shared_state (context-agnostic)
    â””â”€ Generates: Generic final instructions</code></pre>

<h3>No Backwards Compatibility Adapter Needed âœ…</h3>

<p><strong>Why:</strong> Per CLAUDE.md â†’ "âš ï¸ GEEN BACKWARDS COMPATIBILITY" (single-user app, not in production)</p>

<p><strong>Approach:</strong> Direct refactor, no feature flags, no parallel paths</p>

<p>---</p>

<h2>4. TOKEN OPTIMIZATION</h2>

<h3>Current Token Distribution</h3>

<p>| Section | Module | Current Tokens | After Consolidation | Reduction |</p>
<p>|---------|--------|----------------|---------------------|-----------|</p>
<p>| Context instructions | ContextAwarenessModule | ~200 | ~120 (adaptive) | -40% |</p>
<p>| Context forbidden | ErrorPreventionModule | ~100 | ~60 (consolidated) | -40% |</p>
<p>| Context metadata | DefinitionTaskModule | ~80 | ~0 (removed) | -100% |</p>
<p>| <strong>TOTAL</strong> | 3 modules | <strong>~380</strong> | <strong>~180</strong> | <strong>-53%</strong> |</p>

<h3>Adaptive Output Strategy</h3>

<p>Use <code>context_richness_score</code> to determine output verbosity:</p>

<p><strong>Score â‰¥ 0.8 (Rich Context):</strong></p>
<pre><code>ğŸ“Š UITGEBREIDE CONTEXT ANALYSE:
âš ï¸ VERPLICHT: Gebruik onderstaande specifieke context...

ğŸ¯ ORGANISATORISCHE CONTEXT:
  â€¢ Nederlands Politie (NP)
ğŸ¯ JURIDISCHE CONTEXT:
  â€¢ Strafrecht
ğŸ¯ WETTELIJKE BASIS:
  â€¢ Wetboek van Strafrecht

ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN:
- Gebruik 'NP' of 'Nederlands Politie' niet letterlijk...

ğŸ“Š CONTEXT METADATA:
- Context type: organisatorisch + juridisch + wettelijk
- Context richness: 0.85</code></pre>
<p><strong>Estimated tokens:</strong> ~220</p>

<p><strong>Score 0.5-0.8 (Moderate Context):</strong></p>
<pre><code>ğŸ“Œ VERPLICHTE CONTEXT INFORMATIE:
âš ï¸ INSTRUCTIE: Gebruik context zonder expliciete benoeming.

Context: Nederlands Politie (NP), Strafrecht, Wetboek van Strafrecht

ğŸš¨ VERBODEN: Vermijd letterlijke vermelding van NP, Strafrecht, Wetboek.</code></pre>
<p><strong>Estimated tokens:</strong> ~120</p>

<p><strong>Score < 0.5 (Minimal Context):</strong></p>
<pre><code>ğŸ“ Context: geen specifieke context beschikbaar.</code></pre>
<p><strong>Estimated tokens:</strong> ~10</p>

<h3>Expected Savings</h3>

<ul>
<li>**Typical case** (moderate context): 380 â†’ 120 tokens = **-68% reduction**</li>
<li>**Rich context**: 380 â†’ 220 tokens = **-42% reduction**</li>
<li>**Minimal context**: 380 â†’ 10 tokens = **-97% reduction**</li>
</ul>

<p><strong>Average across all cases:</strong> <strong>~53% token reduction</strong></p>

<p>---</p>

<h2>5. IMPLEMENTATION PHASES</h2>

<h3>Phase 1: Create ContextInstructionModule Skeleton (30 min)</h3>

<p><strong>File:</strong> <code>src/services/prompts/modules/context_instruction_module.py</code></p>

<p><strong>Checklist:</strong></p>
<ul>
<li>[ ] Create new file based on BasePromptModule</li>
<li>[ ] Define module_id: "context_instruction"</li>
<li>[ ] Set priority: 75 (high - context is foundational)</li>
<li>[ ] Implement empty methods: initialize(), validate_input(), execute(), get_dependencies()</li>
<li>[ ] Return empty list from get_dependencies() (no dependencies)</li>
<li>[ ] Add docstring explaining Single Source of Truth responsibility</li>
</ul>

<p><strong>Skeleton code:</strong></p>
<pre><code>"""
Context Instruction Module - Single Source of Truth for ALL context-related output.

Consolidates context handling from:
- ContextAwarenessModule (context richness scoring, adaptive formatting)
- ErrorPreventionModule (context-specific forbidden patterns)
- DefinitionTaskModule (context metadata)

This module is the ONLY place that generates context instructions.
"""

import logging
from typing import Any

from .base_module import BasePromptModule, ModuleContext, ModuleOutput

logger = logging.getLogger(__name__)


class ContextInstructionModule(BasePromptModule):
    """
    Single Source of Truth for context instructions.
    
    Responsibilities:
    1. Calculate context richness score (0.0-1.0)
    2. Generate adaptive context instructions
    3. Generate context-specific forbidden patterns
    4. Generate context metadata
    5. Share context data via shared_state
    """

    def __init__(self):
        super().__init__(
            module_id="context_instruction",
            module_name="Context Instruction (Single Source of Truth)",
            priority=75,  # High priority - context is foundational
        )
        # Configuration flags
        self.adaptive_formatting = True
        self.confidence_indicators = True
        self.include_metadata = True

    def initialize(self, config: dict[str, Any]) -&gt; None:
        """Initialize module with configuration."""
        self._config = config
        self.adaptive_formatting = config.get("adaptive_formatting", True)
        self.confidence_indicators = config.get("confidence_indicators", True)
        self.include_metadata = config.get("include_metadata", True)
        self._initialized = True
        logger.debug("ContextInstructionModule initialized")

    def validate_input(self, context: ModuleContext) -&gt; tuple[bool, str | None]:
        """This module always runs (even with no context)."""
        return True, None

    def execute(self, context: ModuleContext) -&gt; ModuleOutput:
        """Generate all context-related output."""
        # TODO: Implement in Phase 2
        return ModuleOutput(content="", metadata={})

    def get_dependencies(self) -&gt; list[str]:
        """No dependencies - reads enriched_context directly."""
        return []</code></pre>

<p><strong>Test:</strong></p>
<pre><code>python -m py_compile src/services/prompts/modules/context_instruction_module.py</code></pre>

<p>---</p>

<h3>Phase 2: Migrate Business Logic (2 hours)</h3>

<h4>Step 2.1: Migrate Context Richness Scoring (30 min)</h4>

<p><strong>Source:</strong> <code>context_awareness_module.py</code> lines 143-184</p>

<p><strong>Action:</strong> Copy <code>_calculate_context_score()</code> method to ContextInstructionModule</p>

<p><strong>Preservation checklist:</strong></p>
<ul>
<li>[ ] Base context contribution (max 0.3)</li>
<li>[ ] Sources contribution (max 0.4)</li>
<li>[ ] Expanded terms contribution (max 0.2)</li>
<li>[ ] Confidence scores contribution (max 0.1)</li>
<li>[ ] Score clamped to 1.0</li>
</ul>

<p><strong>Test:</strong></p>
<pre><code>def test_context_richness_scoring():
    """Verify context richness score calculation."""
    module = ContextInstructionModule()
    context = ModuleContext(...)
    
    # Add test data
    context.enriched_context.base_context = {"organisatorisch": ["NP"]}
    
    output = module.execute(context)
    
    score = context.get_shared("context_richness_score")
    assert 0.0 &lt;= score &lt;= 1.0</code></pre>

<h4>Step 2.2: Migrate Adaptive Formatting (30 min)</h4>

<p><strong>Source:</strong> <code>context_awareness_module.py</code> lines 186-280</p>

<p><strong>Methods to migrate:</strong></p>
<ul>
<li>`_build_rich_context_section()` (lines 186-224)</li>
<li>`_build_moderate_context_section()` (lines 226-261)</li>
<li>`_build_minimal_context_section()` (lines 263-280)</li>
<li>Helper methods: `_format_detailed_base_context()`, `_format_sources_with_confidence()`, etc.</li>
</ul>

<p><strong>Consolidation opportunity:</strong></p>
<ul>
<li>Combine rich/moderate/minimal into single `_build_context_instructions()` method</li>
<li>Use score-based switch statement</li>
<li>Reduce duplication in formatting code</li>
</ul>

<p><strong>Test:</strong></p>
<pre><code>def test_adaptive_formatting_rich():
    """Verify rich context formatting (score â‰¥ 0.8)."""
    # Mock high score
    assert "ğŸ“Š UITGEBREIDE CONTEXT ANALYSE" in output.content

def test_adaptive_formatting_moderate():
    """Verify moderate context formatting (0.5 â‰¤ score &lt; 0.8)."""
    # Mock medium score
    assert "ğŸ“Œ VERPLICHTE CONTEXT INFORMATIE" in output.content

def test_adaptive_formatting_minimal():
    """Verify minimal context formatting (score &lt; 0.5)."""
    # Mock low score
    assert "ğŸ“ VERPLICHTE CONTEXT" in output.content</code></pre>

<h4>Step 2.3: Migrate Context Forbidden Patterns (30 min)</h4>

<p><strong>Source:</strong> <code>error_prevention_module.py</code> lines 193-245</p>

<p><strong>Methods to migrate:</strong></p>
<ul>
<li>`_build_context_forbidden()` (lines 193-245)</li>
</ul>

<p><strong>Centralize organization mappings:</strong></p>
<pre><code># Move to module-level constant for reusability
ORGANIZATION_MAPPINGS = {
    "NP": "Nederlands Politie",
    "DJI": "Dienst JustitiÃ«le Inrichtingen",
    "OM": "Openbaar Ministerie",
    "ZM": "Zittende Magistratuur",
    "3RO": "Samenwerkingsverband Reclasseringsorganisaties",
    "CJIB": "Centraal Justitieel Incassobureau",
    "KMAR": "Koninklijke Marechaussee",
    "FIOD": "Fiscale Inlichtingen- en Opsporingsdienst",
}</code></pre>

<p><strong>Consolidation opportunity:</strong></p>
<ul>
<li>Integrate forbidden patterns into main output (don't generate separately)</li>
<li>Only generate when contexts exist (skip if empty)</li>
</ul>

<p><strong>Test:</strong></p>
<pre><code>def test_context_forbidden_patterns():
    """Verify context-specific forbidden patterns."""
    # Mock context with NP
    assert "Gebruik de term 'NP'" in output.content
    assert "Nederlands Politie" in output.content  # Full name</code></pre>

<h4>Step 2.4: Migrate Context Metadata (30 min)</h4>

<p><strong>Source:</strong> <code>definition_task_module.py</code> lines 259-299</p>

<p><strong>Method to migrate:</strong></p>
<ul>
<li>`_build_prompt_metadata()` (lines 259-299)</li>
</ul>

<p><strong>Consolidation opportunity:</strong></p>
<ul>
<li>Only generate metadata if `include_metadata=True` in config</li>
<li>Use shared_state data (don't re-read base_context)</li>
<li>Combine with main output as footer section</li>
</ul>

<p><strong>Test:</strong></p>
<pre><code>def test_context_metadata():
    """Verify context metadata generation."""
    module = ContextInstructionModule()
    module.include_metadata = True
    
    output = module.execute(context)
    
    assert "ğŸ†” Promptmetadata:" in output.content
    assert "Organisatorische context:" in output.content</code></pre>

<p>---</p>

<h3>Phase 3: Implement Complete execute() Method (30 min)</h3>

<p><strong>Orchestration logic:</strong></p>

<pre><code>def execute(self, context: ModuleContext) -&gt; ModuleOutput:
    """Generate all context-related output."""
    try:
        # Step 1: Calculate context richness score
        context_score = self._calculate_context_score(context.enriched_context)
        context.set_shared("context_richness_score", context_score)
        
        # Step 2: Extract and share context data
        self._share_context_data(context)
        
        # Step 3: Generate main output sections
        sections = []
        
        # 3a. Context instructions (adaptive based on score)
        context_instructions = self._build_context_instructions(
            context, context_score
        )
        if context_instructions:
            sections.append(context_instructions)
        
        # 3b. Context-specific forbidden patterns
        forbidden_patterns = self._build_context_forbidden(context)
        if forbidden_patterns:
            sections.append("\n### ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN:")
            sections.extend(forbidden_patterns)
        
        # 3c. Context metadata (if enabled)
        if self.include_metadata:
            metadata = self._build_context_metadata(context)
            if metadata:
                sections.append("\n" + metadata)
        
        # Step 4: Combine sections
        content = "\n".join(sections)
        
        return ModuleOutput(
            content=content,
            metadata={
                "context_score": context_score,
                "has_context": bool(content.strip()),
            },
        )
        
    except Exception as e:
        logger.error(f"ContextInstructionModule failed: {e}", exc_info=True)
        return ModuleOutput(
            content="ğŸ“ Context: geen context beschikbaar (error)",
            metadata={"error": str(e)},
            success=False,
            error_message=f"Context instruction generation failed: {e}",
        )</code></pre>

<p><strong>Test:</strong></p>
<pre><code>def test_complete_context_output():
    """Verify complete context output integration."""
    module = ContextInstructionModule()
    context = create_test_context(org=["NP"], jur=["Strafrecht"])
    
    output = module.execute(context)
    
    # Verify all three sections present
    assert "ğŸ“Œ VERPLICHTE CONTEXT" in output.content  # Instructions
    assert "ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN" in output.content  # Forbidden
    assert "ğŸ†” Promptmetadata" in output.content  # Metadata
    
    # Verify shared_state populated
    assert context.get_shared("context_richness_score") is not None
    assert context.get_shared("organization_contexts") == ["NP"]</code></pre>

<p>---</p>

<h3>Phase 4: Update Orchestrator Registration (30 min)</h3>

<p><strong>File:</strong> Find where modules are registered (likely <code>src/services/prompts/prompt_service_v2.py</code> or similar)</p>

<p><strong>Actions:</strong></p>
<ol>
<li>[ ] Register ContextInstructionModule</li>
<li>[ ] Remove ContextAwarenessModule registration</li>
<li>[ ] Verify execution order (ContextInstruction should run early, priority 75)</li>
</ol>

<p><strong>Find registration point:</strong></p>
<pre><code>grep -r "register_module" src/services/prompts/ --include="*.py"</code></pre>

<p><strong>Expected registration code:</strong></p>
<pre><code># NEW: Single source of truth for context
orchestrator.register_module(ContextInstructionModule())

# REMOVE: Old context awareness
# orchestrator.register_module(ContextAwarenessModule())  # DELETED</code></pre>

<p><strong>Test:</strong></p>
<pre><code>def test_orchestrator_includes_context_instruction():
    """Verify ContextInstructionModule is registered."""
    orchestrator = create_test_orchestrator()
    
    assert "context_instruction" in orchestrator.modules
    assert "context_awareness" not in orchestrator.modules  # Removed</code></pre>

<p>---</p>

<h3>Phase 5: Refactor ErrorPreventionModule (45 min)</h3>

<p><strong>File:</strong> <code>src/services/prompts/modules/error_prevention_module.py</code></p>

<p><strong>Remove lines:</strong></p>
<ul>
<li>[ ] 75-79: Context retrieval from shared_state</li>
<li>[ ] 95-100: Context forbidden section injection</li>
<li>[ ] 193-245: `_build_context_forbidden()` method</li>
<li>[ ] 209-219: Organization mappings (moved to ContextInstructionModule)</li>
</ul>

<p><strong>Update execute() method:</strong></p>

<p><strong>Before:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; ModuleOutput:
    # Haal context informatie op
    org_contexts = context.get_shared("organization_contexts", [])
    jur_contexts = context.get_shared("juridical_contexts", [])
    wet_contexts = context.get_shared("legal_basis_contexts", [])
    
    sections = []
    sections.append("### âš ï¸ Veelgemaakte fouten:")
    sections.extend(self._build_basic_errors())
    sections.extend(self._build_forbidden_starters())
    
    # Context-specifieke verboden
    context_forbidden = self._build_context_forbidden(...)
    if context_forbidden:
        sections.append("\n### ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN:")
        sections.extend(context_forbidden)
    
    # ... rest</code></pre>

<p><strong>After:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; ModuleOutput:
    sections = []
    sections.append("### âš ï¸ Veelgemaakte fouten (vermijden!):")
    sections.extend(self._build_basic_errors())
    
    if self.extended_forbidden_list:
        sections.extend(self._build_forbidden_starters())
    
    if self.include_validation_matrix:
        sections.append(self._build_validation_matrix())
    
    # Generic warning (not context-specific)
    sections.append(
        "\nğŸš« Let op: bronnen en context mogen niet letterlijk of herleidbaar in de definitie voorkomen."
    )
    
    content = "\n".join(sections)
    
    return ModuleOutput(
        content=content,
        metadata={"extended_list": self.extended_forbidden_list},
    )</code></pre>

<p><strong>Update dependencies:</strong></p>

<p><strong>Before:</strong></p>
<pre><code>def get_dependencies(self) -&gt; list[str]:
    return ["context_awareness"]  # Dependency on context</code></pre>

<p><strong>After:</strong></p>
<pre><code>def get_dependencies(self) -&gt; list[str]:
    return []  # No dependencies (context-agnostic now)</code></pre>

<p><strong>Test:</strong></p>
<pre><code>def test_error_prevention_no_context_logic():
    """Verify ErrorPreventionModule no longer handles context."""
    module = ErrorPreventionModule()
    context = create_test_context(org=["NP"])
    
    output = module.execute(context)
    
    # Should NOT contain context-specific forbidden patterns
    assert "Nederlands Politie" not in output.content
    assert "NP" not in output.content
    
    # Should still contain generic errors
    assert "Begin niet met lidwoorden" in output.content</code></pre>

<p>---</p>

<h3>Phase 6: Refactor DefinitionTaskModule (45 min)</h3>

<p><strong>File:</strong> <code>src/services/prompts/modules/definition_task_module.py</code></p>

<p><strong>Remove lines:</strong></p>
<ul>
<li>[ ] 84-104: Context detection from base_context</li>
<li>[ ] 206-223: Context-aware quality control adaptation</li>
<li>[ ] 225-246: `_build_metadata()` method</li>
<li>[ ] 259-299: `_build_prompt_metadata()` method</li>
<li>[ ] 204: Checklist line "Context verwerkt zonder expliciete benoeming"</li>
</ul>

<p><strong>Update execute() method:</strong></p>

<p><strong>Before:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; ModuleOutput:
    begrip = context.begrip
    word_type = context.get_shared("word_type", "onbekend")
    ontological_category = context.get_shared("ontological_category")
    
    # REMOVE: Context detection
    org_contexts = context.get_shared("organization_contexts", [])
    base_ctx = context.enriched_context.base_context
    jur_contexts = base_ctx.get("juridische_context") or []
    wet_basis = base_ctx.get("wettelijke_basis") or []
    has_context = bool(org_contexts or jur_contexts or wet_basis)
    
    sections = []
    sections.append("### ğŸ¯ FINALE INSTRUCTIES:")
    sections.append(self._build_task_assignment(begrip))
    sections.append(self._build_checklist(ontological_category))
    
    # REMOVE: Context-aware quality control
    if self.include_quality_control:
        sections.append(self._build_quality_control(has_context))
    
    # REMOVE: Context metadata
    if self.include_metadata:
        sections.append(self._build_metadata(...))
    
    # ... rest
    sections.append(self._build_prompt_metadata(...))  # REMOVE
    
    # ...</code></pre>

<p><strong>After:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; ModuleOutput:
    begrip = context.begrip
    ontological_category = context.get_shared("ontological_category")
    
    sections = []
    sections.append("### ğŸ¯ FINALE INSTRUCTIES:")
    sections.append(self._build_task_assignment(begrip))
    sections.append(self._build_checklist(ontological_category))
    
    if self.include_quality_control:
        sections.append(self._build_quality_control())  # No context param
    
    sections.append(self._build_ontological_marker())
    sections.append(self._build_final_instruction(begrip))
    
    content = "\n\n".join(sections)
    
    return ModuleOutput(
        content=content,
        metadata={
            "begrip": begrip,
            "ontological_category": ontological_category,
        },
    )</code></pre>

<p><strong>Simplify _build_checklist():</strong></p>

<p><strong>Before (lines 177-204):</strong></p>
<pre><code>def _build_checklist(self, ontological_category: str | None) -&gt; str:
    # ...
    return f"""ğŸ“‹ **CONSTRUCTIE GUIDE - Bouw je definitie op:**
â†’ Begint met zelfstandig naamwoord (geen lidwoord/koppelwerkwoord)
â†’ EÃ©n enkele zin zonder punt aan het einde
â†’ Geen toelichting, voorbeelden of haakjes
â†’ Ontologische categorie is duidelijk{ont_cat}
â†’ Geen verboden woorden (aspect, element, kan, moet, etc.)
â†’ Context verwerkt zonder expliciete benoeming"""  # â† REMOVE this line</code></pre>

<p><strong>After:</strong></p>
<pre><code>def _build_checklist(self, ontological_category: str | None) -&gt; str:
    ont_cat = ""
    if ontological_category:
        category_hints = {...}
        ont_cat = f"\nğŸ¯ Focus: Dit is een **{ontological_category}** (...)"
    
    return f"""ğŸ“‹ **CONSTRUCTIE GUIDE - Bouw je definitie op:**
â†’ Begint met zelfstandig naamwoord (geen lidwoord/koppelwerkwoord)
â†’ EÃ©n enkele zin zonder punt aan het einde
â†’ Geen toelichting, voorbeelden of haakjes
â†’ Ontologische categorie is duidelijk{ont_cat}
â†’ Geen verboden woorden (aspect, element, kan, moet, etc.)"""</code></pre>

<p><strong>Simplify _build_quality_control():</strong></p>

<p><strong>Before (lines 206-223):</strong></p>
<pre><code>def _build_quality_control(self, has_context: bool) -&gt; str:
    context_vraag = "de gegeven context" if has_context else "algemeen gebruik"
    
    return f"""#### ğŸ” KWALITEITSCONTROLE:
Stel jezelf deze vragen:
1. Is direct duidelijk WAT het begrip is (niet het doel)?
2. Kan iemand hiermee bepalen of iets wel/niet onder dit begrip valt?
3. Is de formulering specifiek genoeg voor {context_vraag}?
4. Bevat de definitie alleen essentiÃ«le informatie?"""</code></pre>

<p><strong>After:</strong></p>
<pre><code>def _build_quality_control(self) -&gt; str:
    return """#### ğŸ” KWALITEITSCONTROLE:
Stel jezelf deze vragen:
1. Is direct duidelijk WAT het begrip is (niet het doel)?
2. Kan iemand hiermee bepalen of iets wel/niet onder dit begrip valt?
3. Is de formulering specifiek en accuraat?
4. Bevat de definitie alleen essentiÃ«le informatie?"""</code></pre>

<p><strong>Test:</strong></p>
<pre><code>def test_definition_task_no_context_logic():
    """Verify DefinitionTaskModule no longer handles context."""
    module = DefinitionTaskModule()
    context = create_test_context(begrip="vergunning")
    
    output = module.execute(context)
    
    # Should NOT contain context metadata
    assert "Organisatorische context:" not in output.content
    assert "Juridische context:" not in output.content
    
    # Should NOT adapt quality control to context
    assert "de gegeven context" not in output.content
    
    # Should still contain generic final instructions
    assert "FINALE INSTRUCTIES" in output.content
    assert "CONSTRUCTIE GUIDE" in output.content</code></pre>

<p>---</p>

<h3>Phase 7: Delete ContextAwarenessModule (15 min)</h3>

<p><strong>File:</strong> <code>src/services/prompts/modules/context_awareness_module.py</code></p>

<p><strong>Actions:</strong></p>
<ol>
<li>[ ] Delete entire file (433 lines)</li>
<li>[ ] Search for imports and remove them</li>
<li>[ ] Search for references and update</li>
</ol>

<p><strong>Search for references:</strong></p>
<pre><code>grep -r "ContextAwarenessModule" src/ --include="*.py"
grep -r "context_awareness_module" src/ --include="*.py"</code></pre>

<p><strong>Expected references to remove:</strong></p>
<pre><code># Remove import
from .context_awareness_module import ContextAwarenessModule

# Remove registration
orchestrator.register_module(ContextAwarenessModule())</code></pre>

<p><strong>Verify deletion:</strong></p>
<pre><code># Should return "No such file"
cat src/services/prompts/modules/context_awareness_module.py</code></pre>

<p>---</p>

<h2>6. TESTING STRATEGY</h2>

<h3>Unit Tests (Create New File)</h3>

<p><strong>File:</strong> <code>tests/services/prompts/modules/test_context_instruction_module.py</code></p>

<p><strong>Test suite:</strong></p>

<pre><code>"""Unit tests for ContextInstructionModule."""

import pytest
from services.definition_generator_context import EnrichedContext
from services.definition_generator_config import UnifiedGeneratorConfig
from services.prompts.modules.context_instruction_module import (
    ContextInstructionModule,
)
from services.prompts.modules.base_module import ModuleContext


def create_test_context(
    begrip="vergunning",
    org=None,
    jur=None,
    wet=None,
):
    """Helper to create test context."""
    base_context = {}
    if org:
        base_context["organisatorisch"] = org
    if jur:
        base_context["juridisch"] = jur
    if wet:
        base_context["wettelijk"] = wet
    
    enriched = EnrichedContext(base_context=base_context)
    config = UnifiedGeneratorConfig()
    
    return ModuleContext(
        begrip=begrip,
        enriched_context=enriched,
        config=config,
        shared_state={},
    )


class TestContextInstructionModule:
    """Test suite for ContextInstructionModule."""
    
    def test_initialization(self):
        """Test module initializes correctly."""
        module = ContextInstructionModule()
        
        assert module.module_id == "context_instruction"
        assert module.priority == 75
        assert module.adaptive_formatting is True
    
    def test_no_dependencies(self):
        """Verify module has no dependencies."""
        module = ContextInstructionModule()
        
        assert module.get_dependencies() == []
    
    def test_validate_input_always_true(self):
        """Module should always run (even with no context)."""
        module = ContextInstructionModule()
        context = create_test_context()
        
        valid, error = module.validate_input(context)
        
        assert valid is True
        assert error is None
    
    def test_context_richness_score_calculation(self):
        """Test context richness score is calculated and shared."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context(org=["NP"], jur=["Strafrecht"])
        
        output = module.execute(context)
        
        score = context.get_shared("context_richness_score")
        assert score is not None
        assert 0.0 &lt;= score &lt;= 1.0
    
    def test_context_data_shared(self):
        """Test context data is shared via shared_state."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context(
            org=["NP", "OM"],
            jur=["Strafrecht"],
            wet=["Wetboek van Strafrecht"],
        )
        
        output = module.execute(context)
        
        assert context.get_shared("organization_contexts") == ["NP", "OM"]
        assert context.get_shared("juridical_contexts") == ["Strafrecht"]
        assert context.get_shared("legal_basis_contexts") == ["Wetboek van Strafrecht"]
    
    def test_rich_context_formatting(self):
        """Test rich context formatting (score â‰¥ 0.8)."""
        # Mock high score by providing lots of context
        # ... implementation
        pass
    
    def test_moderate_context_formatting(self):
        """Test moderate context formatting (0.5 â‰¤ score &lt; 0.8)."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context(org=["NP"])
        
        output = module.execute(context)
        
        # Should contain moderate formatting
        assert "ğŸ“Œ VERPLICHTE CONTEXT" in output.content or "ğŸ“Š UITGEBREIDE" in output.content
    
    def test_minimal_context_formatting(self):
        """Test minimal context formatting (score &lt; 0.5)."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context()  # No context
        
        output = module.execute(context)
        
        # Should contain minimal formatting
        assert "ğŸ“" in output.content or "geen" in output.content.lower()
    
    def test_context_forbidden_patterns(self):
        """Test context-specific forbidden patterns generation."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context(org=["NP"], jur=["Strafrecht"])
        
        output = module.execute(context)
        
        # Should contain forbidden patterns
        assert "ğŸš¨ CONTEXT-SPECIFIEKE VERBODEN" in output.content
        assert "NP" in output.content
        assert "Nederlands Politie" in output.content  # Full name
        assert "Strafrecht" in output.content
    
    def test_organization_mapping(self):
        """Test organization code mapping to full names."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context(org=["DJI"])
        
        output = module.execute(context)
        
        # Should map DJI to full name
        assert "Dienst JustitiÃ«le Inrichtingen" in output.content
    
    def test_context_metadata(self):
        """Test context metadata generation."""
        module = ContextInstructionModule()
        module.initialize({"include_metadata": True})
        
        context = create_test_context(org=["NP"])
        
        output = module.execute(context)
        
        # Should contain metadata
        assert "ğŸ†” Promptmetadata" in output.content or "context" in output.content.lower()
    
    def test_no_context_scenario(self):
        """Test behavior when no context is provided."""
        module = ContextInstructionModule()
        module.initialize({})
        
        context = create_test_context()  # Empty context
        
        output = module.execute(context)
        
        assert output.success is True
        assert len(output.content) &gt; 0  # Should still generate something
    
    def test_error_handling(self):
        """Test error handling in execution."""
        module = ContextInstructionModule()
        module.initialize({})
        
        # Create invalid context (missing required fields)
        invalid_context = ModuleContext(
            begrip="",
            enriched_context=None,  # Invalid
            config=None,
            shared_state={},
        )
        
        output = module.execute(invalid_context)
        
        assert output.success is False
        assert output.error_message is not None


class TestContextInstructionIntegration:
    """Integration tests with other modules."""
    
    def test_error_prevention_no_longer_depends(self):
        """Test ErrorPreventionModule no longer depends on context_awareness."""
        from services.prompts.modules.error_prevention_module import (
            ErrorPreventionModule,
        )
        
        module = ErrorPreventionModule()
        
        # Should have NO dependencies
        assert "context_awareness" not in module.get_dependencies()
        assert "context_instruction" not in module.get_dependencies()
    
    def test_definition_task_no_context_logic(self):
        """Test DefinitionTaskModule no longer handles context."""
        from services.prompts.modules.definition_task_module import (
            DefinitionTaskModule,
        )
        
        module = DefinitionTaskModule()
        module.initialize({})
        
        context = create_test_context(org=["NP"])
        
        output = module.execute(context)
        
        # Should NOT contain context metadata
        assert "Organisatorische context:" not in output.content</code></pre>

<p><strong>Run tests:</strong></p>
<pre><code>pytest tests/services/prompts/modules/test_context_instruction_module.py -v</code></pre>

<p>---</p>

<h3>Integration Tests (Update Existing)</h3>

<p><strong>File:</strong> <code>tests/services/prompts/modules/test_prompt_orchestrator.py</code></p>

<p><strong>Add tests:</strong></p>

<pre><code>def test_orchestrator_with_context_instruction_module():
    """Test orchestrator includes ContextInstructionModule."""
    orchestrator = create_test_orchestrator()
    
    # Verify registration
    assert "context_instruction" in orchestrator.modules
    assert "context_awareness" not in orchestrator.modules  # Deleted
    
    # Verify execution order
    execution_batches = orchestrator.resolve_execution_order()
    
    # ContextInstructionModule should run early (no dependencies)
    first_batch = execution_batches[0]
    assert "context_instruction" in first_batch


def test_full_prompt_generation_with_context():
    """Test full prompt generation with context consolidation."""
    orchestrator = create_test_orchestrator()
    
    begrip = "vergunning"
    context = create_test_enriched_context(org=["NP"])
    config = UnifiedGeneratorConfig()
    
    prompt = orchestrator.build_prompt(begrip, context, config)
    
    # Verify context appears ONCE (consolidated)
    assert prompt.count("ğŸ“Œ VERPLICHTE CONTEXT") &lt;= 1
    assert prompt.count("NP") &gt;= 1  # At least once
    
    # Verify no redundant sections
    assert prompt.count("Nederlands Politie") &lt;= 2  # Once in context, once in forbidden


def test_token_reduction():
    """Verify token reduction from consolidation."""
    # This test requires comparing old vs new system
    # Mock or use fixtures for old system output
    
    # Generate with new system
    orchestrator = create_test_orchestrator()
    prompt_new = orchestrator.build_prompt(...)
    
    # Compare token counts
    tokens_new = count_tokens(prompt_new)
    
    # Should be significantly lower than old system (~380 tokens saved)
    # Exact assertion depends on baseline measurement
    assert tokens_new &lt; 5000  # Example threshold</code></pre>

<p><strong>Run integration tests:</strong></p>
<pre><code>pytest tests/services/prompts/modules/test_prompt_orchestrator.py -v -k context</code></pre>

<p>---</p>

<h3>Validation Tests</h3>

<p><strong>File:</strong> <code>tests/services/test_definition_generator.py</code></p>

<p><strong>Add end-to-end test:</strong></p>

<pre><code>def test_definition_quality_maintained_after_refactor():
    """Ensure definition quality is maintained after context consolidation."""
    test_terms = [
        ("vergunning", ["NP"], ["Strafrecht"]),
        ("registratie", ["DJI"], []),
        ("beoordeling", [], ["Bestuursrecht"]),
    ]
    
    for begrip, org, jur in test_terms:
        # Generate definition with new system
        generator = get_definition_generator()
        definition = generator.generate(
            begrip=begrip,
            organisatorische_context=org,
            juridische_context=jur,
        )
        
        # Validate definition
        validator = get_validator()
        results = validator.validate(definition)
        
        # Quality should be maintained
        assert results.overall_score &gt;= 0.7  # Acceptable quality
        assert definition.content  # Non-empty
        assert begrip not in definition.content  # No circularity</code></pre>

<p><strong>Run validation tests:</strong></p>
<pre><code>pytest tests/services/test_definition_generator.py -v -k quality</code></pre>

<p>---</p>

<h2>7. RISK ANALYSIS & MITIGATION</h2>

<h3>Identified Risks</h3>

<p>| Risk | Likelihood | Impact | Severity | Mitigation Strategy |</p>
<p>|------|------------|--------|----------|---------------------|</p>
<p>| <strong>Breaking prompt generation</strong> | Medium | High | ğŸ”´ CRITICAL | Comprehensive unit tests before integration |</p>
<p>| <strong>Context not appearing in output</strong> | Low | High | ğŸ”´ CRITICAL | Integration tests verify context presence |</p>
<p>| <strong>Token reduction not achieved</strong> | Low | Medium | ğŸŸ¡ MEDIUM | Measure tokens before/after, adjust strategy |</p>
<p>| <strong>Definition quality degradation</strong> | Low | High | ğŸ”´ CRITICAL | Validation tests compare quality metrics |</p>
<p>| <strong>Module dependencies break</strong> | Low | Medium | ğŸŸ¡ MEDIUM | Update dependency graph, test orchestrator |</p>
<p>| <strong>Regression in existing features</strong> | Medium | Medium | ğŸŸ¡ MEDIUM | Full regression test suite before merge |</p>

<h3>Mitigation Details</h3>

<h4>Risk 1: Breaking Prompt Generation</h4>
<p><strong>Prevention:</strong></p>
<ul>
<li>[ ] Unit test each method in ContextInstructionModule</li>
<li>[ ] Test with empty context, single context, multiple contexts</li>
<li>[ ] Verify shared_state is populated correctly</li>
</ul>

<p><strong>Detection:</strong></p>
<ul>
<li>[ ] Integration tests fail if prompt is malformed</li>
<li>[ ] Manual inspection of generated prompts</li>
</ul>

<p><strong>Recovery:</strong></p>
<ul>
<li>[ ] Keep original modules as `.bak` files</li>
<li>[ ] Git revert to last working commit</li>
</ul>

<h4>Risk 2: Context Not Appearing</h4>
<p><strong>Prevention:</strong></p>
<ul>
<li>[ ] Test execute() method outputs non-empty content</li>
<li>[ ] Test shared_state is set correctly</li>
<li>[ ] Verify orchestrator includes module in execution</li>
</ul>

<p><strong>Detection:</strong></p>
<ul>
<li>[ ] Integration test checks for "ğŸ“Œ VERPLICHTE CONTEXT" in output</li>
<li>[ ] Validation test checks context data in shared_state</li>
</ul>

<p><strong>Recovery:</strong></p>
<ul>
<li>[ ] Debug orchestrator execution order</li>
<li>[ ] Check module priority and dependencies</li>
</ul>

<h4>Risk 3: Token Reduction Not Achieved</h4>
<p><strong>Prevention:</strong></p>
<ul>
<li>[ ] Measure baseline token count before refactor</li>
<li>[ ] Calculate expected savings (380 â†’ ~180 tokens)</li>
<li>[ ] Design adaptive output with minimal variants</li>
</ul>

<p><strong>Detection:</strong></p>
<ul>
<li>[ ] Token counting test compares old vs new</li>
<li>[ ] Performance test tracks prompt length</li>
</ul>

<p><strong>Recovery:</strong></p>
<ul>
<li>[ ] Adjust adaptive formatting thresholds</li>
<li>[ ] Further consolidate output sections</li>
</ul>

<h4>Risk 4: Definition Quality Degradation</h4>
<p><strong>Prevention:</strong></p>
<ul>
<li>[ ] Run existing validation tests before and after</li>
<li>[ ] Compare definition quality scores</li>
<li>[ ] Manual review of sample definitions</li>
</ul>

<p><strong>Detection:</strong></p>
<ul>
<li>[ ] Validation test suite catches quality drops</li>
<li>[ ] User testing reveals issues</li>
</ul>

<p><strong>Recovery:</strong></p>
<ul>
<li>[ ] Review business logic migration</li>
<li>[ ] Check for missing instructions in new module</li>
</ul>

<p>---</p>

<h3>Rollback Plan</h3>

<p><strong>NO rollback mechanism needed</strong> per CLAUDE.md:</p>
<ul>
<li>âš ï¸ GEEN BACKWARDS COMPATIBILITY (single-user app, not in production)</li>
<li>âœ… Direct refactor, no feature flags</li>
</ul>

<p><strong>However, safety measures:</strong></p>

<ol>
<li>**Git safety:**</li>
<pre><code>   # Create feature branch
   git checkout -b feature/DEF-126-context-consolidation
   
   # Commit after each phase
   git add -A
   git commit -m "feat(DEF-126): Phase 1 - Create ContextInstructionModule skeleton"
   
   # Can revert individual phases if needed
   git revert &lt;commit-hash&gt;</code></pre>
</ol>

<ol>
<li>**Backup original modules:**</li>
<pre><code>   # Optional: Keep backups during development
   cp src/services/prompts/modules/context_awareness_module.py \
      src/services/prompts/modules/context_awareness_module.py.bak</code></pre>
</ol>

<ol>
<li>**Quick verification:**</li>
<pre><code>   # After each phase, run quick smoke test
   pytest tests/services/prompts/modules/ -v -k context</code></pre>
</ol>

<p>---</p>

<h2>8. METRICS & SUCCESS CRITERIA</h2>

<h3>Primary Success Criteria âœ…</h3>

<p>| Metric | Target | Measurement Method | Pass/Fail |</p>
<p>|--------|--------|-------------------|-----------|</p>
<p>| <strong>Token Reduction</strong> | â‰¥50% (380 â†’ â‰¤190) | Token counting test | â³ TBD |</p>
<p>| <strong>Test Coverage</strong> | â‰¥80% for new module | pytest --cov | â³ TBD |</p>
<p>| <strong>All Tests Pass</strong> | 100% pass rate | pytest exit code | â³ TBD |</p>
<p>| <strong>Definition Quality</strong> | No regression | Validation score comparison | â³ TBD |</p>
<p>| <strong>Single Source of Truth</strong> | 1 module handles context | Code review | â³ TBD |</p>

<h3>Secondary Success Criteria âœ…</h3>

<p>| Metric | Target | Measurement |</p>
<p>|--------|--------|-------------|</p>
<p>| Code Reduction | ~150 lines removed | Line count diff |</p>
<p>| Module Coupling | ErrorPrevention & DefinitionTask no context deps | Dependency graph |</p>
<p>| Execution Time | No significant increase (<5%) | Performance test |</p>
<p>| Maintainability | Easier to update context logic | Developer feedback |</p>

<h3>Measurement Scripts</h3>

<p><strong>Token Counting:</strong></p>
<pre><code># tests/debug/measure_token_reduction.py
import tiktoken

def count_tokens(text: str) -&gt; int:
    """Count tokens using GPT-4 tokenizer."""
    encoder = tiktoken.encoding_for_model("gpt-4")
    return len(encoder.encode(text))

def measure_context_section_tokens():
    """Measure token usage before and after consolidation."""
    # Generate prompt with test case
    orchestrator = create_test_orchestrator()
    prompt = orchestrator.build_prompt(...)
    
    # Extract context-related sections
    # (requires pattern matching or section markers)
    
    tokens = count_tokens(prompt)
    print(f"Total prompt tokens: {tokens}")
    
    # Compare to baseline
    baseline = 380  # Old system
    reduction = baseline - tokens
    print(f"Token reduction: {reduction} ({reduction/baseline*100:.1f}%)")</code></pre>

<p><strong>Coverage Measurement:</strong></p>
<pre><code>pytest tests/services/prompts/modules/test_context_instruction_module.py \
    --cov=src/services/prompts/modules/context_instruction_module \
    --cov-report=term-missing \
    --cov-report=html</code></pre>

<p>---</p>

<h2>9. IMPLEMENTATION TIMELINE</h2>

<h3>Detailed Schedule</h3>

<p>| Phase | Task | Duration | Dependencies | Priority | Status |</p>
<p>|-------|------|----------|--------------|----------|--------|</p>
<p>| <strong>1</strong> | Create ContextInstructionModule skeleton | 30 min | None | HIGH | â³ TODO |</p>
<p>| <strong>2.1</strong> | Migrate context richness scoring | 30 min | Phase 1 | HIGH | â³ TODO |</p>
<p>| <strong>2.2</strong> | Migrate adaptive formatting | 30 min | Phase 2.1 | HIGH | â³ TODO |</p>
<p>| <strong>2.3</strong> | Migrate context forbidden patterns | 30 min | Phase 2.2 | HIGH | â³ TODO |</p>
<p>| <strong>2.4</strong> | Migrate context metadata | 30 min | Phase 2.3 | HIGH | â³ TODO |</p>
<p>| <strong>3</strong> | Implement complete execute() | 30 min | Phase 2 | HIGH | â³ TODO |</p>
<p>| <strong>4</strong> | Update orchestrator registration | 30 min | Phase 3 | HIGH | â³ TODO |</p>
<p>| <strong>5</strong> | Refactor ErrorPreventionModule | 45 min | Phase 4 | MEDIUM | â³ TODO |</p>
<p>| <strong>6</strong> | Refactor DefinitionTaskModule | 45 min | Phase 5 | MEDIUM | â³ TODO |</p>
<p>| <strong>7</strong> | Delete ContextAwarenessModule | 15 min | Phases 5-6 | LOW | â³ TODO |</p>
<p>| <strong>8</strong> | Unit testing | 1 hour | Phases 1-7 | HIGH | â³ TODO |</p>
<p>| <strong>9</strong> | Integration testing | 45 min | Phase 8 | HIGH | â³ TODO |</p>
<p>| <strong>10</strong> | Documentation update | 30 min | Phase 9 | LOW | â³ TODO |</p>
<p>| <strong>TOTAL</strong> | <strong>Full implementation</strong> | <strong>~6 hours</strong> | - | - | â³ TODO |</p>

<h3>Recommended Schedule</h3>

<p><strong>Day 1 (3 hours):</strong></p>
<ul>
<li>Morning: Phases 1-3 (create new module, migrate logic)</li>
<li>Afternoon: Phase 4 (orchestrator registration)</li>
</ul>

<p><strong>Day 2 (3 hours):</strong></p>
<ul>
<li>Morning: Phases 5-7 (refactor old modules, delete)</li>
<li>Afternoon: Phases 8-10 (testing, documentation)</li>
</ul>

<p>---</p>

<h2>10. DOCUMENTATION UPDATES</h2>

<h3>Files to Update</h3>

<ol>
<li>**Architecture Documentation**</li>
</ol>
<ul>
<li>  - `docs/architectuur/PROMPT_SYSTEM_ARCHITECTURE.md`</li>
<li>  - Update module diagram to show ContextInstructionModule</li>
<li>  - Remove ContextAwarenessModule references</li>
<li>  - Update data flow diagrams</li>
</ul>

<ol>
<li>**Module Documentation**</li>
</ol>
<ul>
<li>  - Create: `docs/technisch/context_instruction_module.md`</li>
<li>  - Delete: References to `context_awareness_module.md` (if exists)</li>
</ul>

<ol>
<li>**Developer Guidelines**</li>
</ol>
<ul>
<li>  - `CLAUDE.md` â†’ Update "Belangrijke Bestandslocaties" section</li>
<li>  - Add: ContextInstructionModule as Single Source of Truth for context</li>
</ul>

<ol>
<li>**Changelog**</li>
</ol>
<ul>
<li>  - `docs/refactor-log.md`</li>
<li>  - Add entry for DEF-126 context consolidation</li>
</ul>

<h3>Documentation Template</h3>

<p><strong>File:</strong> <code>docs/technisch/context_instruction_module.md</code></p>

<pre><code># ContextInstructionModule - Single Source of Truth voor Context

## Overzicht

De ContextInstructionModule is de enige module die context-gerelateerde instructies genereert in het prompt systeem. Deze module consolideert de logica van drie voormalige modules:
- ContextAwarenessModule (VERWIJDERD)
- ErrorPreventionModule (context logica verwijderd)
- DefinitionTaskModule (context metadata verwijderd)

## Verantwoordelijkheden

1. **Context Richness Scoring:** Bereken score (0.0-1.0) op basis van context kwaliteit
2. **Adaptive Formatting:** Genereer output aangepast aan context rijkheid
3. **Context-Specific Forbidden Patterns:** Genereer verboden patronen per context
4. **Context Metadata:** Genereer metadata footer met context informatie
5. **Shared State Management:** Deel context data met andere modules

## Data Flow
</code></pre>
<p>EnrichedContext</p>
<p>    â†“</p>
<p>ContextInstructionModule.execute()</p>
<p>    â”œâ”€ _calculate_context_score() â†’ 0.65</p>
<p>    â”œâ”€ _build_context_instructions() â†’ "ğŸ“Œ VERPLICHTE CONTEXT..."</p>
<p>    â”œâ”€ _build_context_forbidden() â†’ "ğŸš¨ VERBODEN: ..."</p>
<p>    â””â”€ _build_context_metadata() â†’ "ğŸ†” Promptmetadata: ..."</p>
<p>    â†“</p>
<p>shared_state:</p>
<ul>
<li>   - context_richness_score: 0.65</li>
<li>   - organization_contexts: ["NP"]</li>
<li>   - juridical_contexts: ["Strafrecht"]</li>
<pre><code>
## Configuratie
</code></pre>
<p>{</p>
<p>    "adaptive_formatting": True,      # Gebruik adaptive output</p>
<p>    "confidence_indicators": True,    # Toon confidence emoji's</p>
<p>    "include_metadata": True,         # Genereer metadata footer</p>
<p>}</p>
<pre><code>
## Token Optimization

De module gebruikt adaptive output om tokens te besparen:

| Context Score | Output Level | Estimated Tokens |
|---------------|--------------|------------------|
| â‰¥ 0.8 | Rich | ~220 |
| 0.5 - 0.8 | Moderate | ~120 |
| &lt; 0.5 | Minimal | ~10 |

## Testing

Zie `tests/services/prompts/modules/test_context_instruction_module.py`

## Migratie van Oude Modules

| Oude Module | Oude Methode | Nieuwe Locatie |
|-------------|--------------|----------------|
| ContextAwarenessModule | `_calculate_context_score()` | ContextInstructionModule (zelfde naam) |
| ContextAwarenessModule | `_build_rich_context_section()` | ContextInstructionModule._build_context_instructions() |
| ErrorPreventionModule | `_build_context_forbidden()` | ContextInstructionModule (zelfde naam) |
| DefinitionTaskModule | `_build_prompt_metadata()` | ContextInstructionModule._build_context_metadata() |</code></pre>
</ul>

<p>---</p>

<h2>11. APPROVAL & SIGN-OFF</h2>

<h3>Approval Requirements</h3>

<p><strong>Per UNIFIED_INSTRUCTIONS.md â†’ APPROVAL LADDER:</strong></p>

<ul>
<li>âœ… **Changes >100 lines:** YES (150+ lines changed across 4 files)</li>
<li>âœ… **Changes >5 files:** NO (4 files: 1 new, 3 modified)</li>
<li>âœ… **Schema changes:** NO</li>
<li>âœ… **Network calls:** NO</li>
</ul>

<p><strong>Conclusion:</strong> <strong>USER APPROVAL REQUIRED</strong> (>100 lines threshold)</p>

<h3>Stakeholders</h3>

<p>| Role | Name | Responsibility | Sign-off |</p>
<p>|------|------|----------------|----------|</p>
<p>| <strong>Developer</strong> | bmad-dev | Implementation | â³ Pending |</p>
<p>| <strong>Architect</strong> | bmad-architect | Design review | â³ Pending |</p>
<p>| <strong>QA</strong> | bmad-tester | Test execution | â³ Pending |</p>
<p>| <strong>Product Owner</strong> | User | Final approval | â³ <strong>REQUIRED</strong> |</p>

<p>---</p>

<h2>12. CONCLUSION</h2>

<h3>Summary</h3>

<p>The DEF-126 Context Consolidation solution:</p>

<ol>
<li>âœ… **Verified Problem:** 380 tokens of redundancy across 3 modules</li>
<li>âœ… **Clear Architecture:** Single Source of Truth pattern</li>
<li>âœ… **Low Risk:** No backwards compatibility, comprehensive tests</li>
<li>âœ… **High Impact:** 50-65% token reduction, improved maintainability</li>
<li>âœ… **Detailed Plan:** 10 phases with concrete steps and tests</li>
</ol>

<h3>Implementation Readiness</h3>

<p><strong>Ready for bmad-dev to execute:</strong></p>
<ul>
<li>âœ… Complete phase-by-phase breakdown</li>
<li>âœ… Code examples for each step</li>
<li>âœ… Test strategy with concrete test cases</li>
<li>âœ… Risk mitigation for each identified risk</li>
<li>âœ… Success criteria with measurement methods</li>
</ul>

<h3>Recommendation</h3>

<p><strong>IMPLEMENT following this plan</strong> with user approval for >100 lines changes.</p>

<p><strong>Next Steps:</strong></p>
<ol>
<li>User approves implementation plan</li>
<li>bmad-dev executes Phases 1-10 sequentially</li>
<li>bmad-tester verifies all tests pass</li>
<li>User reviews final results and quality</li>
</ol>

<p>---</p>

<h2>APPENDIX A: Code Reference</h2>

<h3>Organization Mappings (Centralized)</h3>

<pre><code># src/services/prompts/modules/context_instruction_module.py

# Module-level constant for reusability
ORGANIZATION_MAPPINGS = {
    "NP": "Nederlands Politie",
    "DJI": "Dienst JustitiÃ«le Inrichtingen",
    "OM": "Openbaar Ministerie",
    "ZM": "Zittende Magistratuur",
    "3RO": "Samenwerkingsverband Reclasseringsorganisaties",
    "CJIB": "Centraal Justitieel Incassobureau",
    "KMAR": "Koninklijke Marechaussee",
    "FIOD": "Fiscale Inlichtingen- en Opsporingsdienst",
}</code></pre>

<h3>Context Extraction Helper</h3>

<pre><code>def _extract_contexts(self, context_value: Any) -&gt; list[str]:
    """
    Extract context lijst uit verschillende input formaten.
    
    Backwards compatibility method (from ContextAwarenessModule).
    """
    if not context_value:
        return []
    
    if isinstance(context_value, bool):
        return []  # Legacy: True means no specific context
    if isinstance(context_value, str):
        return [context_value]
    if isinstance(context_value, list):
        return [str(item) for item in context_value if item]
    
    logger.warning(f"Unknown context type: {type(context_value)}")
    return []</code></pre>

<p>---</p>

<h2>APPENDIX B: Testing Checklist</h2>

<h3>Pre-Implementation Tests âœ…</h3>

<ul>
<li>[ ] Run full test suite: `pytest tests/ -v`</li>
<li>[ ] Verify all tests pass (baseline)</li>
<li>[ ] Measure current prompt token count</li>
<li>[ ] Document definition quality scores</li>
</ul>

<h3>Phase 1-3 Tests (New Module)</h3>

<ul>
<li>[ ] `pytest tests/services/prompts/modules/test_context_instruction_module.py -v`</li>
<li>[ ] Verify no import errors</li>
<li>[ ] Verify execute() returns valid output</li>
<li>[ ] Verify shared_state is populated</li>
</ul>

<h3>Phase 4 Tests (Orchestrator)</h3>

<ul>
<li>[ ] `pytest tests/services/prompts/modules/test_prompt_orchestrator.py -v`</li>
<li>[ ] Verify ContextInstructionModule registered</li>
<li>[ ] Verify execution order correct</li>
<li>[ ] Verify no dependency cycles</li>
</ul>

<h3>Phase 5-6 Tests (Refactored Modules)</h3>

<ul>
<li>[ ] `pytest tests/services/prompts/modules/test_error_prevention_module.py -v`</li>
<li>[ ] `pytest tests/services/prompts/modules/test_definition_task_module.py -v`</li>
<li>[ ] Verify no context logic remains</li>
<li>[ ] Verify generic functionality preserved</li>
</ul>

<h3>Phase 7 Tests (Deletion)</h3>

<ul>
<li>[ ] Verify ContextAwarenessModule file deleted</li>
<li>[ ] Verify no import errors across codebase</li>
<li>[ ] `grep -r "ContextAwarenessModule" src/` returns nothing</li>
</ul>

<h3>Integration Tests</h3>

<ul>
<li>[ ] `pytest tests/services/test_definition_generator.py -v`</li>
<li>[ ] Generate sample definitions with context</li>
<li>[ ] Verify context appears in output</li>
<li>[ ] Verify no redundancy (context listed once)</li>
</ul>

<h3>Performance Tests</h3>

<ul>
<li>[ ] Measure token count after refactor</li>
<li>[ ] Verify â‰¥50% reduction achieved</li>
<li>[ ] Measure execution time (should not increase >5%)</li>
</ul>

<h3>Validation Tests</h3>

<ul>
<li>[ ] Run validation suite on sample definitions</li>
<li>[ ] Compare quality scores before/after</li>
<li>[ ] Verify no regression</li>
</ul>

<p>---</p>

<p><strong>Document Status:</strong> âœ… READY FOR IMPLEMENTATION  </p>
<p><strong>Created:</strong> 2025-11-13  </p>
<p><strong>Priority:</strong> HIGH - Significant token/cost savings  </p>
<p><strong>Approval Required:</strong> YES (>100 lines changed)</p>


  </div>
</body>
</html>