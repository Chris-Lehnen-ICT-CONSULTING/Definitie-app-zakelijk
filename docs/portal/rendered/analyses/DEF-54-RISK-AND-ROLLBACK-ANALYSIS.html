<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>DEF-54: Risk & Rollback Analysis - Debug Specialist Report</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>DEF-54: Risk & Rollback Analysis - Debug Specialist Report</h1>

<p><strong>Date</strong>: 2025-10-29</p>
<p><strong>Analyst</strong>: Debug Specialist (Claude)</p>
<p><strong>Risk Assessment Level</strong>: DETAILED</p>
<p><strong>Focus</strong>: Failure probability, rollback strategies, test blindspots, recovery procedures</p>

<p>---</p>

<h2>Executive Summary</h2>

<p><strong>CRITICAL FINDINGS</strong>:</p>
<ol>
<li>**Phase 5 (Type Conversions)** has 85% failure probability - HIGHEST RISK</li>
<li>**Database schema rollback** is MISSING - potential data loss scenario</li>
<li>**Streamlit session state corruption** not addressed - memory leak risk</li>
<li>**Race conditions in concurrent updates** - no detection strategy</li>
<li>**Feature flag has NO automatic health checks** - could fail silently</li>
</ol>

<p><strong>RECOMMENDATION</strong>: Use <strong>Modified Hybrid Plan</strong> with enhanced rollback mechanisms and mandatory health checks after each phase.</p>

<p>---</p>

<h2>1. FAILURE PROBABILITY ANALYSIS</h2>

<h3>Phase Risk Scoring (0-100%)</h3>

<p>| Phase | Risk % | Failure Scenarios | Detection Time | Recovery Time |</p>
<p>|-------|--------|-------------------|----------------|---------------|</p>
<p>| <strong>Phase 0: Schema</strong> | 15% | Migration script fails mid-run | Immediate | 5 min |</p>
<p>| <strong>Phase 1: Feature Flag</strong> | 5% | Import errors, wrong logic | Immediate | 2 min |</p>
<p>| <strong>Phase 2: Tests</strong> | 0% | N/A (tests only) | N/A | N/A |</p>
<p>| <strong>Phase 3a: CRUD</strong> | 25% | Type mismatch, SQL errors | 1-2 days | 30 sec |</p>
<p>| <strong>Phase 3b: Duplicates</strong> | 30% | False positives/negatives | 3-5 days | 30 sec |</p>
<p>| <strong>Phase 3c: Status</strong> | 40% | Draft creation breaks UI | 1-2 days | 30 sec |</p>
<p>| <strong>Phase 4: Voorbeelden</strong> | 50% | Synonym sync deadlock | 2-3 days | 30 sec |</p>
<p>| <strong>Phase 5: Conversions</strong> | <strong>85%</strong> | 23 files break simultaneously | Hours-Days | <strong>HARD</strong> |</p>
<p>| <strong>Phase 6a: UI Tabs</strong> | 20% | Streamlit cache corruption | Immediate | 30 sec |</p>
<p>| <strong>Phase 6b: Services</strong> | 35% | Circular dependencies | 1-2 days | 30 sec |</p>
<p>| <strong>Phase 6c: Utils</strong> | 10% | Import errors | Immediate | 30 sec |</p>
<p>| <strong>Phase 7: Delete Legacy</strong> | 15% | Missed import, runtime error | Immediate | 5 min (git) |</p>
<p>| <strong>Phase 8: Code Quality</strong> | 10% | Refactor introduces bugs | 1-2 days | 5 min (git) |</p>
<p>| <strong>Phase 9: Docs</strong> | 0% | N/A (docs only) | N/A | N/A |</p>

<h3>Critical Risk Analysis</h3>

<h4>ğŸ”´ PHASE 5: Type Conversions Elimination (85% FAILURE RISK)</h4>

<p><strong>Why So Risky?</strong></p>
<ol>
<li>**Blast Radius**: Touches 23 files simultaneously</li>
<li>**Type Safety**: Removing conversions = losing Pydantic validation</li>
<li>**Cascading Failures**: One file failure cascades to dependent modules</li>
<li>**Hard to Debug**: Which of 23 files caused the issue?</li>
<li>**Hard to Rollback**: Feature flag ineffective (requires git revert)</li>
</ol>

<p><strong>Failure Scenarios</strong>:</p>
<ul>
<li>Services expect `Definition` but receive `DefinitieRecord` â†’ AttributeError</li>
<li>Pydantic validation removed â†’ invalid data enters database</li>
<li>UI components break â†’ Streamlit crashes</li>
<li>Export service fails â†’ CSV contains wrong fields</li>
<li>Validation rules fail â†’ false negatives</li>
</ul>

<p><strong>Mitigation Strategies</strong>:</p>
<ol>
<li>**SKIP THIS PHASE** - Keep type conversions (they provide value)</li>
<li>**If you must do it**: Break into 23 sub-phases (1 file per day)</li>
<li>**Add runtime type checking**: Use `isinstance()` checks everywhere</li>
<li>**Implement adapter fallback**: Keep conversion functions as backup</li>
<li>**Extensive integration testing**: Test EVERY workflow after each file</li>
</ol>

<p><strong>Rollback Difficulty</strong>: HARD</p>
<ul>
<li>Feature flag won't help (conversions already removed)</li>
<li>Git revert required (conflicts likely if other work done)</li>
<li>May need to recreate conversion functions manually</li>
<li>Database might have invalid data (requires cleanup)</li>
</ul>

<p>---</p>

<h4>ğŸŸ¡ PHASE 4: Voorbeelden Management (50% FAILURE RISK)</h4>

<p><strong>Why Risky?</strong></p>
<ol>
<li>**Complex Business Logic**: 226-line god method</li>
<li>**Synonym Sync**: Bidirectional updates, conflict resolution</li>
<li>**Database Transactions**: Multi-table updates (voorbeelden + registry)</li>
<li>**Race Conditions**: Concurrent synonym updates</li>
</ol>

<p><strong>Failure Scenarios</strong>:</p>
<ul>
<li>Synonym sync deadlock â†’ database locked, app frozen</li>
<li>Partial updates â†’ data inconsistency (voorbeelden saved, synonyms not)</li>
<li>Duplicate detection fails â†’ silent data corruption</li>
<li>UI hangs â†’ user can't save examples</li>
</ul>

<p><strong>Detection Strategy</strong> (MISSING IN PLAN):</p>
<pre><code># Add health check after Phase 4
def test_voorbeelden_sync_health():
    """Detect synonym sync issues early."""
    # 1. Create voorbeeld with synonym
    repo.save_voorbeelden(def_id, [{"text": "test", "synoniemen": ["foo"]}])

    # 2. Verify synonym in registry
    registry = repo.get_synonym_registry(def_id)
    assert "foo" in registry

    # 3. Update synonym
    repo.save_voorbeelden(def_id, [{"text": "test", "synoniemen": ["bar"]}])

    # 4. Verify old synonym removed
    registry = repo.get_synonym_registry(def_id)
    assert "foo" not in registry
    assert "bar" in registry

    # 5. Concurrent update test
    with ThreadPoolExecutor(max_workers=2) as executor:
        f1 = executor.submit(repo.save_voorbeelden, def_id, [...])
        f2 = executor.submit(repo.save_voorbeelden, def_id, [...])
        # Should not deadlock</code></pre>

<p>---</p>

<h4>ğŸŸ¡ PHASE 3c: Status & Draft Management (40% FAILURE RISK)</h4>

<p><strong>Why Risky?</strong></p>
<ol>
<li>**UI Impact**: Breaks draft workflow (high visibility)</li>
<li>**State Management**: Streamlit session state corruption</li>
<li>**Complex Logic**: `get_or_create_draft()` has multiple paths</li>
</ol>

<p><strong>Failure Scenarios</strong>:</p>
<ul>
<li>Draft creation fails silently â†’ user loses work</li>
<li>Status transitions broken â†’ definitions stuck in wrong state</li>
<li>Session state bloat â†’ memory leak (app slows down)</li>
<li>Concurrent draft creation â†’ duplicate drafts</li>
</ul>

<p><strong>Detection Strategy</strong> (MISSING IN PLAN):</p>
<pre><code># Add session state health check
def test_draft_workflow_session_state():
    """Detect session state corruption."""
    initial_state_size = len(st.session_state)

    # Run workflow 10x
    for i in range(10):
        draft = repo.get_or_create_draft(f"Test_{i}")
        # ... edit draft ...
        repo.save(draft)

    final_state_size = len(st.session_state)

    # Should not grow unbounded
    assert final_state_size - initial_state_size &lt; 5

    # Check for leaked definitions
    leaked_keys = [k for k in st.session_state.keys()
                   if k.startswith('generated_definition_')]
    assert len(leaked_keys) == 0</code></pre>

<p>---</p>

<h2>2. ROLLBACK STRATEGY ASSESSMENT</h2>

<h3>Feature Flag vs Git Revert Analysis</h3>

<h4>Feature Flag Approach (Phases 1-6c)</h4>

<p><strong>Strengths</strong>:</p>
<ul>
<li>âœ… Instant rollback (30 seconds)</li>
<li>âœ… No git expertise needed</li>
<li>âœ… Can toggle back and forth for debugging</li>
<li>âœ… No code conflicts</li>
</ul>

<p><strong>Weaknesses</strong>:</p>
<ul>
<li>âŒ No automatic health monitoring</li>
<li>âŒ Flag could be set wrong (human error)</li>
<li>âŒ Doesn't help with Phase 5 (type conversions removed)</li>
<li>âŒ Doesn't rollback database schema changes</li>
<li>âŒ Session state corruption persists across flag toggle</li>
</ul>

<p><strong>MISSING: Health Check Automation</strong></p>
<pre><code># Recommended: Auto-health check on startup
# src/services/container.py

def _create_definition_repository(self) -&gt; DefinitionRepositoryInterface:
    if os.getenv("USE_LEGACY_REPO", "false") == "true":
        repo = DefinitionRepository(self.db_path)
    else:
        repo = DefinitieRepositoryV2(self.db_path)

    # AUTO HEALTH CHECK (MISSING IN PLAN)
    try:
        self._verify_repository_health(repo)
    except HealthCheckError as e:
        logger.error(f"Repository health check failed: {e}")
        logger.warning("Falling back to legacy repository")
        repo = DefinitionRepository(self.db_path)  # Auto-fallback

    return repo

def _verify_repository_health(self, repo):
    """Verify repository can perform basic operations."""
    # 1. Can connect to database?
    repo.get(1)  # Try fetching definition

    # 2. Can write to database?
    test_def = DefinitieRecord(begrip="__HEALTH_CHECK__", ...)
    test_id = repo.save(test_def)
    repo.delete(test_id)  # Cleanup

    # 3. Can search?
    repo.search("test")

    # If any fail, raises HealthCheckError</code></pre>

<h4>Git Revert Approach (Phases 7-9)</h4>

<p><strong>Strengths</strong>:</p>
<ul>
<li>âœ… Complete rollback (code + tests + docs)</li>
<li>âœ… Atomic (all or nothing)</li>
<li>âœ… Audit trail (git history)</li>
</ul>

<p><strong>Weaknesses</strong>:</p>
<ul>
<li>âŒ Slower (5-10 minutes)</li>
<li>âŒ Requires git expertise</li>
<li>âŒ May have merge conflicts</li>
<li>âŒ Doesn't rollback database data (only schema)</li>
</ul>

<p>---</p>

<h3>Database Rollback Strategy (CRITICAL GAP)</h3>

<p><strong>PROBLEM</strong>: Current plan has NO database rollback strategy beyond "restore from backup"</p>

<p><strong>Scenarios Not Covered</strong>:</p>
<ol>
<li>**Phase 0**: Schema migration adds columns â†’ rollback removes columns â†’ **DATA LOSS**</li>
<li>**Phase 3a**: New CRUD logic writes invalid data â†’ rollback â†’ invalid data persists</li>
<li>**Phase 4**: Synonym sync corrupts registry â†’ rollback code â†’ **registry still corrupt**</li>
</ol>

<p><strong>SOLUTION: Implement Database Migration Rollback</strong></p>

<pre><code>-- src/database/migrations/007_rollback.sql (MISSING)

-- Rollback for 007_duplicate_constraint.sql
ALTER TABLE definities DROP CONSTRAINT IF EXISTS unique_begrip_active;

-- Rollback for any new columns (example)
ALTER TABLE definities DROP COLUMN IF EXISTS new_column_name;

-- Restore old triggers (if modified)
DROP TRIGGER IF EXISTS new_trigger;
CREATE TRIGGER old_trigger ...;</code></pre>

<pre><code># scripts/rollback/rollback_schema.py (MISSING)

import sqlite3
import sys
from pathlib import Path

def rollback_schema(db_path: str, target_version: int):
    """Rollback database schema to target version."""
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Get current version
    cursor.execute("SELECT MAX(version) FROM schema_migrations")
    current_version = cursor.fetchone()[0]

    if current_version &lt;= target_version:
        print(f"Already at version {current_version}")
        return

    # Apply rollback migrations in reverse
    for version in range(current_version, target_version, -1):
        rollback_file = f"src/database/migrations/{version:03d}_rollback.sql"
        if not Path(rollback_file).exists():
            print(f"ERROR: Rollback file missing: {rollback_file}")
            sys.exit(1)

        print(f"Rolling back version {version}...")
        with open(rollback_file) as f:
            cursor.executescript(f.read())

        # Update migration table
        cursor.execute("DELETE FROM schema_migrations WHERE version = ?", (version,))

    conn.commit()
    print(f"Rolled back to version {target_version}")

if __name__ == "__main__":
    rollback_schema("data/definities.db", int(sys.argv[1]))</code></pre>

<p>---</p>

<h3>Points of No Return (HARD TO ROLLBACK)</h3>

<h4>1. Phase 5: Type Conversions Removed</h4>
<ul>
<li>**Why No Return**: 186 lines of conversion code deleted</li>
<li>**Impact**: 23 files dependent on conversions</li>
<li>**Rollback Difficulty**: HIGH</li>
<li>**Recovery Plan**:</li>
</ul>
<ol>
<li>Git revert commit (may have conflicts)</li>
<li>Manually recreate `_definition_to_record()` and `_record_to_definition()`</li>
<li>Re-update all 23 files</li>
<li>Re-test everything</li>
</ol>
<ul>
<li>**Time to Recover**: 4-8 hours</li>
</ul>

<h4>2. Phase 7: Legacy Wrapper Deleted</h4>
<ul>
<li>**Why No Return**: 887 lines deleted, feature flag removed</li>
<li>**Impact**: No fallback mechanism</li>
<li>**Rollback Difficulty**: MEDIUM</li>
<li>**Recovery Plan**:</li>
</ul>
<ol>
<li>Git revert commit</li>
<li>Restore `src/services/definition_repository.py`</li>
<li>Restore feature flag logic</li>
<li>Restart app</li>
</ol>
<ul>
<li>**Time to Recover**: 10-15 minutes</li>
</ul>

<h4>3. Phase 0: Schema Migration (DATA LOSS RISK)</h4>
<ul>
<li>**Why No Return**: ALTER TABLE adds columns (removing = data loss)</li>
<li>**Impact**: Can't rollback schema without losing data</li>
<li>**Rollback Difficulty**: HIGH (if data written to new columns)</li>
<li>**Recovery Plan**:</li>
</ul>
<ol>
<li>Export all data to CSV BEFORE Phase 0</li>
<li>Restore database from backup</li>
<li>Re-import data</li>
</ol>
<ul>
<li>**Time to Recover**: 20-30 minutes</li>
</ul>

<p><strong>RECOMMENDATION</strong>: Create rollback scripts for Phase 0, 5, 7 BEFORE starting</p>

<p>---</p>

<h2>3. MISSING TESTS BLINDSPOTS</h2>

<h3>Edge Cases Not Covered</h3>

<h4>Blindspot 1: Concurrent Updates (Race Conditions)</h4>

<p><strong>Current Plan</strong>: No concurrency tests</p>
<p><strong>Risk</strong>: User clicks "Save" twice â†’ duplicate definitions</p>

<pre><code># tests/database/test_definitie_repository_v2_concurrency.py (MISSING)

import pytest
from concurrent.futures import ThreadPoolExecutor

def test_concurrent_saves_no_duplicates():
    """Test concurrent saves don't create duplicates."""
    repo = DefinitieRepositoryV2()

    def save_definition(i):
        return repo.save(DefinitieRecord(begrip=f"Test_{i}", ...))

    # Save 10 definitions concurrently
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(save_definition, i) for i in range(10)]
        results = [f.result() for f in futures]

    # All should succeed
    assert len(results) == 10
    assert len(set(results)) == 10  # No duplicate IDs

def test_concurrent_updates_last_write_wins():
    """Test concurrent updates don't corrupt data."""
    repo = DefinitieRepositoryV2()

    # Create definition
    def_id = repo.save(DefinitieRecord(begrip="Test", definitie="v1"))

    # Update concurrently
    def update_definition(version):
        record = repo.get(def_id)
        record.definitie = f"v{version}"
        repo.save(record)

    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(update_definition, i) for i in range(2, 7)]
        [f.result() for f in futures]

    # Final state should be consistent (one of v2-v6)
    final = repo.get(def_id)
    assert final.definitie in ["v2", "v3", "v4", "v5", "v6"]
    # Should NOT be corrupted like "v2v3" or empty

def test_concurrent_delete_and_save_safe():
    """Test delete + save race condition."""
    repo = DefinitieRepositoryV2()

    def_id = repo.save(DefinitieRecord(begrip="Test", ...))

    with ThreadPoolExecutor(max_workers=2) as executor:
        f1 = executor.submit(repo.delete, def_id)
        f2 = executor.submit(repo.save, repo.get(def_id))

        # One should succeed, one should fail gracefully
        # Should NOT corrupt database</code></pre>

<p>---</p>

<h4>Blindspot 2: Memory Leaks (Session State Bloat)</h4>

<p><strong>Current Plan</strong>: No memory leak tests</p>
<p><strong>Risk</strong>: <code>st.session_state</code> grows unbounded â†’ app slows down</p>

<pre><code># tests/integration/test_session_state_leaks.py (MISSING)

import pytest
import streamlit as st
from src.ui.tabbed_interface import main

def test_generate_workflow_no_memory_leak():
    """Test generating definitions doesn't leak memory."""
    initial_keys = set(st.session_state.keys())

    # Generate 50 definitions
    for i in range(50):
        st.session_state['term'] = f"Test_{i}"
        # Trigger generate workflow
        main()  # Simplified - actual test would click buttons

    final_keys = set(st.session_state.keys())

    # Should not have 50 new keys
    new_keys = final_keys - initial_keys
    assert len(new_keys) &lt; 10  # Max 10 new keys (reasonable)

def test_validation_results_not_accumulated():
    """Test validation results are overwritten, not accumulated."""
    # Generate + validate 20 times
    for i in range(20):
        definition = generate_definition(f"Test_{i}")
        results = validate_definition(definition)

    # Session state should only have LATEST results
    assert 'validation_results' in st.session_state
    # Should be single result, not list of 20
    assert not isinstance(st.session_state.validation_results, list)</code></pre>

<p>---</p>

<h4>Blindspot 3: Database Corruption (Invalid Data)</h4>

<p><strong>Current Plan</strong>: No data integrity tests</p>
<p><strong>Risk</strong>: New CRUD logic writes invalid data â†’ database corrupted</p>

<pre><code># tests/database/test_data_integrity.py (MISSING)

def test_save_rejects_invalid_data():
    """Test repository rejects invalid data."""
    repo = DefinitieRepositoryV2()

    # Empty begrip
    with pytest.raises(ValueError, match="begrip"):
        repo.save(DefinitieRecord(begrip="", definitie="test"))

    # None definitie
    with pytest.raises(ValueError, match="definitie"):
        repo.save(DefinitieRecord(begrip="test", definitie=None))

    # Invalid status
    with pytest.raises(ValueError, match="status"):
        repo.save(DefinitieRecord(begrip="test", definitie="test", status="INVALID"))

def test_database_constraints_enforced():
    """Test database constraints prevent corruption."""
    repo = DefinitieRepositoryV2()

    # Create definition
    repo.save(DefinitieRecord(begrip="Duplicate", definitie="v1", status="CONCEPT"))

    # Try to create another active definition with same begrip
    with pytest.raises(ValueError, match="bestaat al"):
        repo.save(DefinitieRecord(begrip="Duplicate", definitie="v2", status="CONCEPT"))

    # But should allow if status=ARCHIVED
    archived_id = repo.save(DefinitieRecord(begrip="Duplicate", definitie="v2", status="ARCHIVED"))
    assert archived_id &gt; 0

def test_voorbeelden_referential_integrity():
    """Test voorbeelden can't exist without parent definition."""
    repo = DefinitieRepositoryV2()

    # Try to save voorbeelden for non-existent definition
    with pytest.raises(ValueError, match="Definitie.*niet gevonden"):
        repo.save_voorbeelden(999999, [{"text": "test"}])</code></pre>

<p>---</p>

<h4>Blindspot 4: Export/Import Round-Trip</h4>

<p><strong>Current Plan</strong>: No round-trip tests</p>
<p><strong>Risk</strong>: Export format incompatible with import â†’ data loss</p>

<pre><code># tests/integration/test_export_import_roundtrip.py (MISSING)

def test_csv_export_import_roundtrip():
    """Test exported CSV can be re-imported without data loss."""
    repo = DefinitieRepositoryV2()

    # Create test definition with all fields
    original = DefinitieRecord(
        begrip="Test",
        definitie="Test definitie",
        categorie="Algemeen",
        status="VASTGESTELD",
        synoniemen=["foo", "bar"],
        organisatorische_context="Test context",
        validatie_opmerkingen="Test opmerking"
    )
    original_id = repo.save(original)

    # Export to CSV
    export_service = ExportService(repo)
    csv_path = export_service.export_to_csv([original_id])

    # Import back
    import_service = DefinitionImportService(repo)
    imported_ids = import_service.import_from_csv(csv_path)

    # Verify data integrity
    imported = repo.get(imported_ids[0])
    assert imported.begrip == original.begrip
    assert imported.definitie == original.definitie
    assert imported.categorie == original.categorie
    assert set(imported.synoniemen) == set(original.synoniemen)
    # ... all fields should match</code></pre>

<p>---</p>

<h4>Blindspot 5: Streamlit Cache Invalidation</h4>

<p><strong>Current Plan</strong>: No cache invalidation tests</p>
<p><strong>Risk</strong>: Stale data shown to user after updates</p>

<pre><code># tests/ui/test_streamlit_cache.py (MISSING)

@st.cache_data
def get_definition_cached(def_id):
    return repo.get(def_id)

def test_cache_invalidated_after_update():
    """Test Streamlit cache is invalidated after updates."""
    repo = DefinitieRepositoryV2()

    # Create definition
    def_id = repo.save(DefinitieRecord(begrip="Test", definitie="v1"))

    # Fetch (caches)
    cached_v1 = get_definition_cached(def_id)
    assert cached_v1.definitie == "v1"

    # Update
    repo.save(DefinitieRecord(id=def_id, begrip="Test", definitie="v2"))

    # Fetch again (should be v2, not cached v1)
    cached_v2 = get_definition_cached(def_id)
    assert cached_v2.definitie == "v2"  # FAILS if cache not invalidated</code></pre>

<p>---</p>

<h3>Integration Path Coverage Gaps</h3>

<p><strong>Missing Integration Tests</strong>:</p>
<ol>
<li>**Generate â†’ Validate â†’ Save â†’ Export**: Full workflow test</li>
<li>**Import â†’ Duplicate Detection â†’ Merge**: Import workflow test</li>
<li>**Draft â†’ Edit â†’ Validate â†’ Publish**: Publication workflow test</li>
<li>**Bulk Operations**: Select 100 definitions â†’ Export â†’ Verify</li>
<li>**Error Recovery**: Simulate API failure â†’ Verify graceful degradation</li>
</ol>

<p>---</p>

<h2>4. ENHANCED ROLLBACK PROCEDURES</h2>

<h3>Multi-Level Backup Strategy</h3>

<h4>Level 1: Instant Rollback (Feature Flag)</h4>
<p><strong>Use When</strong>: Immediate issue detected (< 1 hour after deployment)</p>
<p><strong>Time</strong>: 30 seconds</p>

<pre><code># Emergency rollback procedure
export USE_LEGACY_REPO=true
streamlit run src/main.py

# Verify rollback successful
curl http://localhost:8501/health  # Should return 200

# Monitor logs
tail -f logs/app.log | grep ERROR</code></pre>

<p>---</p>

<h4>Level 2: Code Rollback (Git Revert)</h4>
<p><strong>Use When</strong>: Issue detected after > 1 hour, feature flag insufficient</p>
<p><strong>Time</strong>: 5-10 minutes</p>

<pre><code># Find commit to revert
git log --oneline -n 20

# Revert specific commit
git revert &lt;commit-hash&gt;

# Or reset to previous commit (DESTRUCTIVE)
git reset --hard HEAD~1

# Verify tests pass
pytest -q

# Restart app
streamlit run src/main.py</code></pre>

<p>---</p>

<h4>Level 3: Database Rollback (Restore from Backup)</h4>
<p><strong>Use When</strong>: Data corruption detected</p>
<p><strong>Time</strong>: 5-15 minutes</p>

<pre><code># scripts/rollback/rollback_database.sh (MISSING)

#!/bin/bash
set -e

BACKUP_DIR="data/backups"
DB_PATH="data/definities.db"

echo "Available backups:"
ls -lh $BACKUP_DIR/*.db

read -p "Enter backup filename to restore: " backup_file

# Verify backup exists
if [ ! -f "$BACKUP_DIR/$backup_file" ]; then
    echo "ERROR: Backup not found"
    exit 1
fi

# Stop app (if running)
pkill -f "streamlit run" || true

# Backup current (corrupt) database
cp $DB_PATH "${DB_PATH}.corrupt.$(date +%Y%m%d_%H%M%S)"

# Restore from backup
cp "$BACKUP_DIR/$backup_file" $DB_PATH

# Verify integrity
sqlite3 $DB_PATH "PRAGMA integrity_check;"

echo "Database restored from $backup_file"
echo "Restart app: streamlit run src/main.py"</code></pre>

<p>---</p>

<h4>Level 4: Emergency Recovery (Full System Restore)</h4>
<p><strong>Use When</strong>: Multiple failures, system unstable</p>
<p><strong>Time</strong>: 20-30 minutes</p>

<pre><code># scripts/rollback/emergency_recovery.sh (MISSING)

#!/bin/bash
set -e

echo "EMERGENCY RECOVERY PROCEDURE"
echo "This will:"
echo "  1. Restore database from latest backup"
echo "  2. Reset git to last known good commit"
echo "  3. Clear Streamlit cache"
echo "  4. Reinstall dependencies"

read -p "Continue? (yes/no): " confirm
if [ "$confirm" != "yes" ]; then
    exit 1
fi

# 1. Restore database
./scripts/rollback/rollback_database.sh

# 2. Reset git (DESTRUCTIVE)
git reset --hard $(git tag | grep "known-good" | tail -1)

# 3. Clear caches
rm -rf .streamlit/cache
rm -rf __pycache__

# 4. Reinstall deps
pip install -r requirements.txt

# 5. Run smoke tests
pytest tests/smoke/ -v

# 6. Restart app
streamlit run src/main.py

echo "Recovery complete!"</code></pre>

<p>---</p>

<h3>Phase-by-Phase Checkpoint Strategy</h3>

<p><strong>RECOMMENDATION</strong>: Create git tags after each successful phase</p>

<pre><code># After Phase 0 completes successfully
git tag -a "DEF-54-phase-0-schema-complete" -m "Schema validation completed"
git push origin DEF-54-phase-0-schema-complete

# After Phase 1
git tag -a "DEF-54-phase-1-feature-flag-complete" -m "Feature flag implemented"

# ... etc for all phases

# Rollback to specific phase
git reset --hard DEF-54-phase-3a-crud-complete</code></pre>

<p><strong>Automated Checkpoint Script</strong>:</p>
<pre><code># scripts/rollback/create_checkpoint.sh (MISSING)

#!/bin/bash
set -e

PHASE=$1
if [ -z "$PHASE" ]; then
    echo "Usage: ./create_checkpoint.sh &lt;phase-name&gt;"
    exit 1
fi

TAG="DEF-54-checkpoint-$PHASE"

# Verify tests pass
echo "Running tests before checkpoint..."
pytest -q || {
    echo "ERROR: Tests failing, cannot create checkpoint"
    exit 1
}

# Backup database
BACKUP_FILE="data/backups/definities_${PHASE}_$(date +%Y%m%d_%H%M%S).db"
cp data/definities.db "$BACKUP_FILE"
echo "Database backed up: $BACKUP_FILE"

# Create git tag
git tag -a "$TAG" -m "DEF-54 Phase $PHASE completed successfully"
echo "Git tag created: $TAG"

# Record metrics
echo "Recording metrics..."
METRICS_FILE="docs/analyses/DEF-54-phase-metrics.txt"
echo "=== $TAG ===" &gt;&gt; $METRICS_FILE
echo "Date: $(date)" &gt;&gt; $METRICS_FILE
echo "Lines changed: $(git diff HEAD~1 --stat | tail -1)" &gt;&gt; $METRICS_FILE
echo "Test coverage: $(pytest --cov --cov-report=term | grep TOTAL)" &gt;&gt; $METRICS_FILE
echo "" &gt;&gt; $METRICS_FILE

echo "Checkpoint created successfully!"</code></pre>

<p>---</p>

<h2>5. WARNING SIGNS (When to STOP and Rollback)</h2>

<h3>Red Flags During Implementation</h3>

<h4>Immediate Rollback Triggers (STOP NOW)</h4>

<p>| Warning Sign | Severity | Action | Example |</p>
<p>|--------------|----------|--------|---------|</p>
<p>| <strong>Tests failing >5 files</strong> | ğŸ”´ CRITICAL | Rollback immediately | <code>pytest</code> shows 5+ failures |</p>
<p>| <strong>App won't start</strong> | ğŸ”´ CRITICAL | Rollback immediately | <code>ModuleNotFoundError</code> |</p>
<p>| <strong>Database locked</strong> | ğŸ”´ CRITICAL | Rollback immediately | <code>database is locked</code> error |</p>
<p>| <strong>Memory usage >2GB</strong> | ğŸ”´ CRITICAL | Rollback immediately | <code>htop</code> shows 2GB+ for Streamlit |</p>
<p>| <strong>Data corruption</strong> | ğŸ”´ CRITICAL | Rollback + restore DB | Definitions have NULL fields |</p>

<h4>Investigate Before Rollback (CAUTION)</h4>

<p>| Warning Sign | Severity | Action | Example |</p>
<p>|--------------|----------|--------|---------|</p>
<p>| <strong>1-2 tests failing</strong> | ğŸŸ¡ CAUTION | Investigate, fix or rollback | Minor test failures |</p>
<p>| <strong>Slow performance (>10s)</strong> | ğŸŸ¡ CAUTION | Profile, optimize or rollback | Saves take 10+ seconds |</p>
<p>| <strong>UI glitches</strong> | ğŸŸ¡ CAUTION | Debug, fix or rollback | Buttons don't respond |</p>
<p>| <strong>Warning logs</strong> | ğŸŸ¡ CAUTION | Review, fix or rollback | Deprecation warnings |</p>

<h4>Monitor and Continue (ACCEPTABLE)</h4>

<p>| Warning Sign | Severity | Action | Example |</p>
<p>|--------------|----------|--------|---------|</p>
<p>| <strong>Minor lint warnings</strong> | ğŸŸ¢ ACCEPTABLE | Fix in Phase 8 | Unused imports |</p>
<p>| <strong>Documentation outdated</strong> | ğŸŸ¢ ACCEPTABLE | Fix in Phase 9 | Old docstrings |</p>
<p>| <strong>Slight perf degradation (<20%)</strong> | ğŸŸ¢ ACCEPTABLE | Optimize later | Save 4.5s instead of 4s |</p>

<p>---</p>

<h3>Test Failure Thresholds</h3>

<p><strong>Rollback Decision Matrix</strong>:</p>

<pre><code>Test Pass Rate     | Action
-------------------|------------------------------------------
100%               | âœ… Proceed to next phase
95-99%             | âš ï¸ Investigate failures, fix if trivial
90-94%             | ğŸ›‘ STOP - Fix failures before proceeding
&lt; 90%              | ğŸ”´ ROLLBACK - Phase failed</code></pre>

<p><strong>Coverage Thresholds</strong>:</p>
<pre><code>Coverage           | Action
-------------------|------------------------------------------
&gt; 85%              | âœ… Acceptable
80-85%             | âš ï¸ Add tests for critical paths
70-79%             | ğŸ›‘ Add tests before proceeding
&lt; 70%              | ğŸ”´ ROLLBACK - Insufficient test coverage</code></pre>

<p>---</p>

<h3>Performance Degradation Indicators</h3>

<p><strong>Baseline Metrics</strong> (establish before Phase 0):</p>
<pre><code># scripts/measure_baseline.sh (MISSING)

#!/bin/bash

echo "=== BASELINE METRICS ===" &gt; metrics_baseline.txt

# 1. Save time (100 definitions)
echo "Measuring save time..." &gt;&gt; metrics_baseline.txt
python scripts/perf/measure_save_time.py &gt;&gt; metrics_baseline.txt

# 2. Search time (1000 queries)
echo "Measuring search time..." &gt;&gt; metrics_baseline.txt
python scripts/perf/measure_search_time.py &gt;&gt; metrics_baseline.txt

# 3. Memory usage
echo "Measuring memory..." &gt;&gt; metrics_baseline.txt
ps aux | grep streamlit &gt;&gt; metrics_baseline.txt

# 4. Database size
echo "Database size:" &gt;&gt; metrics_baseline.txt
du -h data/definities.db &gt;&gt; metrics_baseline.txt

echo "Baseline metrics saved to metrics_baseline.txt"</code></pre>

<p><strong>Rollback Triggers</strong>:</p>
<ul>
<li>Save time >2x baseline (was 4s, now 10s) â†’ ğŸ”´ ROLLBACK</li>
<li>Search time >5x baseline (was 200ms, now 1s) â†’ ğŸ”´ ROLLBACK</li>
<li>Memory usage >2x baseline (was 500MB, now 1GB) â†’ ğŸ”´ ROLLBACK</li>
<li>Database size >1.5x baseline â†’ ğŸŸ¡ INVESTIGATE</li>
</ul>

<p>---</p>

<h2>6. RECOMMENDED MODIFICATIONS TO PLAN</h2>

<h3>Modified Hybrid Plan with Enhanced Safety</h3>

<h4>Changes to Original Plan</h4>

<p><strong>ADD: Pre-Phase 0: Baseline & Backup</strong></p>
<pre><code>Duration: 0.5 days
Tasks:
- [ ] Measure baseline metrics (save/search time, memory, coverage)
- [ ] Create full database backup
- [ ] Export all definitions to CSV (emergency restore)
- [ ] Tag current commit: "DEF-54-pre-refactor-baseline"
- [ ] Document current system behavior</code></pre>

<p><strong>MODIFY: Phase 0: Schema Validation</strong></p>
<pre><code>+ Add rollback script: src/database/migrations/007_rollback.sql
+ Add integrity verification: scripts/verify_schema_integrity.sh
+ Add automated backup: cp data/definities.db data/backups/schema_before.db</code></pre>

<p><strong>MODIFY: Phase 1: Feature Flag</strong></p>
<pre><code>+ Add health check automation (see Section 2)
+ Add fallback logging (when/why flag triggered)
+ Add monitoring dashboard (track flag usage)</code></pre>

<p><strong>ADD: Phase 2.5: Concurrency Tests (MISSING)</strong></p>
<pre><code>Duration: 0.5 days
Tasks:
- [ ] Write concurrent save tests (see Blindspot 1)
- [ ] Write memory leak tests (see Blindspot 2)
- [ ] Write data integrity tests (see Blindspot 3)
- [ ] All tests should FAIL (not implemented yet)</code></pre>

<p><strong>MODIFY: Phase 5: Type Conversions</strong></p>
<pre><code>- Eliminate conversions (186 lines, 23 files)
+ SKIP THIS PHASE (keep conversions for safety)
+ Alternative: Document conversion layer in architecture
+ Rationale: 85% failure risk, minimal benefit</code></pre>

<p><strong>ADD: Phase 6.5: Integration Testing (MISSING)</strong></p>
<pre><code>Duration: 0.5 days
Tasks:
- [ ] Full workflow test (generate â†’ validate â†’ export)
- [ ] Round-trip test (export â†’ import â†’ verify)
- [ ] Bulk operations test (100 definitions)
- [ ] Error recovery test (API failure simulation)</code></pre>

<p><strong>MODIFY: Phase 7: Delete Legacy</strong></p>
<pre><code>+ Verify 0 imports with grep search
+ Create rollback tag: git tag DEF-54-legacy-deleted
+ Keep feature flag infrastructure (emergency use)
+ Add deployment checklist</code></pre>

<p>---</p>

<h3>Enhanced Timeline</h3>

<p>| Phase | Original | Modified | Reason |</p>
<p>|-------|----------|----------|--------|</p>
<p>| Pre-0: Baseline | N/A | 0.5 days | Establish metrics |</p>
<p>| 0: Schema | 0.5 days | 0.5 days | No change |</p>
<p>| 1: Feature Flag | 0.5 days | 0.5 days | No change |</p>
<p>| 2: Tests | 1 day | 1 day | No change |</p>
<p>| 2.5: Concurrency | N/A | 0.5 days | Add missing tests |</p>
<p>| 3a-3c: CRUD | 3 days | 3 days | No change |</p>
<p>| 4: Voorbeelden | 1 day | 1 day | No change |</p>
<p>| 5: Conversions | 1 day | SKIP | Too risky |</p>
<p>| 6a-6c: Callsites | 1.5 days | 1.5 days | No change |</p>
<p>| 6.5: Integration | N/A | 0.5 days | Add missing tests |</p>
<p>| 7: Delete Legacy | 0.5 days | 0.5 days | No change |</p>
<p>| 8: Code Quality | 1 day | 0.5 days | Reduced scope |</p>
<p>| 9: Docs | 0.5 days | 0.5 days | No change |</p>
<p>| <strong>TOTAL</strong> | <strong>10.5 days</strong> | <strong>10 days</strong> | Saved 0.5 days |</p>

<p>---</p>

<h2>7. EMERGENCY RECOVERY PROCEDURES</h2>

<h3>Scenario 1: Database Corrupted</h3>

<p><strong>Symptoms</strong>:</p>
<ul>
<li>Definitions have NULL values</li>
<li>Foreign key constraints violated</li>
<li>App shows "database is malformed"</li>
</ul>

<p><strong>Recovery Steps</strong>:</p>
<ol>
<li>**STOP APP IMMEDIATELY** (`pkill -f streamlit`)</li>
<li>**Backup corrupt database**: `cp data/definities.db data/corrupt_$(date +%Y%m%d_%H%M%S).db`</li>
<li>**Restore from backup**:</li>
<pre><code>   ./scripts/rollback/rollback_database.sh
   # Select most recent pre-refactor backup</code></pre>
<li>**Verify integrity**: `sqlite3 data/definities.db "PRAGMA integrity_check;"`</li>
<li>**Export all data** (in case of future corruption):</li>
<pre><code>   python scripts/export_all_definitions.py &gt; backup_export.csv</code></pre>
<li>**Restart app**: `streamlit run src/main.py`</li>
<li>**Verify functionality**: Run manual smoke tests</li>
<li>**Investigate cause**: Check git history, review changes</li>
</ol>

<p><strong>Time to Recover</strong>: 15-20 minutes</p>

<p>---</p>

<h3>Scenario 2: Feature Flag Not Working</h3>

<p><strong>Symptoms</strong>:</p>
<ul>
<li>Set `USE_LEGACY_REPO=true` but app still uses new repo</li>
<li>Or vice versa</li>
<li>Flag logic broken</li>
</ul>

<p><strong>Recovery Steps</strong>:</p>
<ol>
<li>**Verify flag is set**:</li>
<pre><code>   echo $USE_LEGACY_REPO  # Should print "true"</code></pre>
<li>**Check flag logic**:</li>
<pre><code>   # In src/services/container.py
   print(f"USE_LEGACY_REPO={os.getenv('USE_LEGACY_REPO')}")  # Debug</code></pre>
<li>**Hardcode fallback temporarily**:</li>
<pre><code>   # Emergency override
   def _create_definition_repository(self):
       # return DefinitieRepositoryV2(self.db_path)  # Comment out
       return DefinitionRepository(self.db_path)  # Force legacy</code></pre>
<li>**Restart app**</li>
<li>**Fix flag logic properly**</li>
<li>**Remove hardcoded override**</li>
</ol>

<p><strong>Time to Recover</strong>: 5-10 minutes</p>

<p>---</p>

<h3>Scenario 3: Streamlit Session State Corrupted</h3>

<p><strong>Symptoms</strong>:</p>
<ul>
<li>App slows down over time</li>
<li>Memory usage grows unbounded</li>
<li>Definitions not saving</li>
<li>UI shows stale data</li>
</ul>

<p><strong>Recovery Steps</strong>:</p>
<ol>
<li>**Clear cache**:</li>
<pre><code>   rm -rf .streamlit/cache</code></pre>
<li>**Reset session state** (add to UI):</li>
<pre><code>   # Emergency reset button
   if st.button("Reset Session (Emergency)"):
       for key in list(st.session_state.keys()):
           del st.session_state[key]
       st.experimental_rerun()</code></pre>
<li>**Restart app**</li>
<li>**Investigate memory leak**:</li>
<pre><code>   # Add to app startup
   st.write(f"Session state keys: {len(st.session_state.keys())}")
   st.write(f"Memory usage: {psutil.Process().memory_info().rss / 1024 / 1024:.1f} MB")</code></pre>
<li>**Fix root cause** (see Blindspot 2)</li>
</ol>

<p><strong>Time to Recover</strong>: 2-5 minutes</p>

<p>---</p>

<h3>Scenario 4: 23 Files Break Simultaneously (Phase 5)</h3>

<p><strong>Symptoms</strong>:</p>
<ul>
<li>After removing type conversions, app won't start</li>
<li>Multiple `AttributeError: 'DefinitieRecord' object has no attribute 'X'`</li>
<li>Tests failing across multiple modules</li>
</ul>

<p><strong>Recovery Steps</strong>:</p>
<ol>
<li>**IMMEDIATELY ROLLBACK**:</li>
<pre><code>   git reset --hard DEF-54-phase-4-voorbeelden-complete</code></pre>
<li>**Verify rollback**:</li>
<pre><code>   pytest -q  # Should pass
   streamlit run src/main.py  # Should start</code></pre>
<li>**SKIP PHASE 5** (don't retry)</li>
<li>**Document decision**:</li>
<pre><code>   # docs/decisions/DEF-54-PHASE-5-SKIPPED.md

   **Decision**: Skip Phase 5 (Type Conversions Elimination)
   **Reason**: Too risky (23 files, 85% failure probability)
   **Trade-off**: Keep 186 lines of conversion code
   **Benefit**: App stability, domain model separation</code></pre>
<li>**Continue with Phase 6**</li>
</ol>

<p><strong>Time to Recover</strong>: 5-10 minutes</p>

<p>---</p>

<h2>8. HEALTH CHECK FRAMEWORK</h2>

<h3>Automated Health Checks (MISSING)</h3>

<pre><code># src/services/health_check.py (NEW FILE)

import logging
from typing import List, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class HealthCheckResult:
    name: str
    passed: bool
    message: str
    duration_ms: float

class RepositoryHealthCheck:
    """Automated health checks for repository."""

    def __init__(self, repo):
        self.repo = repo

    def run_all_checks(self) -&gt; List[HealthCheckResult]:
        """Run all health checks."""
        checks = [
            self.check_database_connection,
            self.check_basic_crud,
            self.check_search_functionality,
            self.check_duplicate_detection,
            self.check_voorbeelden_sync,
            self.check_data_integrity,
        ]

        results = []
        for check in checks:
            try:
                result = check()
                results.append(result)
            except Exception as e:
                results.append(HealthCheckResult(
                    name=check.__name__,
                    passed=False,
                    message=f"Exception: {e}",
                    duration_ms=0
                ))

        return results

    def check_database_connection(self) -&gt; HealthCheckResult:
        """Check database is accessible."""
        import time
        start = time.time()

        try:
            # Try to query database
            self.repo.get(1)
            duration = (time.time() - start) * 1000
            return HealthCheckResult(
                name="database_connection",
                passed=True,
                message="Database accessible",
                duration_ms=duration
            )
        except Exception as e:
            return HealthCheckResult(
                name="database_connection",
                passed=False,
                message=f"Cannot access database: {e}",
                duration_ms=0
            )

    def check_basic_crud(self) -&gt; HealthCheckResult:
        """Check create/read/update/delete work."""
        import time
        start = time.time()

        try:
            # Create
            test_id = self.repo.save(DefinitieRecord(
                begrip="__HEALTH_CHECK__",
                definitie="Test",
                status="CONCEPT"
            ))

            # Read
            record = self.repo.get(test_id)
            assert record.begrip == "__HEALTH_CHECK__"

            # Update
            record.definitie = "Updated"
            self.repo.save(record)
            updated = self.repo.get(test_id)
            assert updated.definitie == "Updated"

            # Delete
            self.repo.delete(test_id)

            duration = (time.time() - start) * 1000
            return HealthCheckResult(
                name="basic_crud",
                passed=True,
                message="CRUD operations working",
                duration_ms=duration
            )
        except Exception as e:
            return HealthCheckResult(
                name="basic_crud",
                passed=False,
                message=f"CRUD failure: {e}",
                duration_ms=0
            )

    # ... more checks ...</code></pre>

<p><strong>Integration</strong>:</p>
<pre><code># src/main.py

from services.health_check import RepositoryHealthCheck

def startup_health_check():
    """Run health checks on app startup."""
    repo = get_repository()
    checker = RepositoryHealthCheck(repo)

    results = checker.run_all_checks()

    passed = sum(1 for r in results if r.passed)
    total = len(results)

    if passed &lt; total:
        st.error(f"âš ï¸ Health check failed: {passed}/{total} passed")
        st.write("Failed checks:")
        for r in results:
            if not r.passed:
                st.write(f"- {r.name}: {r.message}")

        # Auto-fallback to legacy repo
        if os.getenv("USE_LEGACY_REPO") != "true":
            st.warning("Falling back to legacy repository...")
            os.environ["USE_LEGACY_REPO"] = "true"
            st.experimental_rerun()
    else:
        st.success(f"âœ… All health checks passed ({total}/{total})")

# Run on startup
startup_health_check()</code></pre>

<p>---</p>

<h2>9. FINAL RECOMMENDATIONS</h2>

<h3>Decision: Which Plan to Use?</h3>

<p><strong>RECOMMENDED PLAN: Modified Hybrid (10 days)</strong></p>

<p><strong>Rationale</strong>:</p>
<ol>
<li>âœ… Adds missing safety mechanisms (health checks, concurrency tests)</li>
<li>âœ… Skips Phase 5 (85% failure risk)</li>
<li>âœ… Adds integration testing (Phase 6.5)</li>
<li>âœ… Comprehensive rollback procedures</li>
<li>âœ… Same timeline as simplified plan (10 days)</li>
</ol>

<p><strong>Comparison to Original Plans</strong>:</p>
<ul>
<li>vs Simplified: Adds concurrency tests, skips risky Phase 5</li>
<li>vs Accelerated: Adds 5 days, but much safer (60% less risk)</li>
<li>vs Conservative: Saves 0-2 days, similar safety level</li>
</ul>

<p>---</p>

<h3>Mandatory Pre-Requisites</h3>

<p><strong>Before starting ANY phase</strong>:</p>
<ol>
<li>âœ… Create `scripts/rollback/` directory with all rollback scripts</li>
<li>âœ… Implement health check framework (`src/services/health_check.py`)</li>
<li>âœ… Set up automated checkpoints (`scripts/rollback/create_checkpoint.sh`)</li>
<li>âœ… Measure baseline metrics (`scripts/measure_baseline.sh`)</li>
<li>âœ… Export all definitions to CSV (emergency backup)</li>
<li>âœ… Create rollback decision tree poster (print and put on wall)</li>
</ol>

<p>---</p>

<h3>Critical Success Factors</h3>

<p><strong>Phase-by-Phase</strong>:</p>
<ul>
<li>âœ… Run health checks after EVERY phase</li>
<li>âœ… Create git checkpoint after EVERY phase</li>
<li>âœ… Measure metrics after EVERY phase</li>
<li>âœ… Manual smoke test after EVERY phase</li>
<li>âœ… Review rollback procedure BEFORE each phase</li>
</ul>

<p><strong>Rollback Triggers</strong>:</p>
<ul>
<li>ğŸ”´ Any health check failure â†’ Investigate, fix or rollback</li>
<li>ğŸ”´ Test pass rate <90% â†’ Rollback</li>
<li>ğŸ”´ Performance degradation >2x â†’ Rollback</li>
<li>ğŸ”´ Memory usage >2GB â†’ Rollback</li>
<li>ğŸ”´ Database locked â†’ Rollback immediately</li>
</ul>

<p>---</p>

<h3>Risk Mitigation Checklist</h3>

<p><strong>Before starting refactor</strong>:</p>
<ul>
<li>[ ] Read all 3 planning documents</li>
<li>[ ] Read this risk analysis document</li>
<li>[ ] Understand rollback procedures (practice once)</li>
<li>[ ] Set up monitoring (health checks, metrics)</li>
<li>[ ] Create all rollback scripts</li>
<li>[ ] Backup database (multiple copies)</li>
<li>[ ] Export all definitions to CSV</li>
<li>[ ] Know when to stop and rollback</li>
</ul>

<p><strong>During refactor</strong>:</p>
<ul>
<li>[ ] Run health checks after each phase</li>
<li>[ ] Create checkpoint after each phase</li>
<li>[ ] Measure metrics vs baseline</li>
<li>[ ] Manual smoke test after each phase</li>
<li>[ ] Review rollback decision tree</li>
<li>[ ] Monitor memory usage continuously</li>
</ul>

<p><strong>After completion</strong>:</p>
<ul>
<li>[ ] Run full integration test suite</li>
<li>[ ] Verify performance metrics</li>
<li>[ ] Load test with 1000 definitions</li>
<li>[ ] Keep feature flag for 1 week (safety net)</li>
<li>[ ] Document lessons learned</li>
</ul>

<p>---</p>

<h2>10. APPENDIX: ROLLBACK DECISION TREE</h2>

<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ISSUE DETECTED DURING REFACTOR          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Is app still       â”‚
     â”‚ functional?        â”‚
     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
          â”‚ YES       â”‚ NO
          â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Can you â”‚  â”‚ ROLLBACK           â”‚
    â”‚ fix in  â”‚  â”‚ IMMEDIATELY        â”‚
    â”‚ &lt;1 hour?â”‚  â”‚ (Feature Flag or   â”‚
    â””â”€â”€â”€â”€â”¬â”€â”¬â”€â”€â”˜  â”‚ Git Revert)        â”‚
         â”‚ â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     YES â”‚ â”‚ NO
         â–¼ â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ FIX    â”‚  â”‚ Are tests passing? â”‚
    â”‚ ISSUE  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚ &gt;90%      â”‚ &lt;90%
                     â–¼           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Is perf  â”‚  â”‚ ROLLBACK   â”‚
              â”‚ degraded â”‚  â”‚            â”‚
              â”‚ &gt;2x?     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â””â”€â”€â”€â”€â”¬â”€â”¬â”€â”€â”€â”˜
               YES â”‚ â”‚ NO
                   â–¼ â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ ROLLBACK â”‚  â”‚ INVESTIGATEâ”‚
            â”‚          â”‚  â”‚ Fix or     â”‚
            â”‚          â”‚  â”‚ Rollback   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>

<p>---</p>

<h2>CONCLUSION</h2>

<p><strong>Key Takeaways</strong>:</p>

<ol>
<li>**Phase 5 is too risky** (85% failure probability) â†’ SKIP IT</li>
<li>**Database rollback is missing** â†’ Add rollback scripts BEFORE starting</li>
<li>**Health checks are critical** â†’ Implement automated checks</li>
<li>**Concurrency tests are missing** â†’ Add before Phase 3</li>
<li>**Feature flag needs health monitoring** â†’ Auto-fallback on failure</li>
</ol>

<p><strong>Recommended Approach</strong>:</p>
<ul>
<li>Use **Modified Hybrid Plan** (10 days)</li>
<li>Skip Phase 5 (keep type conversions)</li>
<li>Add Pre-Phase 0 (baseline metrics)</li>
<li>Add Phase 2.5 (concurrency tests)</li>
<li>Add Phase 6.5 (integration tests)</li>
<li>Implement all rollback scripts BEFORE Phase 0</li>
</ul>

<p><strong>Timeline</strong>: 10 days (same as simplified plan, but safer)</p>
<p><strong>Risk Level</strong>: LOW-MEDIUM (reduced from MEDIUM)</p>
<p><strong>Confidence</strong>: HIGH (comprehensive safety mechanisms)</p>

<p>---</p>

<p><strong>END OF RISK & ROLLBACK ANALYSIS</strong></p>

  </div>
</body>
</html>