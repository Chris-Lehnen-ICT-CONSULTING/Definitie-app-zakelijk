<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Level Classifier - Modulaire Refactoring Plan (Optie B)</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">‚Üê Terug naar Portal</a>
    <h1>Level Classifier - Modulaire Refactoring Plan (Optie B)</h1>

<p><strong>Status:</strong> üîµ OPTIONEEL - Alleen NA EPIC-028</p>
<p><strong>Effort:</strong> 7 story points</p>
<p><strong>Priority:</strong> LOW (Tech Debt)</p>
<p><strong>Created:</strong> 2025-10-07</p>

<p>---</p>

<h2>Executive Summary</h2>

<p><strong>BELANGRIJK:</strong> Dit plan is OPTIONEEL en alleen relevant NADAT EPIC-028 succesvol is afgerond.</p>

<p><strong>Doel:</strong> Refactor huidige monolithische <code>OntologischeAnalyzer</code> naar modulaire architectuur met herbruikbare componenten.</p>

<p><strong>Business Value:</strong></p>
<ul>
<li>Policy-based classification (meer controle voor power users)</li>
<li>Herbruikbare score generator (potentieel voor andere use cases)</li>
<li>Betere testbaarheid (mocking wordt eenvoudiger)</li>
<li>Duidelijkere separation of concerns</li>
</ul>

<p><strong>Waarschuwing:</strong></p>
<ul>
<li>Voegt complexiteit toe (1 class ‚Üí 3 classes)</li>
<li>Geen directe eindgebruiker impact</li>
<li>Risico op regressie als slecht uitgevoerd</li>
</ul>

<p>---</p>

<h2>Huidige Architectuur (Monolithisch)</h2>

<pre><code>class OntologischeAnalyzer:
    """
    All-in-one implementation:
    - Web lookup orchestration
    - Score generation (4 test functions)
    - Category classification (max logic)
    - Identity &amp; role analysis
    - Documentation generation
    """

    async def bepaal_ontologische_categorie(begrip, org, jur):
        # Stap 1-2: Context gathering
        profiel = await self._stap1_lexicale_verkenning(begrip)
        context = await self._stap2_context_analyse(begrip, org, jur)

        # Stap 3: Score + Classification (MONOLITHIC)
        scores = {
            "type": await self._test_type(begrip, profiel, context),
            "proces": await self._test_proces(begrip, profiel, context),
            "resultaat": await self._test_resultaat(begrip, profiel, context),
            "exemplaar": await self._test_exemplaar(begrip, profiel, context),
        }
        categorie = max(scores, key=scores.get)  # HARD-CODED LOGIC

        # Stap 4-6: Post-processing
        ...
        return (OntologischeCategorie(categorie), resultaat)</code></pre>

<p><strong>Problemen:</strong></p>
<ol>
<li>Score generation en classification zijn gekoppeld</li>
<li>Hard-coded `max()` logica (geen policy support)</li>
<li>Moeilijk te testen (moet hele analyzer mocken)</li>
<li>Niet herbruikbaar buiten 6-stappen protocol</li>
</ol>

<p>---</p>

<h2>Nieuwe Architectuur (Modulair)</h2>

<h3>Component 1: OntologicalScoreGenerator</h3>

<p><strong>Verantwoordelijkheid:</strong> Score generatie op basis van lexicale en semantische analyse</p>

<p><strong>Locatie:</strong> <code>src/services/ontology/score_generator.py</code></p>

<pre><code>"""Score generator voor ontologische categorie√´n."""

import logging
from typing import Any

logger = logging.getLogger(__name__)


class OntologicalScoreGenerator:
    """
    Genereert scores voor ontologische categorie√´n.

    Gebruikt lexicale patterns en semantische kenmerken om te bepalen
    hoe sterk een begrip past bij elke categorie.
    """

    async def generate_scores(
        self,
        begrip: str,
        semantic_profile: dict[str, Any],
        context_map: dict[str, Any],
    ) -&gt; dict[str, float]:
        """
        Genereer scores voor alle ontologische categorie√´n.

        Args:
            begrip: Te analyseren begrip
            semantic_profile: Semantische kenmerken (uit stap 1)
            context_map: Context informatie (uit stap 2)

        Returns:
            Dictionary met scores per categorie:
            {"type": 0.8, "proces": 0.3, "resultaat": 0.1, "exemplaar": 0.2}
        """
        scores = {}
        scores["type"] = await self._calculate_type_score(
            begrip, semantic_profile, context_map
        )
        scores["proces"] = await self._calculate_proces_score(
            begrip, semantic_profile, context_map
        )
        scores["resultaat"] = await self._calculate_resultaat_score(
            begrip, semantic_profile, context_map
        )
        scores["exemplaar"] = await self._calculate_exemplaar_score(
            begrip, semantic_profile, context_map
        )

        logger.debug(f"Generated scores for '{begrip}': {scores}")
        return scores

    async def _calculate_type_score(
        self, begrip: str, profile: dict, context: dict
    ) -&gt; float:
        """Calculate TYPE category score."""
        score = 0.0

        # Lexicale indicatoren
        type_woorden = [
            "type", "soort", "klasse", "categorie", "vorm",
            "systeem", "methode", "instrument", "tool", "middel",
        ]
        for woord in type_woorden:
            if woord in begrip.lower():
                score += 0.3

        # Sterke type woorden
        sterke_type_woorden = ["toets", "test", "document", "formulier", "certificaat"]
        for woord in sterke_type_woorden:
            if woord in begrip.lower():
                score += 0.5

        # Semantische kenmerken
        kenmerken = profile.get("semantische_kenmerken", {})
        if kenmerken.get("is_abstract", False):
            score += 0.2
        if kenmerken.get("is_concreet", False):
            score += 0.3
        if kenmerken.get("is_classificeerbaar", False):
            score += 0.4

        return min(score, 1.0)

    async def _calculate_proces_score(
        self, begrip: str, profile: dict, context: dict
    ) -&gt; float:
        """Calculate PROCES category score."""
        # Similar logic to current _test_proces()
        ...

    async def _calculate_resultaat_score(
        self, begrip: str, profile: dict, context: dict
    ) -&gt; float:
        """Calculate RESULTAAT category score."""
        # Similar logic to current _test_resultaat()
        ...

    async def _calculate_exemplaar_score(
        self, begrip: str, profile: dict, context: dict
    ) -&gt; float:
        """Calculate EXEMPLAAR category score."""
        # Similar logic to current _test_exemplaar()
        ...</code></pre>

<p><strong>Tests:</strong> <code>tests/services/ontology/test_score_generator.py</code></p>

<p>---</p>

<h3>Component 2: OntologicalLevelClassifier</h3>

<p><strong>Verantwoordelijkheid:</strong> Policy-based classificatie op basis van scores</p>

<p><strong>Locatie:</strong> <code>src/services/ontology/level_classifier.py</code></p>

<pre><code>"""Policy-based ontological level classification."""

import logging
from enum import Enum

from domain.ontological_categories import OntologischeCategorie

logger = logging.getLogger(__name__)


class ClassificationPolicy(Enum):
    """Beschikbare classificatie policies."""

    GEBALANCEERD = "gebalanceerd"  # Max score wins
    STRENG = "streng"              # Require high confidence
    CONSERVATIEF = "conservatief"  # Prefer TYPE bij ambiguity


class OntologicalLevelClassifier:
    """
    Policy-based classificatie van ontologische categorie√´n.

    Bepaalt de primaire categorie op basis van scores en gekozen policy.
    Verschillende policies bieden verschillende trade-offs tussen
    precision en recall.
    """

    def classify_level(
        self,
        scores: dict[str, float],
        text_context: str | None = None,
        policy_name: str = "gebalanceerd",
    ) -&gt; OntologischeCategorie:
        """
        Classificeer begrip op basis van scores en policy.

        Args:
            scores: Scores per categorie {"type": 0.8, "proces": 0.3, ...}
            text_context: Optionele text context voor tie-breaking
            policy_name: Policy naam ("gebalanceerd", "streng", "conservatief")

        Returns:
            OntologischeCategorie enum value

        Raises:
            ValueError: Als policy_name onbekend is
        """
        try:
            policy = ClassificationPolicy(policy_name)
        except ValueError:
            logger.warning(f"Unknown policy '{policy_name}', using 'gebalanceerd'")
            policy = ClassificationPolicy.GEBALANCEERD

        if policy == ClassificationPolicy.GEBALANCEERD:
            categorie = self._apply_gebalanceerd_policy(scores)
        elif policy == ClassificationPolicy.STRENG:
            categorie = self._apply_streng_policy(scores)
        elif policy == ClassificationPolicy.CONSERVATIEF:
            categorie = self._apply_conservatief_policy(scores)
        else:
            categorie = self._apply_gebalanceerd_policy(scores)

        logger.info(
            f"Classified as '{categorie}' using policy '{policy.value}' "
            f"(scores: {scores})"
        )
        return OntologischeCategorie(categorie)

    def _apply_gebalanceerd_policy(self, scores: dict[str, float]) -&gt; str:
        """
        Gebalanceerd: Kies categorie met hoogste score.

        Dit is de huidige default logica.
        """
        return max(scores, key=scores.get)

    def _apply_streng_policy(self, scores: dict[str, float]) -&gt; str:
        """
        Streng: Require high confidence (score &gt; 0.7).

        Bij lage confidence, fallback naar TYPE als conservatieve keuze.
        """
        max_cat = max(scores, key=scores.get)
        max_score = scores[max_cat]

        if max_score &lt; 0.7:
            logger.warning(
                f"Low confidence ({max_score:.2f}), falling back to TYPE"
            )
            return "type"

        return max_cat

    def _apply_conservatief_policy(self, scores: dict[str, float]) -&gt; str:
        """
        Conservatief: Prefer TYPE bij ambiguity.

        Bij scores binnen 0.1 van elkaar, kies TYPE als die erbij zit.
        """
        max_score = max(scores.values())
        threshold = max_score - 0.1

        # Alle candidates binnen threshold
        candidates = [cat for cat, score in scores.items() if score &gt;= threshold]

        if len(candidates) &gt; 1:
            logger.debug(f"Ambiguous classification: {candidates}")
            if "type" in candidates:
                return "type"

        return max(scores, key=scores.get)

    def get_confidence(self, scores: dict[str, float]) -&gt; float:
        """
        Bereken confidence score voor classificatie.

        Returns:
            Float tussen 0.0 en 1.0
        """
        if not scores:
            return 0.0

        max_score = max(scores.values())
        second_max = sorted(scores.values(), reverse=True)[1] if len(scores) &gt; 1 else 0.0

        # Confidence is hoog als max duidelijk hoger is dan tweede
        gap = max_score - second_max
        return min(max_score * (1 + gap), 1.0)</code></pre>

<p><strong>Tests:</strong> <code>tests/services/ontology/test_level_classifier.py</code></p>

<p>---</p>

<h3>Component 3: OntologischeAnalyzer (Refactored)</h3>

<p><strong>Verantwoordelijkheid:</strong> 6-stappen protocol orchestration met DI</p>

<p><strong>Locatie:</strong> <code>src/ontologie/ontological_analyzer.py</code> (REFACTORED)</p>

<pre><code>"""
Ontologische Analyzer - 6-stappen protocol met modulaire services.

REFACTORED: Nu met dependency injection voor score generator en classifier.
"""

import logging
from typing import Any

from domain.ontological_categories import OntologischeCategorie
from services.container import get_container
from services.interfaces import LookupRequest

logger = logging.getLogger(__name__)


class OntologischeAnalyzer:
    """
    6-stappen ontologisch protocol met modulaire architectuur.

    Dependencies:
    - score_generator: OntologicalScoreGenerator (DI)
    - level_classifier: OntologicalLevelClassifier (DI)
    """

    def __init__(self, score_generator=None, level_classifier=None):
        """
        Initialiseer analyzer met optionele dependencies.

        Als dependencies niet gegeven, gebruik ServiceContainer.
        """
        # Get container for web lookup service (unchanged)
        container = get_container()
        self.web_lookup_service = container.web_lookup()
        self.definitie_zoeker = DefinitieZoekerAdapter(self.web_lookup_service)

        # Dependency injection voor nieuwe modules
        if score_generator is None:
            from services.ontology.score_generator import OntologicalScoreGenerator
            score_generator = OntologicalScoreGenerator()

        if level_classifier is None:
            from services.ontology.level_classifier import OntologicalLevelClassifier
            level_classifier = OntologicalLevelClassifier()

        self.score_generator = score_generator
        self.level_classifier = level_classifier

        self.category_templates = self._load_category_templates()
        logger.info(
            "OntologischeAnalyzer initialized with modular services "
            f"(score_gen={type(score_generator).__name__}, "
            f"classifier={type(level_classifier).__name__})"
        )

    async def bepaal_ontologische_categorie(
        self,
        begrip: str,
        org_context: str = "",
        jur_context: str = "",
        classification_policy: str = "gebalanceerd",
    ) -&gt; tuple[OntologischeCategorie, dict[str, Any]]:
        """
        Doorloop het volledige 6-stappen protocol.

        Args:
            begrip: Te analyseren begrip
            org_context: Organisatorische context
            jur_context: Juridische context
            classification_policy: Policy voor classificatie
                ("gebalanceerd", "streng", "conservatief")

        Returns:
            (OntologischeCategorie, analyse_resultaat)
        """
        try:
            logger.info(f"Start ontologische analyse voor '{begrip}'")

            # Stap 1: Lexicale verkenning (UNCHANGED)
            semantisch_profiel = await self._stap1_lexicale_verkenning(begrip)

            # Stap 2: Context analyse (UNCHANGED)
            context_map = await self._stap2_context_analyse(
                begrip, org_context, jur_context
            )

            # Stap 3: DELEGEER naar modulaire services
            test_scores = await self.score_generator.generate_scores(
                begrip, semantisch_profiel, context_map
            )

            primaire_categorie_str = self.level_classifier.classify_level(
                scores=test_scores,
                text_context=begrip,
                policy_name=classification_policy,
            )

            # Bepaal secundaire aspecten (unchanged logic)
            max_score = test_scores[primaire_categorie_str.value]
            secundaire_aspecten = [
                cat
                for cat, score in test_scores.items()
                if cat != primaire_categorie_str.value and score &gt; 0.3
            ]

            categorie_resultaat = {
                "primaire_categorie": primaire_categorie_str.value,
                "secundaire_aspecten": secundaire_aspecten,
                "test_scores": test_scores,
                "confidence": max_score,
                "classification_policy": classification_policy,
            }

            # Stap 4-6: UNCHANGED
            identiteit_criteria = await self._stap4_identiteit_persistentie(
                begrip, categorie_resultaat
            )
            rol_analyse = await self._stap5_rol_analyse(begrip, categorie_resultaat)
            documentatie = self._stap6_documentatie(
                begrip, categorie_resultaat, identiteit_criteria, rol_analyse
            )

            # Compileer resultaat (UNCHANGED)
            analyse_resultaat = {
                "begrip": begrip,
                "semantisch_profiel": semantisch_profiel,
                "context_map": context_map,
                "categorie_resultaat": categorie_resultaat,
                "identiteit_criteria": identiteit_criteria,
                "rol_analyse": rol_analyse,
                "documentatie": documentatie,
                "reasoning": self._generate_comprehensive_reasoning(
                    begrip, categorie_resultaat, semantisch_profiel, context_map
                ),
            }

            logger.info(
                f"Analyse voltooid voor '{begrip}': "
                f"{primaire_categorie_str.value} (policy: {classification_policy})"
            )

            return (primaire_categorie_str, analyse_resultaat)

        except Exception as e:
            logger.error(f"Fout in ontologische analyse voor '{begrip}': {e}")
            return await self._fallback_analyse(begrip, org_context, jur_context)

    # Stap 1-2 blijven UNCHANGED
    # Stap 4-6 blijven UNCHANGED
    # Helper functies blijven UNCHANGED
    # _test_* functies worden VERWIJDERD (nu in score_generator)</code></pre>

<p>---</p>

<h2>Implementatie Roadmap</h2>

<h3>Fase 1: Extract Score Generator (2 SP)</h3>

<p><strong>User Story:</strong></p>
<pre><code>Als developer
Wil ik score generation gescheiden van classification
Zodat ik scores kan hergebruiken in andere contexten</code></pre>

<p><strong>Tasks:</strong></p>
<ol>
<li>[ ] Create `src/services/ontology/score_generator.py`</li>
<li>[ ] Move `_test_type()` ‚Üí `_calculate_type_score()`</li>
<li>[ ] Move `_test_proces()` ‚Üí `_calculate_proces_score()`</li>
<li>[ ] Move `_test_resultaat()` ‚Üí `_calculate_resultaat_score()`</li>
<li>[ ] Move `_test_exemplaar()` ‚Üí `_calculate_exemplaar_score()`</li>
<li>[ ] Add `generate_scores()` method</li>
<li>[ ] Create `tests/services/ontology/test_score_generator.py`</li>
<li>[ ] Test all 4 score calculations independently</li>
<li>[ ] Update `OntologischeAnalyzer._stap3_formele_categorietoets()` to use generator</li>
<li>[ ] Run full test suite ‚Üí ensure no regressions</li>
</ol>

<p><strong>Acceptance:</strong></p>
<ul>
<li>[ ] Score generator werkt standalone</li>
<li>[ ] All unit tests pass</li>
<li>[ ] Integration tests pass</li>
<li>[ ] Original analyzer functionality unchanged</li>
</ul>

<p>---</p>

<h3>Fase 2: Create Level Classifier (2 SP)</h3>

<p><strong>User Story:</strong></p>
<pre><code>Als power user
Wil ik verschillende classificatie policies kunnen kiezen
Zodat ik controle heb over type vs proces beslissingen</code></pre>

<p><strong>Tasks:</strong></p>
<ol>
<li>[ ] Create `src/services/ontology/level_classifier.py`</li>
<li>[ ] Implement `ClassificationPolicy` enum</li>
<li>[ ] Implement `classify_level()` method</li>
<li>[ ] Implement `_apply_gebalanceerd_policy()` (current max logic)</li>
<li>[ ] Implement `_apply_streng_policy()` (high confidence requirement)</li>
<li>[ ] Implement `_apply_conservatief_policy()` (prefer TYPE)</li>
<li>[ ] Implement `get_confidence()` helper</li>
<li>[ ] Create `tests/services/ontology/test_level_classifier.py`</li>
<li>[ ] Test all 3 policies with different score distributions</li>
<li>[ ] Update `OntologischeAnalyzer` to use classifier</li>
<li>[ ] Run full test suite ‚Üí ensure backwards compatibility</li>
</ol>

<p><strong>Acceptance:</strong></p>
<ul>
<li>[ ] All 3 policies work correctly</li>
<li>[ ] Policy "gebalanceerd" produces same results as old max()</li>
<li>[ ] Unit tests cover edge cases (ties, low scores, etc.)</li>
<li>[ ] Integration tests pass</li>
</ul>

<p>---</p>

<h3>Fase 3: Update Service Container & DI (1 SP)</h3>

<p><strong>User Story:</strong></p>
<pre><code>Als developer
Wil ik score generator en classifier via DI krijgen
Zodat ik makkelijk kan testen met mocks</code></pre>

<p><strong>Tasks:</strong></p>
<ol>
<li>[ ] Add `score_generator()` method to `ServiceContainer`</li>
<li>[ ] Add `level_classifier()` method to `ServiceContainer`</li>
<li>[ ] Update `ontological_analyzer()` method to inject dependencies</li>
<li>[ ] Update UI `_determine_ontological_category()` to use container</li>
<li>[ ] Update config to support classification policy setting</li>
<li>[ ] Add configuration option in UI (dropdown "Classificatie Policy")</li>
<li>[ ] Test DI injection works correctly</li>
<li>[ ] Run full test suite</li>
</ol>

<p><strong>Acceptance:</strong></p>
<ul>
<li>[ ] Container provides all 3 services</li>
<li>[ ] UI uses container for analyzer instantiation</li>
<li>[ ] No broken dependencies</li>
<li>[ ] Config changes are optional (defaults to "gebalanceerd")</li>
</ul>

<p>---</p>

<h3>Fase 4: Integration Testing & Documentation (2 SP)</h3>

<p><strong>User Story:</strong></p>
<pre><code>Als tester
Wil ik end-to-end flows testen met verschillende policies
Zodat ik zeker weet dat niets kapot is</code></pre>

<p><strong>Tasks:</strong></p>
<ol>
<li>[ ] Create `tests/integration/test_ontological_classification_policies.py`</li>
<li>[ ] Test policy "gebalanceerd" ‚Üí same as old behavior</li>
<li>[ ] Test policy "streng" ‚Üí rejects low confidence</li>
<li>[ ] Test policy "conservatief" ‚Üí prefers TYPE</li>
<li>[ ] Test UI integration (dropdown + generated definitions)</li>
<li>[ ] Test prompt module integration (ESS-02 section)</li>
<li>[ ] Test database storage (policy saved in metadata?)</li>
<li>[ ] Manual smoke test all policies via UI</li>
<li>[ ] Update `docs/architectuur/ontological_classification.md`</li>
<li>[ ] Update `CLAUDE.md` with new architecture</li>
<li>[ ] Create migration guide for users</li>
</ol>

<p><strong>Acceptance:</strong></p>
<ul>
<li>[ ] All integration tests pass</li>
<li>[ ] Manual UI testing successful</li>
<li>[ ] No regressions in existing functionality</li>
<li>[ ] Documentation up to date</li>
<li>[ ] Migration guide available</li>
</ul>

<p>---</p>

<h2>Service Container Changes</h2>

<h3>Before (Current)</h3>

<pre><code># In ServiceContainer
# (No specific method - analyzer instantiated directly in UI)</code></pre>

<h3>After (Refactored)</h3>

<pre><code># In ServiceContainer
def score_generator(self):
    """Get or create OntologicalScoreGenerator."""
    if "score_generator" not in self._instances:
        from services.ontology.score_generator import OntologicalScoreGenerator
        self._instances["score_generator"] = OntologicalScoreGenerator()
    return self._instances["score_generator"]

def level_classifier(self):
    """Get or create OntologicalLevelClassifier."""
    if "level_classifier" not in self._instances:
        from services.ontology.level_classifier import OntologicalLevelClassifier
        self._instances["level_classifier"] = OntologicalLevelClassifier()
    return self._instances["level_classifier"]

def ontological_analyzer(self):
    """Get or create OntologischeAnalyzer with DI."""
    if "ontological_analyzer" not in self._instances:
        from ontologie.ontological_analyzer import OntologischeAnalyzer
        self._instances["ontological_analyzer"] = OntologischeAnalyzer(
            score_generator=self.score_generator(),
            level_classifier=self.level_classifier(),
        )
    return self._instances["ontological_analyzer"]</code></pre>

<p>---</p>

<h2>UI Changes</h2>

<h3>Before (Current)</h3>

<pre><code># In tabbed_interface.py
async def _determine_ontological_category(self, begrip, org_context, jur_context):
    from ontologie.ontological_analyzer import OntologischeAnalyzer
    analyzer = OntologischeAnalyzer()  # Direct instantiation
    categorie, analyse = await analyzer.bepaal_ontologische_categorie(
        begrip, org_context, jur_context
    )
    # ...</code></pre>

<h3>After (Refactored)</h3>

<pre><code># In tabbed_interface.py
async def _determine_ontological_category(
    self,
    begrip,
    org_context,
    jur_context,
    classification_policy="gebalanceerd"
):
    # Get analyzer via DI container
    container = get_container()
    analyzer = container.ontological_analyzer()

    categorie, analyse = await analyzer.bepaal_ontologische_categorie(
        begrip, org_context, jur_context,
        classification_policy=classification_policy  # NEW parameter
    )
    # ...</code></pre>

<p><strong>UI Dropdown:</strong></p>
<pre><code># In definition generator tab
st.selectbox(
    "Classificatie Policy",
    options=["gebalanceerd", "streng", "conservatief"],
    help="""
    - Gebalanceerd: Kies hoogste score
    - Streng: Vereis hoge confidence (&gt;0.7)
    - Conservatief: Prefer TYPE bij ambiguity
    """,
    key="classification_policy"
)</code></pre>

<p>---</p>

<h2>Testing Strategy</h2>

<h3>Unit Tests</h3>

<p><strong>test_score_generator.py:</strong></p>
<pre><code>@pytest.mark.asyncio
async def test_calculate_type_score_high():
    generator = OntologicalScoreGenerator()
    score = await generator._calculate_type_score(
        "toets",
        {"semantische_kenmerken": {"is_concreet": True, "is_classificeerbaar": True}},
        {}
    )
    assert score == 1.0  # 0.5 (toets) + 0.3 (concreet) + 0.4 (classificeerbaar) = 1.2 ‚Üí 1.0

@pytest.mark.asyncio
async def test_generate_scores_integration():
    generator = OntologicalScoreGenerator()
    scores = await generator.generate_scores(
        "validatie",
        {"semantische_kenmerken": {"gebeurt_in_tijd": True}},
        {}
    )
    assert scores["proces"] &gt; 0.5  # -tie ending + gebeurt_in_tijd
    assert scores["proces"] &gt; scores["type"]</code></pre>

<p><strong>test_level_classifier.py:</strong></p>
<pre><code>def test_classify_gebalanceerd():
    classifier = OntologicalLevelClassifier()
    categorie = classifier.classify_level(
        {"type": 0.8, "proces": 0.3, "resultaat": 0.1, "exemplaar": 0.0},
        policy_name="gebalanceerd"
    )
    assert categorie == OntologischeCategorie.TYPE

def test_classify_streng_low_confidence():
    classifier = OntologicalLevelClassifier()
    categorie = classifier.classify_level(
        {"type": 0.6, "proces": 0.5, "resultaat": 0.4, "exemplaar": 0.3},
        policy_name="streng"
    )
    assert categorie == OntologischeCategorie.TYPE  # Fallback bij &lt; 0.7

def test_classify_conservatief_ambiguous():
    classifier = OntologicalLevelClassifier()
    categorie = classifier.classify_level(
        {"type": 0.75, "proces": 0.72, "resultaat": 0.1, "exemplaar": 0.0},
        policy_name="conservatief"
    )
    assert categorie == OntologischeCategorie.TYPE  # Prefer TYPE bij ambiguity</code></pre>

<h3>Integration Tests</h3>

<p><strong>test_ontological_classification_policies.py:</strong></p>
<pre><code>@pytest.mark.asyncio
async def test_end_to_end_gebalanceerd_policy():
    """Test dat gebalanceerd policy zelfde resultaat geeft als oude implementatie."""
    container = get_container()
    analyzer = container.ontological_analyzer()

    categorie, resultaat = await analyzer.bepaal_ontologische_categorie(
        "toets", "", "", classification_policy="gebalanceerd"
    )

    assert categorie == OntologischeCategorie.TYPE
    assert resultaat["categorie_resultaat"]["classification_policy"] == "gebalanceerd"

@pytest.mark.asyncio
async def test_end_to_end_streng_policy():
    """Test dat streng policy hogere drempel hanteert."""
    # Test met ambiguous scores
    # Verify fallback to TYPE</code></pre>

<p>---</p>

<h2>Migration Guide</h2>

<h3>For Developers</h3>

<p><strong>Old Code:</strong></p>
<pre><code>from ontologie.ontological_analyzer import OntologischeAnalyzer

analyzer = OntologischeAnalyzer()
categorie, resultaat = await analyzer.bepaal_ontologische_categorie(
    begrip, org_context, jur_context
)</code></pre>

<p><strong>New Code (Recommended):</strong></p>
<pre><code>from services.container import get_container

container = get_container()
analyzer = container.ontological_analyzer()  # Get via DI
categorie, resultaat = await analyzer.bepaal_ontologische_categorie(
    begrip, org_context, jur_context,
    classification_policy="gebalanceerd"  # Optional
)</code></pre>

<p><strong>Backwards Compatibility:</strong></p>
<p>Oude code blijft werken! Default constructor instantiates dependencies internally.</p>

<p>---</p>

<h2>Risks & Mitigations</h2>

<p>| Risk | Probability | Impact | Mitigation |</p>
<p>|------|-------------|--------|------------|</p>
<p>| Regressions in classification | MEDIUM | HIGH | Comprehensive test suite + manual testing |</p>
<p>| Performance degradation | LOW | MEDIUM | Benchmark before/after |</p>
<p>| Increased complexity confuses devs | MEDIUM | MEDIUM | Clear documentation + migration guide |</p>
<p>| Policy confusion for users | MEDIUM | LOW | Good UI help text + sensible defaults |</p>

<p>---</p>

<h2>Rollback Plan</h2>

<p><strong>If refactoring causes issues:</strong></p>

<ol>
<li>Revert commits to before Fase 1</li>
<li>Remove new files:</li>
</ol>
<ul>
<li>  - `src/services/ontology/score_generator.py`</li>
<li>  - `src/services/ontology/level_classifier.py`</li>
</ul>
<ol>
<li>Restore original `ontological_analyzer.py` from git history</li>
<li>Run tests to verify rollback success</li>
</ol>

<p><strong>Git Strategy:</strong></p>
<ul>
<li>Create feature branch `feature/modular-ontology-classification`</li>
<li>Merge to main only after ALL phases pass</li>
<li>Tag stable version before merge for easy rollback</li>
</ul>

<p>---</p>

<h2>Success Metrics</h2>

<p><strong>Technical:</strong></p>
<ul>
<li>[ ] Test coverage > 90% for new modules</li>
<li>[ ] No performance regression (< 5% overhead)</li>
<li>[ ] All existing tests still pass</li>
<li>[ ] No new linting errors</li>
</ul>

<p><strong>Functional:</strong></p>
<ul>
<li>[ ] Policy "gebalanceerd" produces identical results as old code</li>
<li>[ ] All 3 policies work as specified</li>
<li>[ ] UI dropdown functional</li>
<li>[ ] Database stores policy metadata</li>
</ul>

<p><strong>Developer Experience:</strong></p>
<ul>
<li>[ ] Mocking in tests is easier</li>
<li>[ ] Code review feedback positive</li>
<li>[ ] Documentation complete</li>
</ul>

<p>---</p>

<h2>Follow-up Work (Post-Refactoring)</h2>

<p><strong>Potential future enhancements:</strong></p>

<ol>
<li>**Custom Policies:** Allow users to define custom classification policies in config</li>
<li>**ML-based Scoring:** Replace lexical patterns with ML model</li>
<li>**Policy Analytics:** Track which policies are most used</li>
<li>**A/B Testing:** Compare policy effectiveness on real data</li>
<li>**Score Explanation:** Generate human-readable explanation of why each score was assigned</li>
</ol>

<p>---</p>

<h2>Conclusion</h2>

<p><strong>WHEN TO DO THIS:</strong></p>
<ul>
<li>‚úÖ AFTER EPIC-028 is fully complete</li>
<li>‚úÖ AFTER all feature removal is stable</li>
<li>‚úÖ AFTER test coverage is good</li>
<li>‚úÖ WHEN team has bandwidth</li>
</ul>

<p><strong>WHEN NOT TO DO THIS:</strong></p>
<ul>
<li>‚ùå During EPIC-028 cleanup</li>
<li>‚ùå When rushing to meet deadline</li>
<li>‚ùå If test coverage is low</li>
<li>‚ùå If team is under pressure</li>
</ul>

<p><strong>DEFAULT RECOMMENDATION:</strong> Wait until Q1 2026 for tech debt epic.</p>

<p>---</p>

<p><strong>Document Version:</strong> 1.0</p>
<p><strong>Author:</strong> Claude Code</p>
<p><strong>Review Status:</strong> Ready for Review</p>

  </div>
</body>
</html>