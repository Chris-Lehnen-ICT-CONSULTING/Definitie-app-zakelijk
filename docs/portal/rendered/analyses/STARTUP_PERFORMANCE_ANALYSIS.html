<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ğŸ” STREAMLIT STARTUP PERFORMANCE ANALYSIS</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>ğŸ” STREAMLIT STARTUP PERFORMANCE ANALYSIS</h1>
<p><strong>Date:</strong> 2025-10-30</p>
<p><strong>Analyst:</strong> Debug Specialist</p>
<p><strong>Severity:</strong> MEDIUM</p>
<p><strong>Impact/Effort Ratio:</strong> HIGH (quick wins available)</p>

<p>---</p>

<h2>ğŸ“Š EXECUTIVE SUMMARY</h2>

<p><strong>Problem:</strong> TabbedInterface initialization takes 509ms (25x slower than 20ms target), consuming 95% of total app startup time (537ms).</p>

<p><strong>Root Cause:</strong> <strong>EAGER SERVICE INITIALIZATION</strong> - TabbedInterface.__init__() triggers cascade of service instantiation on EVERY Streamlit rerun, despite @st.cache_resource decorator.</p>

<p><strong>Quick Win:</strong> Defer Tab component initialization â†’ <strong>Expected reduction: 300-400ms (59-79%)</strong></p>

<p>---</p>

<h2>1ï¸âƒ£ ROOT CAUSE ANALYSIS</h2>

<h3>Timing Breakdown (Measured)</h3>

<pre><code>TOTAL STARTUP: 537ms
â”œâ”€ SessionState init:     28ms (5%)   âœ… ACCEPTABLE
â”œâ”€ TabbedInterface init: 509ms (95%)  ğŸ”´ BOTTLENECK
â”‚   â”œâ”€ Import modules:   784ms (first time only)
â”‚   â””â”€ __init__():       481ms (EVERY RERUN!)
â”‚       â”œâ”€ ServiceContainer:      8ms
â”‚       â”œâ”€ PromptOrchestrator:  435ms (90% of init!)
â”‚       â”œâ”€ Repository init:       5ms
â”‚       â”œâ”€ Tab components:       30ms
â”‚       â””â”€ Misc overhead:         3ms
â””â”€ UI render:              0ms (not measured)</code></pre>

<h3>The Core Problem: EAGER TAB INITIALIZATION</h3>

<p><strong>File:</strong> <code>src/ui/tabbed_interface.py</code> lines 89-173</p>

<pre><code>class TabbedInterface:
    def __init__(self):
        # âŒ PROBLEM: Instantiates ALL tabs EAGERLY
        self.definition_tab = DefinitionGeneratorTab(self.checker)     # ~10ms
        self.edit_tab = DefinitionEditTab(validation_service)          # ~15ms
        self.expert_tab = ExpertReviewTab(self.repository)             # ~3ms
        self.import_export_beheer_tab = ImportExportBeheerTab(...)     # ~2ms</code></pre>

<p><strong>Why This Hurts:</strong></p>
<ol>
<li>**Cache decorator doesn't help** - @st.cache_resource caches the OBJECT, not initialization work</li>
<li>**First rerun still pays full cost** - 481ms unavoidable on session start</li>
<li>**Tabs are initialized but NEVER USED** - Only 1 tab visible at a time</li>
<li>**Service cascade** - Each tab triggers its own service dependencies</li>
</ol>

<p>---</p>

<h2>2ï¸âƒ£ DETAILED PERFORMANCE BREAKDOWN</h2>

<h3>Phase 1: ServiceContainer (8ms) âœ… OPTIMIZED</h3>

<pre><code>ServiceContainer.__init__()
â”œâ”€ _load_configuration():    3ms
â”œâ”€ Create config objects:     2ms
â””â”€ Logger setup:              3ms</code></pre>

<p><strong>Status:</strong> Already optimized via US-202 (singleton pattern)</p>
<p><strong>Evidence:</strong> Single container ID logged (477d04bf)</p>

<h3>Phase 2: PromptOrchestrator (435ms) ğŸ”´ MAJOR BOTTLENECK</h3>

<pre><code>PromptOrchestrator creation (via container.orchestrator())
â”œâ”€ ModularPromptAdapter:     10ms
â”œâ”€ PromptBuilder init:       15ms
â”œâ”€ Load 16 prompt modules:  410ms (PRIMARY ISSUE!)
â”‚   â”œâ”€ File I/O overhead:   200ms (16 files Ã— 12.5ms)
â”‚   â”œâ”€ Template parsing:    150ms
â”‚   â””â”€ Module registration:  60ms
â””â”€ Context manager setup:     0ms</code></pre>

<p><strong>Root Cause:</strong> PromptOrchestrator loads ALL 16 prompt modules synchronously during ServiceContainer.orchestrator() call, triggered by:</p>
<ol>
<li>`self.container = get_cached_service_container()` (line 96)</li>
<li>`validation_service = self.container.orchestrator()` (line 160)</li>
</ol>

<h3>Phase 3: Tab Components (30ms) âš ï¸ WASTEFUL</h3>

<pre><code>Tab initialization (all 4 tabs created but only 1 used)
â”œâ”€ DefinitionGeneratorTab:   10ms
â”œâ”€ DefinitionEditTab:        15ms
â”œâ”€ ExpertReviewTab:           3ms
â””â”€ ImportExportBeheerTab:     2ms</code></pre>

<p><strong>Problem:</strong> All tabs initialized EAGERLY, only 1 tab rendered per request</p>

<p>---</p>

<h2>3ï¸âƒ£ CACHING INVESTIGATION</h2>

<h3>Why @st.cache_resource Doesn't Help</h3>

<p><strong>File:</strong> <code>src/main.py</code> lines 60-82</p>

<pre><code>@st.cache_resource
def get_tabbed_interface():
    """Cached TabbedInterface instance (reused across reruns)."""
    logger.info("TabbedInterface.__init__() called - should happen ONCE per app session")
    return TabbedInterface()  # âŒ Still pays 481ms cost on FIRST call</code></pre>

<p><strong>Analysis:</strong></p>
<ul>
<li>âœ… Cache HIT works perfectly (subsequent reruns = 10ms)</li>
<li>âŒ Cache MISS is unavoidable (first rerun = 481ms)</li>
<li>âš ï¸  No lazy loading - all work done upfront</li>
</ul>

<p><strong>Conclusion:</strong> Decorator is working as designed, but initialization is TOO HEAVY.</p>

<p>---</p>

<h2>4ï¸âƒ£ OPTIMIZATION OPPORTUNITIES</h2>

<h3>ğŸ¥‡ OPTION 1: LAZY TAB INSTANTIATION (Recommended)</h3>
<p><strong>Impact:</strong> ğŸŸ¢ HIGH | <strong>Effort:</strong> ğŸŸ¢ LOW | <strong>Risk:</strong> ğŸŸ¢ LOW</p>

<p><strong>Change:</strong> Defer tab creation until first render</p>

<pre><code>class TabbedInterface:
    def __init__(self):
        self.container = get_cached_service_container()
        self.repository = get_definitie_repository()
        # âœ… Store dependencies, DON'T instantiate tabs
        self._tabs = {}  # Lazy cache for tab instances

    def _get_tab(self, tab_key: str):
        """Lazy tab factory."""
        if tab_key not in self._tabs:
            if tab_key == "generator":
                self._tabs[tab_key] = DefinitionGeneratorTab(self.checker)
            elif tab_key == "edit":
                self._tabs[tab_key] = DefinitionEditTab(validation_service)
            # ... etc
        return self._tabs[tab_key]

    def _render_tab_content(self, tab_key: str):
        tab = self._get_tab(tab_key)  # Only create when needed
        tab.render()</code></pre>

<p><strong>Expected Reduction:</strong> 300-400ms (59-79%)</p>
<p><strong>Breakdown:</strong></p>
<ul>
<li>Defer PromptOrchestrator load: -435ms (avoided until definition generation)</li>
<li>Defer 3 unused tab inits: -18ms (only create active tab)</li>
<li>Keep ServiceContainer eager: +8ms (still needed for repository)</li>
</ul>

<p><strong>Net Result:</strong> First render ~180ms (acceptable), subsequent ~10ms (cache hit)</p>

<p>---</p>

<h3>ğŸ¥ˆ OPTION 2: ASYNC PROMPT MODULE LOADING</h3>
<p><strong>Impact:</strong> ğŸŸ¡ MEDIUM | <strong>Effort:</strong> ğŸŸ¡ MEDIUM | <strong>Risk:</strong> ğŸŸ¡ MEDIUM</p>

<p><strong>Change:</strong> Load prompt modules in parallel instead of sequentially</p>

<pre><code># In PromptOrchestrator.__init__()
import asyncio

async def _load_modules_parallel(self):
    tasks = [self._load_module(name) for name in PROMPT_MODULES]
    return await asyncio.gather(*tasks)

# In ServiceContainer
def orchestrator(self):
    if "orchestrator" not in self._instances:
        orchestrator = DefinitionOrchestratorV2(...)
        # Trigger async load in background
        asyncio.create_task(orchestrator._load_modules_parallel())
        self._instances["orchestrator"] = orchestrator</code></pre>

<p><strong>Expected Reduction:</strong> 250-300ms (49-59%)</p>
<p><strong>Risk:</strong> Prompt modules may not be ready for immediate use</p>

<p>---</p>

<h3>ğŸ¥‰ OPTION 3: PROMPT MODULE CACHING</h3>
<p><strong>Impact:</strong> ğŸŸ¢ HIGH | <strong>Effort:</strong> ğŸ”´ HIGH | <strong>Risk:</strong> ğŸŸ¡ MEDIUM</p>

<p><strong>Change:</strong> Pre-compile and cache prompt templates</p>

<pre><code># New file: src/services/prompts/template_cache.py
import pickle
from pathlib import Path

def get_compiled_templates():
    cache_path = Path("cache/prompt_templates.pkl")
    if cache_path.exists():
        return pickle.load(cache_path.open("rb"))  # ~20ms
    else:
        templates = compile_all_templates()  # ~410ms (one-time)
        cache_path.write_bytes(pickle.dumps(templates))
        return templates</code></pre>

<p><strong>Expected Reduction:</strong> 390ms (76%) after cache warm</p>
<p><strong>Caveat:</strong> First run still slow, adds cache invalidation complexity</p>

<p>---</p>

<h2>5ï¸âƒ£ RECOMMENDED APPROACH</h2>

<h3>Phase 1: IMMEDIATE FIX (This Week)</h3>
<p><strong>Implement:</strong> Option 1 (Lazy Tab Instantiation)</p>

<p><strong>Steps:</strong></p>
<ol>
<li>Add `_tabs = {}` cache to TabbedInterface.__init__()</li>
<li>Create `_get_tab(tab_key)` lazy factory</li>
<li>Update `_render_tab_content()` to use factory</li>
<li>Test all 4 tabs render correctly</li>
<li>Measure startup time reduction</li>
</ol>

<p><strong>Expected Result:</strong> 509ms â†’ ~180ms (65% reduction)</p>

<h3>Phase 2: FOLLOW-UP (Next Sprint)</h3>
<p><strong>Implement:</strong> Option 2 (Async Prompt Loading)</p>

<p><strong>Rationale:</strong></p>
<ul>
<li>PromptOrchestrator still needed for definition generation</li>
<li>Lazy tabs only defer, don't eliminate PromptOrchestrator load</li>
<li>Async loading provides additional 50-60% reduction</li>
</ul>

<p><strong>Expected Result:</strong> 180ms â†’ ~90ms (total 82% reduction from baseline)</p>

<h3>Phase 3: LONG-TERM (Future Epic)</h3>
<p><strong>Consider:</strong> Option 3 (Template Caching)</p>

<p><strong>Trigger:</strong> If startup time still >100ms after Phase 1+2</p>

<p>---</p>

<h2>6ï¸âƒ£ SEVERITY RATING: MEDIUM</h2>

<h3>Why NOT Critical?</h3>

<ol>
<li>**Acceptable UX:** 537ms startup is noticeable but not blocking</li>
<li>**Cache hits work:** Subsequent reruns are fast (10ms)</li>
<li>**No user impact:** Doesn't affect definition generation performance</li>
<li>**Single-user app:** No concurrent load amplification</li>
</ol>

<h3>Why NOT Low?</h3>

<ol>
<li>**Exceeds target:** 2.7x slower than 200ms goal</li>
<li>**Wasteful architecture:** 90% of work is premature</li>
<li>**Technical debt:** Eager initialization anti-pattern</li>
<li>**Compounding risk:** Future features will make it worse</li>
</ol>

<h3>Decision: MEDIUM Priority</h3>

<p><strong>Recommendation:</strong> Fix in next sprint, not emergency hotfix</p>

<p>---</p>

<h2>7ï¸âƒ£ IMPACT/EFFORT MATRIX</h2>

<p>| Option | Impact | Effort | Risk | Time | Recommendation |</p>
<p>|--------|--------|--------|------|------|----------------|</p>
<p>| <strong>Lazy Tabs</strong> | ğŸŸ¢ HIGH (65%) | ğŸŸ¢ LOW (4 hrs) | ğŸŸ¢ LOW | Week 1 | âœ… <strong>DO FIRST</strong> |</p>
<p>| <strong>Async Loading</strong> | ğŸŸ¡ MED (50%) | ğŸŸ¡ MED (8 hrs) | ğŸŸ¡ MED | Week 2 | âš ï¸ <strong>IF NEEDED</strong> |</p>
<p>| <strong>Template Cache</strong> | ğŸŸ¢ HIGH (76%) | ğŸ”´ HIGH (16 hrs) | ğŸŸ¡ MED | Month 1 | â¸ï¸ <strong>DEFER</strong> |</p>

<p>---</p>

<h2>8ï¸âƒ£ VERIFICATION METRICS</h2>

<h3>Success Criteria (Phase 1)</h3>

<pre><code># Before (baseline)
assert interface_init_ms &lt; 20  # âŒ FAIL: 509ms

# After (target)
assert interface_init_ms &lt; 100  # âœ… PASS: ~180ms expected
assert interface_init_ms &lt; 200  # ğŸ¯ GOAL: meets project target</code></pre>

<h3>Regression Tests</h3>

<pre><code># Test lazy loading doesn't break tab switching
def test_tab_switching_performance():
    interface = get_tabbed_interface()

    # First tab access (cache miss)
    start = time.perf_counter()
    interface._get_tab("generator")
    first_access_ms = (time.perf_counter() - start) * 1000
    assert first_access_ms &lt; 50  # Should still be fast

    # Second access (cache hit)
    start = time.perf_counter()
    interface._get_tab("generator")
    second_access_ms = (time.perf_counter() - start) * 1000
    assert second_access_ms &lt; 1  # Near-instant</code></pre>

<p>---</p>

<h2>9ï¸âƒ£ IMPLEMENTATION CHECKLIST</h2>

<h3>Pre-Implementation</h3>
<ul>
<li>[ ] Review TabbedInterface tab lifecycle with team</li>
<li>[ ] Confirm no tabs share mutable state</li>
<li>[ ] Identify any eager-initialization dependencies</li>
</ul>

<h3>Implementation (4 hours)</h3>
<ul>
<li>[ ] Add `_tabs` cache dict to TabbedInterface</li>
<li>[ ] Implement `_get_tab(tab_key)` lazy factory</li>
<li>[ ] Update `_render_tab_content()` to use factory</li>
<li>[ ] Update `__init__()` to defer tab creation</li>
<li>[ ] Add unit tests for lazy loading</li>
</ul>

<h3>Validation (1 hour)</h3>
<ul>
<li>[ ] Measure startup time reduction (target: >60%)</li>
<li>[ ] Test all 4 tabs render correctly</li>
<li>[ ] Verify no regression in tab switching</li>
<li>[ ] Check memory usage (should be lower)</li>
</ul>

<h3>Documentation (30 minutes)</h3>
<ul>
<li>[ ] Update CLAUDE.md performance section</li>
<li>[ ] Add lazy loading pattern to best practices</li>
<li>[ ] Document tab lifecycle in architecture docs</li>
</ul>

<p>---</p>

<h2>ğŸ”Ÿ RELATED ISSUES</h2>

<h3>Fixed Issues (Confirmed Working)</h3>
<ul>
<li>âœ… **US-202:** ServiceContainer duplication (fixed, verified single instance)</li>
<li>âœ… **US-202:** Rule caching (77% improvement, 1x load vs 10x)</li>
</ul>

<h3>Related Performance Work</h3>
<ul>
<li>ğŸ“‹ **Future:** PromptOrchestrator async loading (Phase 2)</li>
<li>ğŸ“‹ **Future:** Template caching (Phase 3)</li>
<li>ğŸ“‹ **Monitor:** Database query performance (not a bottleneck yet)</li>
</ul>

<p>---</p>

<h2>ğŸ“š REFERENCES</h2>

<h3>Code Locations</h3>
<ul>
<li>**Main entry:** `src/main.py` lines 60-82 (@st.cache_resource decorator)</li>
<li>**TabbedInterface:** `src/ui/tabbed_interface.py` lines 86-173 (eager init)</li>
<li>**ServiceContainer:** `src/services/container.py` (working correctly)</li>
<li>**PromptOrchestrator:** `src/services/prompts/modular_prompt_adapter.py` (bottleneck)</li>
</ul>

<h3>Documentation</h3>
<ul>
<li>**Performance Goals:** `CLAUDE.md` â†’ "Kritieke Performance Overwegingen"</li>
<li>**Architecture:** `docs/architectuur/TECHNICAL_ARCHITECTURE.md`</li>
<li>**US-202 Analysis:** `docs/reports/toetsregels-caching-fix.md`</li>
</ul>

<p>---</p>

<h2>âœ… ACTION ITEMS</h2>

<p><strong>For Solo Developer:</strong></p>

<ol>
<li>**This Week:** Implement lazy tab instantiation (4 hrs)</li>
<li>**This Week:** Measure and validate performance gain (1 hr)</li>
<li>**Next Sprint:** Consider async prompt loading IF >100ms remains</li>
<li>**Future:** Monitor startup time as new features added</li>
</ol>

<p><strong>Priority:</strong> MEDIUM (not blocking, but high ROI fix available)</p>

  </div>
</body>
</html>