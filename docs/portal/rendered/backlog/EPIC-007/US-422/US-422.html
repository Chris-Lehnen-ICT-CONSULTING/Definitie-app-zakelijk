<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Advanced Duplicate Detection with ML</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <p>---</p>
<p>id: US-422</p>
<p>epic: EPIC-007</p>
<p>titel: Advanced Duplicate Detection with ML</p>
<p>type: feature</p>
<p>status: proposed</p>
<p>prioriteit: LOW</p>
<p>story_points: 13</p>
<p>sprint: backlog</p>
<p>aangemaakt: 2025-01-29</p>
<p>bijgewerkt: 2025-01-29</p>
<p>owner: data-scientist</p>
<p>applies_to: definitie-app@current</p>
<p>canonical: false</p>
<p>last_verified: 2025-01-29</p>
<p>vereisten:</p>
<ul>
<li> - REQ-007</li>
<li> - REQ-095</li>
<p>toegewezen_aan: development-team</p>
<p>---</p>
</ul>

<h1>US-422: Advanced Duplicate Detection with ML</h1>

<p><strong>Epic:</strong> EPIC-007 - Performance & Scaling</p>

<h2>Gebruikersverhaal</h2>

<p><strong>Als een</strong> data administrator</p>
<p><strong>wil ik</strong> intelligente duplicate detection met machine learning</p>
<p><strong>zodat</strong> ik semantisch vergelijkbare definities kan identificeren die niet exact matchen</p>

<h2>Probleembeschrijving</h2>

<p>De huidige duplicate detection (placeholder in <code>ui/components/management_tab.py:1114-1126</code>) detecteert alleen exacte matches op basis van begrip + context. Dit mist:</p>
<ul>
<li>Semantisch vergelijkbare definities met andere bewoordingen</li>
<li>Definities met typfouten of variaties</li>
<li>Near-duplicates met kleine verschillen</li>
<li>Cross-context duplicates die eigenlijk hetzelfde betekenen</li>
</ul>

<p>Een ML-gebaseerde aanpak kan:</p>
<ul>
<li>Embeddings gebruiken voor semantische vergelijking</li>
<li>Fuzzy matching voor spelling variaties</li>
<li>Contextual similarity voor cross-domain duplicates</li>
<li>Automatische merge suggesties genereren</li>
</ul>

<h2>Acceptatiecriteria</h2>

<h3>Functionele Criteria</h3>
<ul>
<li>[ ] Detecteer semantisch vergelijkbare definities (>85% similarity)</li>
<li>[ ] Identificeer spelling variaties en typfouten</li>
<li>[ ] Cross-context duplicate detection</li>
<li>[ ] Similarity score voor elk paar (0-100%)</li>
<li>[ ] Merge suggestions met preview</li>
<li>[ ] Bulk merge capability met undo</li>
<li>[ ] Whitelist voor false positives</li>
<li>[ ] Export duplicate rapport</li>
</ul>

<h3>Technische Criteria</h3>
<ul>
<li>[ ] Sentence embeddings voor semantische vergelijking</li>
<li>[ ] Levenshtein distance voor spelling variaties</li>
<li>[ ] TF-IDF voor keyword similarity</li>
<li>[ ] Async processing voor grote datasets</li>
<li>[ ] Caching van embeddings voor performance</li>
<li>[ ] Incremental updates bij nieuwe definities</li>
</ul>

<h3>ML Criteria</h3>
<ul>
<li>[ ] Pre-trained Dutch language model (bijv. BERTje)</li>
<li>[ ] Fine-tuning op juridische terminologie</li>
<li>[ ] Threshold configuratie per categorie</li>
<li>[ ] Confidence scores voor suggestions</li>
<li>[ ] Active learning van user feedback</li>
</ul>

<h2>Implementatie Details</h2>

<h3>Duplicate Detection Service</h3>
<pre><code>class AdvancedDuplicateDetector:
    """ML-powered duplicate detection."""

    def __init__(self):
        self.embedder = DutchEmbedder()  # BERTje of vergelijkbaar
        self.fuzzy_matcher = FuzzyMatcher()
        self.cache = EmbeddingCache()

    async def find_duplicates(self,
                             threshold: float = 0.85) -&gt; List[DuplicateCluster]:
        """Find duplicate clusters using ML."""
        definitions = await self._get_all_definitions()
        embeddings = await self._compute_embeddings(definitions)

        clusters = []
        for i, def1 in enumerate(definitions):
            similar = self._find_similar(
                def1,
                embeddings[i],
                definitions[i+1:],
                embeddings[i+1:],
                threshold
            )
            if similar:
                clusters.append(DuplicateCluster(def1, similar))

        return clusters

    async def _compute_embeddings(self,
                                 definitions: List[Definition]) -&gt; np.ndarray:
        """Compute or retrieve cached embeddings."""
        embeddings = []
        for definition in definitions:
            cache_key = f"emb_{definition.id}_{definition.version}"

            if cached := self.cache.get(cache_key):
                embeddings.append(cached)
            else:
                embedding = await self.embedder.encode(
                    definition.begrip + " " + definition.definitie
                )
                self.cache.set(cache_key, embedding)
                embeddings.append(embedding)

        return np.array(embeddings)

    def _find_similar(self,
                     target: Definition,
                     target_embedding: np.ndarray,
                     candidates: List[Definition],
                     candidate_embeddings: np.ndarray,
                     threshold: float) -&gt; List[SimilarDefinition]:
        """Find similar definitions above threshold."""
        similarities = cosine_similarity(
            target_embedding.reshape(1, -1),
            candidate_embeddings
        )[0]

        similar = []
        for idx, score in enumerate(similarities):
            if score &gt;= threshold:
                # Additional checks
                fuzzy_score = self.fuzzy_matcher.ratio(
                    target.definitie,
                    candidates[idx].definitie
                )

                similar.append(SimilarDefinition(
                    definition=candidates[idx],
                    semantic_score=score,
                    fuzzy_score=fuzzy_score,
                    overall_score=(score + fuzzy_score) / 2
                ))

        return sorted(similar, key=lambda x: x.overall_score, reverse=True)

    async def suggest_merge(self,
                          cluster: DuplicateCluster) -&gt; MergeSuggestion:
        """Generate intelligent merge suggestion."""
        # Bepaal beste versie als master
        master = self._select_master(cluster)

        # Combineer beste eigenschappen
        merged = Definition(
            begrip=master.begrip,
            definitie=self._merge_definitions(cluster),
            categorie=self._most_common_category(cluster),
            organisatorische_context=self._merge_contexts(cluster),
            validation_score=max(d.validation_score for d in cluster.definitions)
        )

        return MergeSuggestion(
            master=master,
            merged=merged,
            confidence=self._calculate_merge_confidence(cluster)
        )</code></pre>

<h3>Fuzzy Matching</h3>
<pre><code>class FuzzyMatcher:
    """Fuzzy string matching for variations."""

    def ratio(self, str1: str, str2: str) -&gt; float:
        """Calculate similarity ratio."""
        # Normaliseer strings
        s1 = self._normalize(str1)
        s2 = self._normalize(str2)

        # Combineer verschillende metrics
        levenshtein = 1 - (editdistance.eval(s1, s2) / max(len(s1), len(s2)))
        jaccard = self._jaccard_similarity(s1.split(), s2.split())
        ngram = self._ngram_similarity(s1, s2, n=3)

        return (levenshtein + jaccard + ngram) / 3

    def _normalize(self, text: str) -&gt; str:
        """Normalize text for comparison."""
        return text.lower().strip()

    def _jaccard_similarity(self, set1: set, set2: set) -&gt; float:
        """Jaccard similarity tussen word sets."""
        intersection = len(set1.intersection(set2))
        union = len(set1.union(set2))
        return intersection / union if union &gt; 0 else 0

    def _ngram_similarity(self, str1: str, str2: str, n: int = 3) -&gt; float:
        """N-gram similarity."""
        ngrams1 = set(str1[i:i+n] for i in range(len(str1) - n + 1))
        ngrams2 = set(str2[i:i+n] for i in range(len(str2) - n + 1))
        return self._jaccard_similarity(ngrams1, ngrams2)</code></pre>

<h3>ML Model Configuration</h3>
<pre><code># config/ml_duplicate_detection.yaml
model:
  type: "sentence-transformers"
  name: "GroNLP/bert-base-dutch-cased"
  max_sequence_length: 512

thresholds:
  semantic_similarity: 0.85
  fuzzy_matching: 0.80
  overall_score: 0.82

categories:
  # Different thresholds per category
  proces:
    semantic: 0.87
    fuzzy: 0.83
  type:
    semantic: 0.85
    fuzzy: 0.80
  resultaat:
    semantic: 0.88
    fuzzy: 0.85

cache:
  embedding_ttl: 86400  # 24 hours
  max_size: 10000

active_learning:
  enabled: true
  feedback_threshold: 10  # Retrain after 10 feedback items</code></pre>

<h2>Definition of Done</h2>

<ul>
<li>[ ] ML duplicate detection service geÃ¯mplementeerd</li>
<li>[ ] Embedding cache voor performance</li>
<li>[ ] Fuzzy matching algorithms</li>
<li>[ ] Merge suggestion engine</li>
<li>[ ] UI voor duplicate review</li>
<li>[ ] Bulk merge functionaliteit</li>
<li>[ ] Undo capability voor merges</li>
<li>[ ] Whitelist management</li>
<li>[ ] Unit tests (>85% coverage)</li>
<li>[ ] Performance test met 10k+ definities</li>
<li>[ ] A/B test met users (ML vs exact matching)</li>
<li>[ ] Documentation voor configuratie</li>
<li>[ ] Training data voor fine-tuning</li>
</ul>

<h2>Risico's</h2>

<p>| Risico | Impact | Kans | Mitigatie |</p>
<p>|--------|--------|------|-----------|</p>
<p>| False positives | Medium | Medium | Configureerbare thresholds, whitelist |</p>
<p>| Performance met grote datasets | High | Medium | Caching, async processing |</p>
<p>| Model accuracy juridische termen | High | Low | Fine-tuning op domain data |</p>
<p>| Memory gebruik embeddings | Medium | Low | Incremental processing |</p>
<p>| User acceptance auto-merge | Medium | Medium | Preview, undo, confidence scores |</p>

<h2>Dependencies</h2>

<ul>
<li>Sentence transformers library</li>
<li>Pre-trained Dutch language model</li>
<li>Vector similarity libraries (faiss/annoy)</li>
<li>Fuzzy matching libraries (fuzzywuzzy/rapidfuzz)</li>
<li>Async processing framework</li>
</ul>

<h2>Notes</h2>

<ul>
<li>Start met pre-trained model, fine-tune later</li>
<li>Begin met conservative thresholds (meer false negatives dan positives)</li>
<li>Implementeer feedback loop voor model verbetering</li>
<li>Consider offline batch processing voor grote datasets</li>
<li>Mogelijk toekomstige integratie met externe knowledge bases</li>
</ul>

<h2>Mockups</h2>

<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Duplicate Detection Results          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ Found 3 duplicate clusters             â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Cluster 1 (95% confidence)      â”‚    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ â”‚ âš¡ "Authenticatie" (DJI)         â”‚    â”‚
â”‚ â”‚ âš¡ "Authentificatie" (OM)        â”‚    â”‚
â”‚ â”‚    â†’ Spelling variation detected â”‚    â”‚
â”‚ â”‚                                  â”‚    â”‚
â”‚ â”‚ [ğŸ‘ï¸ Preview Merge] [âœ… Merge]   â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚ â”‚ Cluster 2 (87% confidence)      â”‚    â”‚
â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚ â”‚ ğŸ“„ "Vonnis" (Strafrecht)         â”‚    â”‚
â”‚ â”‚ ğŸ“„ "Uitspraak" (Strafrecht)      â”‚    â”‚
â”‚ â”‚    â†’ Semantic similarity         â”‚    â”‚
â”‚ â”‚                                  â”‚    â”‚
â”‚ â”‚ [ğŸ‘ï¸ Preview] [â• Whitelist]     â”‚    â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                         â”‚
â”‚ [â¬‡ï¸ Export Report] [âš™ï¸ Settings]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>
  </div>
</body>
</html>