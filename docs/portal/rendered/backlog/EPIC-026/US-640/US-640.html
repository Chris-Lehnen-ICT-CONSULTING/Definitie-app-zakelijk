<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>US-640: titel: Set up Test Infrastructure (Phase 0)</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <p>---</p>
<p>id: US-640</p>
<p>epic: EPIC-026</p>
<p>titel: "US-640: titel: Set up Test Infrastructure (Phase 0)"</p>
<p>owner: test-engineer</p>
<p>prioriteit: P0</p>
<p>status: pending</p>
<p>estimate: 1 week</p>
<p>sprint: Phase 0 Week 1</p>
<p>created: 2025-10-03</p>
<p>---</p>

<h1>US-640: Set up Test Infrastructure (Phase 0)</h1>

<p><strong>Epic:</strong> EPIC-026 - God Object Refactoring</p>
<p><strong>Owner:</strong> Test Engineer</p>
<p><strong>Priority:</strong> P0 (CRITICAL - blocks all refactoring)</p>
<p><strong>Estimate:</strong> 1 week (5 days)</p>
<p><strong>Sprint:</strong> Phase 0 Week 1</p>

<p>---</p>

<h2>User Story</h2>

<p><strong>As a</strong> test engineer</p>
<p><strong>I want to</strong> set up comprehensive test infrastructure for Streamlit</p>
<p><strong>So that</strong> we can safely refactor 4,318 LOC of god objects with 0% current coverage</p>

<p>---</p>

<h2>Context</h2>

<p><strong>Current State:</strong></p>
<ul>
<li>tabbed_interface.py: 1,793 LOC, **0 tests** (Regression Risk: 3,156 â˜¢ï¸)</li>
<li>definition_generator_tab.py: 2,525 LOC, **1 test** (Regression Risk: 2,847 ğŸ”´)</li>
<li>No Streamlit test harness exists</li>
<li>Cannot safely refactor without tests</li>
</ul>

<p><strong>Goal:</strong> Build test infrastructure that enables 436 tests to be created in Phase 0</p>

<p>---</p>

<h2>Acceptance Criteria</h2>

<h3>AC1: Streamlit Test Harness Operational</h3>
<ul>
<li>[ ] pytest-playwright installed and configured</li>
<li>[ ] Streamlit app can be launched in test mode</li>
<li>[ ] Basic navigation tests working (5 test scenarios)</li>
<li>[ ] Session state mocking functional</li>
<li>[ ] Test runs in CI/CD pipeline</li>
</ul>

<h3>AC2: Golden Master Framework</h3>
<ul>
<li>[ ] Golden master testing library integrated</li>
<li>[ ] Can record current behavior (baseline capture)</li>
<li>[ ] Can compare post-refactor vs baseline</li>
<li>[ ] Diff reporting for failures</li>
</ul>

<h3>AC3: Async Test Patterns</h3>
<ul>
<li>[ ] async/await test patterns working</li>
<li>[ ] Can test asyncio.run() bridge (57 files use it)</li>
<li>[ ] Event loop mocking functional</li>
<li>[ ] No flaky async tests</li>
</ul>

<h3>AC4: Mock Infrastructure</h3>
<ul>
<li>[ ] AIServiceV2 mocking (GPT-4 calls)</li>
<li>[ ] Database mocking (SQLite)</li>
<li>[ ] External service mocking (Wikipedia, SRU)</li>
<li>[ ] Mock fixtures reusable</li>
</ul>

<h3>AC5: Documentation</h3>
<ul>
<li>[ ] Test infrastructure guide created (`docs/testing/EPIC-026-test-infrastructure.md`)</li>
<li>[ ] Example tests for each pattern</li>
<li>[ ] Troubleshooting guide for common issues</li>
</ul>

<p>---</p>

<h2>Technical Requirements</h2>

<h3>Libraries to Install</h3>

<pre><code>pip install pytest-playwright pytest-asyncio pytest-mock pytest-golden
playwright install chromium</code></pre>

<h3>Test Structure</h3>

<pre><code>tests/epic-026/
â”œâ”€â”€ conftest.py                    # Shared fixtures
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ test_streamlit_harness.py  # Basic harness tests
â”‚   â”œâ”€â”€ test_golden_master.py      # Golden master validation
â”‚   â””â”€â”€ test_async_patterns.py     # Async test patterns
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_generation_flow.py    # 5 integration scenarios (PoC)
â””â”€â”€ fixtures/
    â”œâ”€â”€ mock_ai_service.py
    â”œâ”€â”€ mock_database.py
    â””â”€â”€ golden_baselines/           # Golden master data</code></pre>

<p>---</p>

<h2>Dependencies</h2>

<p><strong>Blocks:</strong></p>
<ul>
<li>US-454 (Create Generation Orchestrator Tests) - needs this infrastructure</li>
<li>US-455 (Create Regeneration Orchestrator Tests) - needs this infrastructure</li>
<li>US-456 (Create Coverage Gap Tests) - needs this infrastructure</li>
</ul>

<p><strong>Depends On:</strong></p>
<ul>
<li>None (first task in Phase 0)</li>
</ul>

<p>---</p>

<h2>Test Strategy</h2>

<h3>Phase 1: Basic Harness (Day 1-2)</h3>

<p><strong>Goal:</strong> Launch Streamlit app in test mode, navigate tabs</p>

<pre><code># tests/epic-026/infrastructure/test_streamlit_harness.py
def test_app_launches():
    """Streamlit app starts without errors"""
    page = launch_streamlit_app()
    assert page.title == "DefinitieAgent"

def test_navigate_to_generator_tab():
    """Can navigate to definition generator tab"""
    page = launch_streamlit_app()
    page.click("text=Definitie Genereren")
    assert page.is_visible("text=Begrip")</code></pre>

<p>---</p>

<h3>Phase 2: Session State (Day 2-3)</h3>

<p><strong>Goal:</strong> Mock and manipulate st.session_state</p>

<pre><code>def test_session_state_mocking():
    """Can mock session state for testing"""
    with mock_session_state({"category": "Toezicht"}):
        result = some_function_using_session_state()
        assert result.category == "Toezicht"</code></pre>

<p><strong>Challenge:</strong> st.session_state is global singleton - need isolation</p>

<p>---</p>

<h3>Phase 3: Golden Master (Day 3-4)</h3>

<p><strong>Goal:</strong> Record current behavior, compare later</p>

<pre><code>def test_definition_generation_golden_master():
    """Definition generation matches golden baseline"""
    result = generate_definition("Toezicht", contexts={"org": ["IGJ"]})

    # First run: records baseline
    # Later runs: compares against baseline
    assert_golden_match(result, "test_generation_toezicht.json")</code></pre>

<p>---</p>

<h3>Phase 4: Async Patterns (Day 4-5)</h3>

<p><strong>Goal:</strong> Test async workflows without race conditions</p>

<pre><code>@pytest.mark.asyncio
async def test_async_category_determination():
    """Async category determination works"""
    mock_ai = MockAIService(response="Toezicht")

    result = await determine_category("begrip", mock_ai)

    assert result.category == "Toezicht"
    assert result.confidence &gt; 0.8</code></pre>

<p>---</p>

<h3>Phase 5: Integration (Day 5)</h3>

<p><strong>Goal:</strong> 5 end-to-end scenarios as PoC</p>

<p><strong>Scenarios:</strong></p>
<ol>
<li>Happy path: Generate definition (Toezicht, org=IGJ)</li>
<li>Duplicate found: Show user duplicate check dialog</li>
<li>Category change: Trigger regeneration</li>
<li>Document upload: Process PDF, extract context</li>
<li>Validation failure: Show validation errors</li>
</ol>

<p>---</p>

<h2>Risks</h2>

<h3>Risk 1: Streamlit is Hard to Test</h3>
<p><strong>Likelihood:</strong> HIGH</p>
<p><strong>Impact:</strong> MEDIUM (slower test creation)</p>
<p><strong>Mitigation:</strong> Use playwright (browser automation), not pytest-streamlit (too limited)</p>

<h3>Risk 2: Flaky Tests</h3>
<p><strong>Likelihood:</strong> HIGH (async + UI)</p>
<p><strong>Impact:</strong> HIGH (blocks Phase 0 Gate 1: <5% flakiness required)</p>
<p><strong>Mitigation:</strong></p>
<ul>
<li>Explicit waits (not implicit sleeps)</li>
<li>Retry logic for UI interactions</li>
<li>Isolated test environment</li>
</ul>

<h3>Risk 3: Golden Master Baseline Drift</h3>
<p><strong>Likelihood:</strong> MEDIUM</p>
<p><strong>Impact:</strong> MEDIUM (false positives)</p>
<p><strong>Mitigation:</strong> Version golden baselines, document when to update</p>

<p>---</p>

<h2>Success Metrics</h2>

<ul>
<li>[ ] Infrastructure complete in 5 days (not 7)</li>
<li>[ ] 5 integration tests passing (PoC)</li>
<li>[ ] 0 flaky tests in infrastructure tests</li>
<li>[ ] CI/CD integration successful</li>
<li>[ ] Team trained on test patterns (1 hour session)</li>
</ul>

<p>---</p>

<h2>Documentation Deliverable</h2>

<p><strong>File:</strong> <code>docs/testing/EPIC-026-test-infrastructure.md</code></p>

<p><strong>Contents:</strong></p>
<ol>
<li>Architecture overview (test harness + golden master)</li>
<li>How to write tests (examples for each pattern)</li>
<li>How to run tests (local + CI/CD)</li>
<li>Troubleshooting guide (common issues)</li>
<li>Golden master maintenance (when to update baselines)</li>
</ol>

<p>---</p>

<h2>Rollback</h2>

<p><strong>If this US fails:</strong> Cannot proceed with Phase 0</p>
<p><strong>Abort trigger:</strong> If >7 days without working harness â†’ Reassess Phase 0 feasibility</p>

<p>---</p>

<p><strong>Status:</strong> Pending</p>
<p><strong>Next Action:</strong> Assign test engineer, start Day 1 (pytest-playwright setup)</p>

  </div>
</body>
</html>