<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>EPIC-026: Technical Risk Heatmap</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>EPIC-026: Technical Risk Heatmap</h1>

<p><strong>Date:</strong> 2025-10-03</p>
<p><strong>Purpose:</strong> Visual risk assessment for refactoring decision</p>

<p>---</p>

<h2>Risk Matrix</h2>

<pre><code>IMPACT
  ^
H â”‚  6         2,5        1,3
I â”‚
G â”‚
H â”‚
  â”‚
M â”‚  8         9          4
E â”‚
D â”‚
I â”‚
U â”‚  7         10
M â”‚
  â”‚
L â”‚              11
O â”‚
W â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€&gt;
      LOW      MEDIUM     HIGH
           PROBABILITY</code></pre>

<h3>Risk Legend</h3>

<p>| # | Risk | Probability | Impact | Score |</p>
<p>|---|------|-------------|--------|-------|</p>
<p>| <strong>1</strong> | Break generation flow (Week 4-5) | HIGH | HIGH | ğŸ”´ 9 |</p>
<p>| <strong>2</strong> | State management breaks UI | MEDIUM-HIGH | HIGH | ğŸ”´ 8 |</p>
<p>| <strong>3</strong> | Integration tests reveal unknowns | MEDIUM-HIGH | HIGH | ğŸ”´ 8 |</p>
<p>| <strong>4</strong> | Timeline overrun (9â†’11 weeks) | HIGH | MEDIUM | ğŸŸ¡ 7 |</p>
<p>| <strong>5</strong> | Async/sync boundary issues | MEDIUM-HIGH | HIGH | ğŸ”´ 8 |</p>
<p>| <strong>6</strong> | Test coverage gaps cause regressions | LOW | HIGH | ğŸŸ¡ 6 |</p>
<p>| <strong>7</strong> | Circular dependencies discovered | LOW | MEDIUM | ğŸŸ¢ 3 |</p>
<p>| <strong>8</strong> | Service initialization failures | LOW | MEDIUM | ğŸŸ¢ 3 |</p>
<p>| <strong>9</strong> | Hardcoded patterns remain hardcoded | MEDIUM | MEDIUM | ğŸŸ¡ 5 |</p>
<p>| <strong>10</strong> | Over-engineering (abstraction debt) | MEDIUM | MEDIUM | ğŸŸ¡ 5 |</p>
<p>| <strong>11</strong> | Repository split creates issues | LOW | LOW | ğŸŸ¢ 2 |</p>

<p><strong>Risk Score:</strong> Probability Ã— Impact (1-9 scale)</p>
<ul>
<li>ğŸ”´ **Critical (7-9):** Immediate mitigation required</li>
<li>ğŸŸ¡ **Medium (4-6):** Monitor and mitigate</li>
<li>ğŸŸ¢ **Low (1-3):** Accept or defer</li>
</ul>

<p>---</p>

<h2>Critical Risks (Score 7-9)</h2>

<h3>ğŸ”´ Risk #1: Break Generation Flow (Score 9)</h3>

<p><strong>Description:</strong> Extracting <code>_handle_definition_generation</code> (385 LOC god method) breaks core business logic</p>

<p><strong>Probability:</strong> HIGH (70%)</p>
<ul>
<li>Complex orchestration across 5+ services</li>
<li>Async/sync boundary mixing</li>
<li>15+ session state mutations</li>
<li>No current test coverage</li>
</ul>

<p><strong>Impact:</strong> HIGH</p>
<ul>
<li>Application cannot generate definitions</li>
<li>Blocks entire user workflow</li>
<li>Requires major rework or rollback</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Create 15-20 integration tests BEFORE extraction (Week 1)</li>
<li>âœ… Incremental extraction (one step at a time)</li>
<li>âœ… Daily testing after each change</li>
<li>âœ… Rollback checkpoints every 2 days</li>
<li>âœ… 2-week contingency buffer</li>
</ul>

<p><strong>Owner:</strong> Code Architect (Week 4-5)</p>

<p>---</p>

<h3>ğŸ”´ Risk #2: State Management Breaks UI (Score 8)</h3>

<p><strong>Description:</strong> Session state contract changes break entire UI</p>

<p><strong>Probability:</strong> MEDIUM-HIGH (50%)</p>
<ul>
<li>50+ `SessionStateManager` calls in `tabbed_interface.py`</li>
<li>30+ calls in `definition_generator_tab.py`</li>
<li>100+ calls across all tabs</li>
<li>State contracts span entire application</li>
</ul>

<p><strong>Impact:</strong> HIGH</p>
<ul>
<li>UI doesn't render</li>
<li>Tab navigation fails</li>
<li>Generation results lost</li>
<li>User data corruption</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Document state schema (Week 1)</li>
<li>âœ… Create type-safe state wrappers (Week 1)</li>
<li>âœ… Schema validation at runtime</li>
<li>âœ… Incremental migration (don't change all at once)</li>
<li>âœ… State contract tests</li>
</ul>

<p><strong>Owner:</strong> Code Architect (All weeks)</p>

<p>---</p>

<h3>ğŸ”´ Risk #3: Integration Tests Reveal Unknowns (Score 8)</h3>

<p><strong>Description:</strong> Creating integration tests (Week 1) uncovers hidden dependencies</p>

<p><strong>Probability:</strong> MEDIUM-HIGH (40%)</p>
<ul>
<li>Current test coverage: 1 test for 4,318 LOC UI code</li>
<li>Unknown coupling between components</li>
<li>Undocumented session state contracts</li>
<li>Hidden service dependencies</li>
</ul>

<p><strong>Impact:</strong> HIGH</p>
<ul>
<li>Week 1 takes 2 weeks instead of 1</li>
<li>+1-2 weeks timeline slip</li>
<li>May discover blockers for extraction</li>
<li>Could require plan revision</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Allocate 7 days for Week 1 (not 5)</li>
<li>âœ… Focus first 3 days on test creation</li>
<li>âœ… Early escalation if unknowns found</li>
<li>âœ… Go/No-Go decision at end of Week 1</li>
</ul>

<p><strong>Owner:</strong> Code Architect (Week 1)</p>

<p>---</p>

<h3>ğŸ”´ Risk #5: Async/Sync Boundary Issues (Score 8)</h3>

<p><strong>Description:</strong> Clean async patterns impossible in sync Streamlit framework</p>

<p><strong>Probability:</strong> MEDIUM-HIGH (50%)</p>
<ul>
<li>Streamlit is synchronous</li>
<li>Category determination is async</li>
<li>Generation is async (via run_async)</li>
<li>Cannot eliminate asyncio.run() bridge</li>
</ul>

<p><strong>Impact:</strong> HIGH</p>
<ul>
<li>Concurrency bugs</li>
<li>Race conditions</li>
<li>Error handling complexity</li>
<li>Performance issues</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Accept async/sync bridge as architectural constraint</li>
<li>âœ… Focus on clean boundaries, not elimination</li>
<li>âœ… Comprehensive async error handling</li>
<li>âœ… Use existing `run_async()` pattern</li>
</ul>

<p><strong>Owner:</strong> Code Architect (Week 4-5)</p>

<p>---</p>

<h2>Medium Risks (Score 4-6)</h2>

<h3>ğŸŸ¡ Risk #4: Timeline Overrun (Score 7)</h3>

<p><strong>Description:</strong> 9 weeks â†’ 11-12 weeks due to complexity</p>

<p><strong>Probability:</strong> HIGH (60%)</p>
<ul>
<li>Proposed plan has tight timeline</li>
<li>No buffer for unknowns</li>
<li>Complex orchestrator extraction</li>
<li>State management migration</li>
</ul>

<p><strong>Impact:</strong> MEDIUM</p>
<ul>
<li>+2-3 weeks delay</li>
<li>Budget overrun</li>
<li>Blocks other work</li>
<li>Stakeholder frustration</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… **Use 4-5 week alternative plan** (44% faster)</li>
<li>âœ… Weekly reassessment</li>
<li>âœ… Parallel work after Week 3</li>
<li>âœ… Deliver partial if needed</li>
</ul>

<p><strong>Owner:</strong> Project Manager</p>

<p>---</p>

<h3>ğŸŸ¡ Risk #6: Test Coverage Gaps (Score 6)</h3>

<p><strong>Description:</strong> Insufficient tests allow regressions</p>

<p><strong>Probability:</strong> LOW (20%)</p>
<ul>
<li>Plan includes comprehensive testing</li>
<li>15-20 integration tests</li>
<li>90%+ coverage for services</li>
</ul>

<p><strong>Impact:</strong> HIGH</p>
<ul>
<li>Bugs in production</li>
<li>User-facing errors</li>
<li>Rollback required</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Test coverage requirement: 90%+</li>
<li>âœ… Integration tests must pass</li>
<li>âœ… Manual QA after each week</li>
<li>âœ… Smoke tests in CI/CD</li>
</ul>

<p><strong>Owner:</strong> Code Architect + QA</p>

<p>---</p>

<h3>ğŸŸ¡ Risk #9: Hardcoded Patterns Remain (Score 5)</h3>

<p><strong>Description:</strong> Proposed plan moves patterns to services (still hardcoded)</p>

<p><strong>Probability:</strong> MEDIUM (40%)</p>
<ul>
<li>`OntologicalCategoryService` just moves code</li>
<li>Patterns not in config</li>
<li>Not data-driven</li>
</ul>

<p><strong>Impact:</strong> MEDIUM</p>
<ul>
<li>Maintenance burden remains</li>
<li>Inconsistency risk</li>
<li>Not extensible</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… **Use alternative plan** (extract to config)</li>
<li>âœ… Create `config/ontological_patterns.yaml`</li>
<li>âœ… Make services read from config</li>
</ul>

<p><strong>Owner:</strong> Code Architect (Week 1-2)</p>

<p>---</p>

<h3>ğŸŸ¡ Risk #10: Over-Engineering (Score 5)</h3>

<p><strong>Description:</strong> Creating unnecessary abstraction layers</p>

<p><strong>Probability:</strong> MEDIUM (40%)</p>
<ul>
<li>7 new services (5 unnecessary)</li>
<li>4 layers instead of 3</li>
<li>Orchestrator proliferation</li>
</ul>

<p><strong>Impact:</strong> MEDIUM</p>
<ul>
<li>Maintenance burden</li>
<li>Complexity increase</li>
<li>Slower development</li>
<li>Technical debt</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… **Use alternative plan** (2 new services, 3 layers)</li>
<li>âœ… Reuse existing services</li>
<li>âœ… YAGNI principle</li>
<li>âœ… Architecture review before Week 2</li>
</ul>

<p><strong>Owner:</strong> Technical Architect</p>

<p>---</p>

<h2>Low Risks (Score 1-3)</h2>

<h3>ğŸŸ¢ Risk #7: Circular Dependencies (Score 3)</h3>

<p><strong>Description:</strong> Circular dependencies block refactoring</p>

<p><strong>Probability:</strong> LOW (10%)</p>
<ul>
<li>Only 2 lazy imports in codebase</li>
<li>No evidence of pervasive circular deps</li>
<li>Clear service boundaries</li>
</ul>

<p><strong>Impact:</strong> MEDIUM</p>
<ul>
<li>Requires architectural changes</li>
<li>Could block extraction</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Dependency injection</li>
<li>âœ… Interface-based abstractions</li>
<li>âœ… Import graph analysis</li>
</ul>

<p><strong>Owner:</strong> Code Architect</p>

<p>---</p>

<h3>ğŸŸ¢ Risk #8: Service Initialization Failures (Score 3)</h3>

<p><strong>Description:</strong> Service initialization fails in production</p>

<p><strong>Probability:</strong> LOW (10%)</p>
<ul>
<li>ServiceContainer pattern already works</li>
<li>DI well-established</li>
<li>89 services already working</li>
</ul>

<p><strong>Impact:</strong> MEDIUM</p>
<ul>
<li>Application doesn't start</li>
<li>Fallback to dummy services</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… Initialization tests</li>
<li>âœ… Graceful fallbacks</li>
<li>âœ… CI/CD checks</li>
</ul>

<p><strong>Owner:</strong> DevOps</p>

<p>---</p>

<h3>ğŸŸ¢ Risk #11: Repository Split Issues (Score 2)</h3>

<p><strong>Description:</strong> Splitting <code>definitie_repository.py</code> causes problems</p>

<p><strong>Probability:</strong> LOW (5%)</p>
<ul>
<li>Not a god object (complexity 4.7)</li>
<li>51 tests (excellent coverage)</li>
<li>Well-structured</li>
</ul>

<p><strong>Impact:</strong> LOW</p>
<ul>
<li>Easy rollback</li>
<li>Not critical path</li>
</ul>

<p><strong>Mitigation:</strong></p>
<ul>
<li>âœ… **DEFER to later epic** (not in scope)</li>
<li>âœ… Keep as-is (low priority)</li>
</ul>

<p><strong>Owner:</strong> N/A (deferred)</p>

<p>---</p>

<h2>Risk Comparison: Proposed vs Alternative</h2>

<h3>Proposed Plan Risk Profile</h3>

<p>| Risk Category | Count | Total Score |</p>
<p>|---------------|-------|-------------|</p>
<p>| ğŸ”´ Critical (7-9) | 5 | 41 |</p>
<p>| ğŸŸ¡ Medium (4-6) | 4 | 23 |</p>
<p>| ğŸŸ¢ Low (1-3) | 2 | 5 |</p>
<p>| <strong>TOTAL</strong> | <strong>11</strong> | <strong>69</strong> |</p>

<p><strong>Overall Risk:</strong> MEDIUM-HIGH</p>

<p>---</p>

<h3>Alternative Plan Risk Profile</h3>

<p>| Risk Category | Count | Total Score |</p>
<p>|---------------|-------|-------------|</p>
<p>| ğŸ”´ Critical (7-9) | 3 | 25 |</p>
<p>| ğŸŸ¡ Medium (4-6) | 2 | 11 |</p>
<p>| ğŸŸ¢ Low (1-3) | 2 | 5 |</p>
<p>| <strong>TOTAL</strong> | <strong>7</strong> | <strong>41</strong> |</p>

<p><strong>Overall Risk:</strong> MEDIUM</p>

<p><strong>Risk Reduction:</strong> 41% (69 â†’ 41 total score)</p>

<p>---</p>

<h3>Mitigated Risks (Alternative Plan)</h3>

<p>âœ… <strong>Risk #4 (Timeline Overrun)</strong> - Reduced from 60% to 30% probability</p>
<ul>
<li> - Reason: 4-5 weeks vs 9 weeks (less time to overrun)</li>
</ul>

<p>âœ… <strong>Risk #9 (Hardcoded Patterns)</strong> - Eliminated (0% probability)</p>
<ul>
<li> - Reason: Patterns extracted to config (data-driven)</li>
</ul>

<p>âœ… <strong>Risk #10 (Over-Engineering)</strong> - Reduced from 40% to 10% probability</p>
<ul>
<li> - Reason: Only 2 new services, 3 layers (not 4)</li>
</ul>

<p>âœ… <strong>Risk #11 (Repository Split)</strong> - Eliminated (0% probability)</p>
<ul>
<li> - Reason: Deferred (not in scope)</li>
</ul>

<p>---</p>

<h2>Risk Mitigation Strategy</h2>

<h3>Week-by-Week Risk Management</h3>

<p><strong>Week 1: Foundation (CRITICAL PHASE)</strong></p>
<ul>
<li>**Primary Risks:** #3 (integration tests reveal unknowns)</li>
<li>**Mitigation:** 7 days (not 5), early escalation</li>
<li>**Go/No-Go Decision:** End of Week 1</li>
</ul>

<p><strong>Week 2: Business Logic Extraction</strong></p>
<ul>
<li>**Primary Risks:** #9 (hardcoded patterns), #10 (over-engineering)</li>
<li>**Mitigation:** Extract to config, reuse existing services</li>
</ul>

<p><strong>Week 3: UI Component Splitting</strong></p>
<ul>
<li>**Primary Risks:** #2 (state management)</li>
<li>**Mitigation:** Type-safe wrappers, incremental migration</li>
</ul>

<p><strong>Week 4: Orchestration Extraction (CRITICAL PHASE)</strong></p>
<ul>
<li>**Primary Risks:** #1 (break generation), #5 (async/sync)</li>
<li>**Mitigation:** Comprehensive tests, daily testing, rollback points</li>
</ul>

<p><strong>Week 5: Cleanup</strong></p>
<ul>
<li>**Primary Risks:** None (low-risk cleanup work)</li>
</ul>

<p>---</p>

<h2>Risk Acceptance Criteria</h2>

<h3>Go/No-Go Gates</h3>

<p><strong>Week 1 Gate:</strong></p>
<ul>
<li>âœ… 15-20 integration tests created and passing</li>
<li>âœ… State schema documented</li>
<li>âœ… No critical unknowns discovered</li>
<li>âŒ **STOP if:** >5 critical unknowns, timeline slip >1 week</li>
</ul>

<p><strong>Week 4 Gate:</strong></p>
<ul>
<li>âœ… Orchestrator extraction complete</li>
<li>âœ… All integration tests passing</li>
<li>âœ… No functional regressions</li>
<li>âŒ **STOP if:** Tests fail, generation broken, >3 days blocked</li>
</ul>

<p><strong>Final Gate:</strong></p>
<ul>
<li>âœ… UI reduced to <1,200 LOC</li>
<li>âœ… All tests passing (90%+ coverage)</li>
<li>âœ… No performance degradation</li>
<li>âœ… Documentation complete</li>
</ul>

<p>---</p>

<h2>Rollback Strategy</h2>

<h3>Rollback Triggers</h3>

<p>| Trigger | Action | Owner |</p>
<p>|---------|--------|-------|</p>
<p>| <strong>Integration tests fail (Week 1)</strong> | Reassess plan, add 1 week | PM |</p>
<p>| <strong>Generation broken (Week 4)</strong> | Rollback to Week 3 checkpoint | Code Architect |</p>
<p>| <strong>Timeline slip >2 weeks</strong> | Deliver partial (1-2 files) | PM |</p>
<p>| <strong><50% progress at Week 3</strong> | Abort, rescope to MVP | Stakeholders |</p>

<h3>Checkpoint Strategy</h3>

<p><strong>Git Tags at End of Each Week:</strong></p>
<ul>
<li>`epic-026-week-1-foundation`</li>
<li>`epic-026-week-2-business-logic`</li>
<li>`epic-026-week-3-ui-split`</li>
<li>`epic-026-week-4-orchestration`</li>
<li>`epic-026-week-5-cleanup`</li>
</ul>

<p><strong>Rollback Command:</strong></p>
<pre><code>git checkout epic-026-week-N-&lt;name&gt;
pytest -q  # Verify tests pass</code></pre>

<p><strong>Maximum Rollback Window:</strong> 2 weeks (to previous checkpoint)</p>

<p>---</p>

<h2>Risk Dashboard (For Monitoring)</h2>

<h3>KPIs to Track</h3>

<p>| KPI | Target | Alert Threshold |</p>
<p>|-----|--------|-----------------|</p>
<p>| <strong>Test Coverage</strong> | >90% | <80% |</p>
<p>| <strong>Integration Tests Passing</strong> | 100% | <95% |</p>
<p>| <strong>Timeline Variance</strong> | Â±0 weeks | >+1 week |</p>
<p>| <strong>God Method LOC</strong> | <50 LOC | >100 LOC |</p>
<p>| <strong>New Services Created</strong> | 2 | >3 |</p>
<p>| <strong>Hardcoded Patterns</strong> | 0 | >1 |</p>
<p>| <strong>Complexity (Max)</strong> | <15 | >25 |</p>

<h3>Weekly Risk Review</h3>

<p><strong>Questions to Ask:</strong></p>
<ol>
<li>Are all integration tests passing?</li>
<li>Is timeline on track?</li>
<li>Are we creating unnecessary services?</li>
<li>Are patterns in config (not code)?</li>
<li>Is UI getting thinner?</li>
</ol>

<p><strong>Escalation Path:</strong></p>
<ul>
<li>Week variance >3 days â†’ PM notified</li>
<li>Critical risk triggered â†’ Stakeholders notified</li>
<li>Rollback needed â†’ Architecture review</li>
</ul>

<p>---</p>

<h2>Recommendation</h2>

<h3>Risk-Based Decision</h3>

<p><strong>Proposed Plan:</strong></p>
<ul>
<li>Total Risk Score: 69</li>
<li>Critical Risks: 5</li>
<li>Overall Risk: MEDIUM-HIGH</li>
</ul>

<p><strong>Alternative Plan:</strong></p>
<ul>
<li>Total Risk Score: 41</li>
<li>Critical Risks: 3</li>
<li>Overall Risk: MEDIUM</li>
</ul>

<p><strong>Risk Reduction:</strong> 41% with alternative approach</p>

<h3>âš ï¸ APPROVE ALTERNATIVE PLAN</h3>

<p><strong>Reasons:</strong></p>
<ol>
<li>Lower overall risk (41 vs 69)</li>
<li>Fewer critical risks (3 vs 5)</li>
<li>Mitigates hardcoded patterns (config-driven)</li>
<li>Shorter timeline = less time to derail</li>
<li>Simpler architecture = less risk surface</li>
</ol>

<p>---</p>

<p><strong>Status:</strong> READY FOR DECISION</p>
<p><strong>Next Action:</strong> Present to stakeholders with risk assessment</p>
<p><strong>Decision Required:</strong> Accept MEDIUM risk (alternative) vs MEDIUM-HIGH risk (proposed)?</p>

<p>---</p>

<p><strong>Prepared by:</strong> Technical Architecture Analyst (Agent 2)</p>
<p><strong>Date:</strong> 2025-10-03</p>

  </div>
</body>
</html>