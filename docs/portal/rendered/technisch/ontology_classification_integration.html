<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Ontologische Classificatie Integratie Guide</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">← Terug naar Portal</a>
    <h1>Ontologische Classificatie Integratie Guide</h1>

<p><strong>Datum:</strong> 2025-10-07</p>
<p><strong>Status:</strong> Implementation Ready</p>
<p><strong>Versie:</strong> 1.0.0</p>

<h2>Overzicht</h2>

<p>Deze guide beschrijft de integratie van het nieuwe <strong>Hybrid Ontology Classification System</strong> in DefinitieAgent.</p>

<h3>Architectuur Keuze: Hybrid Approach</h3>

<p><strong>Primary: LLM-based</strong> classificatie met <strong>Validation: Rules-based</strong> sanity checks.</p>

<pre><code>Begrip + Context
    ↓
[LLM Classificatie]  → {level, confidence, rationale, linguistic_cues}
    ↓
[Rule Validator]     → Verify plausibility
    ↓
UI Display</code></pre>

<p><strong>Rationale:</strong></p>
<ul>
<li>LLM lost score generatie probleem op (end-to-end: begrip → categorie)</li>
<li>Rules dienen als sanity check</li>
<li>Beste van beide werelden: flexibiliteit + validatie</li>
<li>Transparantie via prompt visibility</li>
</ul>

<h2>Service Architectuur</h2>

<h3>Layer: ServiceAdapter (Optie 2)</h3>

<pre><code>src/services/classification/
├── ontology_classifier.py          # LLM-based classificatie service
├── ontology_validator.py           # Rules-based validator
└── prompts/
    └── ontology_classification.yaml  # Prompt configuratie</code></pre>

<h3>Service Dependencies</h3>

<pre><code>OntologyClassifierService
├── Depends on: AIServiceV2 (GPT-4 calls)
├── Depends on: OntologyValidator (sanity checks)
└── Configures: Temperature=0.3, MaxTokens=500</code></pre>

<h2>API Specificatie</h2>

<h3>OntologyClassifierService</h3>

<pre><code>class OntologyClassifierService:
    """LLM-based ontologische classificatie met rule validatie."""

    def classify(
        self,
        begrip: str,
        definitie: str,
        context: Optional[str] = None,
        voorbeelden: Optional[List[str]] = None
    ) -&gt; ClassificationResult:
        """
        Classificeer begrip naar ontologische categorie.

        Returns:
            ClassificationResult met:
            - level: TYPE|EXEMPLAAR|PROCES|RESULTAAT|ONBESLIST
            - confidence: 0.0-1.0
            - rationale: Verklaring
            - linguistic_cues: List van aanwijzingen
            - validation_warnings: List van warnings
        """</code></pre>

<h3>ClassificationResult</h3>

<pre><code>@dataclass
class ClassificationResult:
    level: OntologyLevel              # TYPE/EXEMPLAAR/PROCES/RESULTAAT/ONBESLIST
    confidence: float                 # 0.0-1.0
    rationale: str                    # Verklaring waarom deze classificatie
    linguistic_cues: List[str]        # Linguïstische aanwijzingen
    validation_warnings: List[str]    # Warnings van validator (lege list = OK)</code></pre>

<h2>Gebruik in UI</h2>

<h3>Basis Integratie</h3>

<pre><code>from src.services.classification.ontology_classifier import OntologyClassifierService
from src.ui.components.ontology_classification_display import display_ontology_classification

# 1. Get service from container
container = get_cached_container()
classifier = container.ontology_classifier()

# 2. Classificeer begrip
result = classifier.classify(
    begrip="verificatie",
    definitie="Het controleren van de juistheid van gegevens",
    context="Juridische context",
    voorbeelden=["Het verifiëren van identiteit"]
)

# 3. Display in UI
display_ontology_classification(result, mode="full")</code></pre>

<h3>Tabbed Interface Integratie</h3>

<p>Update <code>src/ui/tabbed_interface.py</code>:</p>

<pre><code>async def _determine_ontological_category_v3(
    self,
    begrip: str,
    definitie: str,
    org_context: str,
    jur_context: str
):
    """Bepaal ontologische categorie via Hybrid LLM + Rules approach."""
    try:
        # Get classifier from container
        classifier = self.container.ontology_classifier()

        # Build context
        context = f"Organisatorisch: {org_context}\nJuridisch: {jur_context}"

        # Classificeer
        result = classifier.classify(
            begrip=begrip,
            definitie=definitie,
            context=context
        )

        # Return tuple voor backward compatibility
        return (
            OntologischeCategorie[result.level],  # Convert to enum
            result.rationale,
            {  # Score dict voor legacy code
                "type": 1.0 if result.level == "TYPE" else 0.0,
                "exemplaar": 1.0 if result.level == "EXEMPLAAR" else 0.0,
                "proces": 1.0 if result.level == "PROCES" else 0.0,
                "resultaat": 1.0 if result.level == "RESULTAAT" else 0.0
            }
        )

    except Exception as e:
        logger.error(f"Ontologische classificatie gefaald: {e}")
        # Fallback naar ONBESLIST
        return (
            OntologischeCategorie.ONBESLIST,
            f"Classificatie gefaald: {str(e)}",
            {"type": 0, "exemplaar": 0, "proces": 0, "resultaat": 0}
        )</code></pre>

<h2>Display Modes</h2>

<h3>1. Full Display</h3>

<p>Toont alle details inclusief validation warnings:</p>

<pre><code>display_ontology_classification(result, mode="full")</code></pre>

<h3>2. Compact Display</h3>

<p>Inline display met emoji + confidence:</p>

<pre><code>display_ontology_classification(result, mode="compact")</code></pre>

<h3>3. With Prompt Visibility</h3>

<p>Voor transparency - toont gebruikte prompt:</p>

<pre><code># Load prompt voor display
import yaml
with open("config/prompts/ontology_classification.yaml") as f:
    prompt_config = yaml.safe_load(f)

display_ontology_classification(
    result,
    mode="with_prompt",
    prompt_content=prompt_config['system']
)</code></pre>

<h2>Validation Warnings Interpretatie</h2>

<p>De validator kan deze warnings genereren:</p>

<p>| Warning Type | Betekenis | Actie |</p>
<p>|-------------|-----------|-------|</p>
<p>| Anti-indicator gevonden | LLM classificatie contradiceert linguïstische patronen | Controleer classificatie |</p>
<p>| Geen sterke indicatoren | Definitie bevat geen duidelijke aanwijzingen | Mogelijk ONBESLIST |</p>
<p>| Domein mismatch | Verwachte categorie verschilt van classificatie | Review classificatie |</p>
<p>| Sanity check failed | Implausibele classificatie (bijv. PROCES voor "document") | Waarschijnlijk fout |</p>

<h3>Voorbeeld Warnings</h3>

<pre><code>⚠️ Anti-indicator gevonden voor TYPE: 'handeling' in definitie
⚠️ Domein 'legal_procedure' keywords gevonden (['procedure']),
   verwachte level is PROCES, niet TYPE</code></pre>

<h2>Performance Overwegingen</h2>

<h3>API Calls</h3>

<ul>
<li>**Per classificatie:** 1 GPT-4 call (~$0.002)</li>
<li>**Response tijd:** 1-2 seconden (LLM latency)</li>
<li>**Caching:** AI Service cache hergebruikt identical prompts</li>
</ul>

<h3>Optimalisatie Strategieën</h3>

<ol>
<li>**Batch Classificatie** voor meerdere begrippen:</li>
<pre><code>   results = classifier.classify_batch([
       {"begrip": "appel", "definitie": "..."},
       {"begrip": "proces", "definitie": "..."}
   ])</code></pre>
</ol>

<ol>
<li>**Cache Result** in session state:</li>
<pre><code>   # Cache result per begrip
   cache_key = f"ontology_{begrip}_{hash(definitie)}"
   if cache_key not in st.session_state:
       st.session_state[cache_key] = classifier.classify(...)
   result = st.session_state[cache_key]</code></pre>
</ol>

<ol>
<li>**Skip re-classification** bij definitie wijzigingen:</li>
</ol>
<ul>
<li>  - Alleen opnieuw classificeren als begrip of definitie wezenlijk verandert</li>
</ul>

<h2>Testing</h2>

<h3>Unit Tests</h3>

<pre><code># Run classificatie tests
pytest tests/services/classification/test_ontology_classifier.py -v

# Run validator tests
pytest tests/services/classification/test_ontology_validator.py -v</code></pre>

<h3>Integration Tests</h3>

<pre><code>def test_full_integration():
    """Test complete flow: begrip → classificatie → display."""
    container = get_cached_container()
    classifier = container.ontology_classifier()

    result = classifier.classify(
        begrip="verificatie",
        definitie="Het controleren van juistheid"
    )

    assert result.level in ["TYPE", "EXEMPLAAR", "PROCES", "RESULTAAT", "ONBESLIST"]
    assert 0.0 &lt;= result.confidence &lt;= 1.0
    assert len(result.rationale) &gt; 0</code></pre>

<h2>Prompt Customization</h2>

<p>Prompts zijn configureerbaar via <code>config/prompts/ontology_classification.yaml</code>:</p>

<pre><code>system: |
  Je bent een expert in ontologische classificatie...

  [Custom instructies hier]

user_template: |
  Begrip: {begrip}
  Definitie: {definitie}

  [Custom template hier]</code></pre>

<p><strong>Best Practices:</strong></p>
<ul>
<li>Gebruik Nederlandse voorbeelden in system prompt</li>
<li>Specificeer juridische context-specifieke regels</li>
<li>Test prompt wijzigingen met diverse begrippen</li>
</ul>

<h2>Monitoring & Logging</h2>

<h3>Metrics to Track</h3>

<pre><code># Log classificatie events
logger.info(
    f"Classificatie resultaat: {result.level}",
    extra={
        "begrip": begrip,
        "confidence": result.confidence,
        "validation_warnings": len(result.validation_warnings),
        "duration_ms": duration
    }
)</code></pre>

<h3>Key Metrics</h3>

<ul>
<li>**Confidence Distribution:** Histogram van confidence scores</li>
<li>**Validation Warning Rate:** % classificaties met warnings</li>
<li>**Level Distribution:** Verdeling TYPE/PROCES/RESULTAAT/etc</li>
<li>**API Latency:** P50, P95, P99 response tijden</li>
</ul>

<h2>Troubleshooting</h2>

<h3>Issue: Lage Confidence Scores</h3>

<p><strong>Symptoom:</strong> Confidence systematisch < 0.6</p>

<p><strong>Oplossingen:</strong></p>
<ol>
<li>Verbeter definitie kwaliteit</li>
<li>Voeg context toe (org/juridisch)</li>
<li>Voeg voorbeelden toe</li>
<li>Check prompt template (mogelijk te streng)</li>
</ol>

<h3>Issue: Veel Validation Warnings</h3>

<p><strong>Symptoom:</strong> >50% classificaties hebben warnings</p>

<p><strong>Oplossingen:</strong></p>
<ol>
<li>Review validation rules (mogelijk te streng)</li>
<li>Retrain verwachtingen (LLM kan correct zijn)</li>
<li>Voeg domein-specifieke rules toe</li>
</ol>

<h3>Issue: ONBESLIST te vaak</h3>

<p><strong>Symptoom:</strong> >20% classificaties zijn ONBESLIST</p>

<p><strong>Oplossingen:</strong></p>
<ol>
<li>Lower confidence threshold in prompt</li>
<li>Verbeter system prompt met meer voorbeelden</li>
<li>Voeg domain context toe</li>
</ol>

<h2>Migration Path</h2>

<h3>Van Legacy QuickAnalyzer</h3>

<pre><code># OLD (QuickAnalyzer)
analyzer = QuickOntologischeAnalyzer()
categorie, reasoning = analyzer.quick_categoriseer(begrip)

# NEW (OntologyClassifierService)
classifier = container.ontology_classifier()
result = classifier.classify(begrip, definitie)
categorie = OntologischeCategorie[result.level]
reasoning = result.rationale</code></pre>

<h3>Backward Compatibility</h3>

<p>Service kan scores dict genereren voor legacy code:</p>

<pre><code>result = classifier.classify(begrip, definitie)

# Legacy score format
legacy_scores = {
    "type": 1.0 if result.level == "TYPE" else 0.0,
    "exemplaar": 1.0 if result.level == "EXEMPLAAR" else 0.0,
    "proces": 1.0 if result.level == "PROCES" else 0.0,
    "resultaat": 1.0 if result.level == "RESULTAAT" else 0.0
}</code></pre>

<h2>Future Enhancements</h2>

<h3>Phase 2: Multi-Model Ensemble</h3>

<p>Combine LLM + Rules + Linguistic analyzer:</p>

<pre><code>result_llm = llm_classifier.classify(begrip, definitie)
result_rules = rule_classifier.classify_from_scores(scores)
result_linguistic = linguistic_analyzer.analyze(definitie)

# Weighted ensemble
final_result = ensemble_combine([result_llm, result_rules, result_linguistic])</code></pre>

<h3>Phase 3: Fine-Tuned Model</h3>

<p>Train fine-tuned model op Nederlandse juridische begrippen:</p>

<ul>
<li>Data: 1000+ geannoteerde begrippen</li>
<li>Model: GPT-3.5 fine-tune</li>
<li>Benefit: Sneller + goedkoper + betere accuracy</li>
</ul>

<h2>References</h2>

<ul>
<li>**Service Code:** `src/services/classification/ontology_classifier.py`</li>
<li>**Validator Code:** `src/services/classification/ontology_validator.py`</li>
<li>**Prompt Config:** `config/prompts/ontology_classification.yaml`</li>
<li>**UI Component:** `src/ui/components/ontology_classification_display.py`</li>
<li>**Tests:** `tests/services/classification/`</li>
<li>**Handover Document:** `docs/handovers/HANDOVER_ONTOLOGICAL_CLASSIFICATION_REFACTOR.md`</li>
</ul>

  </div>
</body>
</html>