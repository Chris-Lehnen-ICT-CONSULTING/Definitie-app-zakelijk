<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Ontology Classification Implementation Roadmap</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>Ontology Classification Implementation Roadmap</h1>

<p><strong>Datum:</strong> 2025-10-07</p>
<p><strong>Auteur:</strong> Implementation Analysis</p>
<p><strong>Status:</strong> Ready for Implementation</p>

<h2>Executive Summary</h2>

<p>Dit document beschrijft de complete implementatie roadmap voor het nieuwe <strong>Hybrid Ontology Classification System</strong> in DefinitieAgent.</p>

<h3>Architectuur Beslissing</h3>

<p><strong>AANBEVELING: Hybrid Approach (LLM Primary + Rules Validation)</strong></p>

<pre><code>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Begrip + Definitie              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LLM Classificatie (GPT-4)            â”‚
â”‚  - End-to-end: begrip â†’ categorie       â”‚
â”‚  - Context-aware, flexibel              â”‚
â”‚  - Temperature: 0.3 (consistent)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“ {level, confidence, rationale}
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Rules-based Validator                â”‚
â”‚  - Sanity checks                        â”‚
â”‚  - Linguistic patterns                  â”‚
â”‚  - Domain heuristics                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“ + validation_warnings
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         UI Display                      â”‚
â”‚  - Classification result                â”‚
â”‚  - Confidence score                     â”‚
â”‚  - Rationale                            â”‚
â”‚  - Warnings (if any)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</code></pre>

<h2>Vergelijking: Rules-Based vs LLM vs Hybrid</h2>

<p>| Aspect | Rules-Based | LLM-Based | <strong>Hybrid (AANBEVOLEN)</strong> |</p>
<p>|--------|-------------|-----------|-------------------------|</p>
<p>| <strong>Score Generatie</strong> | âŒ Externe dependency | âœ… Built-in | âœ… Built-in |</p>
<p>| <strong>Snelheid</strong> | âœ… <10ms | âŒ 1-2s | âš ï¸ 1-2s (LLM bottleneck) |</p>
<p>| <strong>Kosten</strong> | âœ… Gratis | âŒ $0.002/call | âŒ $0.002/call |</p>
<p>| <strong>Flexibiliteit</strong> | âŒ Beperkt | âœ… Hoog | âœ… Hoog |</p>
<p>| <strong>Transparantie</strong> | âœ… Exact traceable | âš ï¸ AI rationale | âœ… AI + Rule checks |</p>
<p>| <strong>Deterministisch</strong> | âœ… Ja | âŒ Nee | âš ï¸ Nee (LLM primary) |</p>
<p>| <strong>Onderhoudbaarheid</strong> | âŒ Regex updates | âœ… Prompt tuning | âœ… Prompt + Rules |</p>
<p>| <strong>Edge Cases</strong> | âŒ Vast programma | âœ… Adaptief | âœ… Adaptief + Checks |</p>
<p>| <strong>Implementatie Tijd</strong> | 8u | 6u | <strong>10u</strong> |</p>

<p><strong>Conclusie:</strong> Hybrid biedt beste balans tussen flexibiliteit en betrouwbaarheid.</p>

<h2>Implementatie Fases</h2>

<h3>Fase 1: Core Service (4 uur)</h3>

<p><strong>Deliverable:</strong> <code>src/services/classification/ontology_classifier.py</code></p>

<p><strong>Functionaliteit:</strong></p>
<ul>
<li>LLM-based classificatie via GPT-4</li>
<li>Prompt template loading uit YAML</li>
<li>JSON response parsing</li>
<li>Error handling met ONBESLIST fallback</li>
<li>Batch classificatie support</li>
</ul>

<p><strong>Key Methods:</strong></p>
<pre><code>classify(begrip, definitie, context, voorbeelden) â†’ ClassificationResult
classify_batch(items) â†’ List[ClassificationResult]</code></pre>

<p><strong>Dependencies:</strong></p>
<ul>
<li>AIServiceV2 (existing)</li>
<li>OntologyValidator (fase 2)</li>
</ul>

<h3>Fase 2: Rules-based Validator (2 uur)</h3>

<p><strong>Deliverable:</strong> <code>src/services/classification/ontology_validator.py</code></p>

<p><strong>Functionaliteit:</strong></p>
<ul>
<li>Linguistic pattern matching (regex)</li>
<li>Anti-indicator detection</li>
<li>Domain-specific heuristics (legal, biology)</li>
<li>Sanity checks (PROCES â‰  document)</li>
</ul>

<p><strong>Validation Types:</strong></p>
<ol>
<li>**Linguistic Patterns:** Zoek naar (anti-)indicatoren in definitie</li>
<li>**Domain Rules:** Check domein-specifieke verwachtingen</li>
<li>**Sanity Checks:** Detecteer implausibele combinaties</li>
</ol>

<h3>Fase 3: Prompt Configuration (1 uur)</h3>

<p><strong>Deliverable:</strong> <code>config/prompts/ontology_classification.yaml</code></p>

<p><strong>Configuratie:</strong></p>
<pre><code>system: |
  Expert instructies + categorieÃ«n uitleg + Nederlandse voorbeelden

user_template: |
  Begrip: {begrip}
  Definitie: {definitie}
  {context_section}

  Return JSON: {level, confidence, rationale, linguistic_cues}

version: "1.0.0"
model_requirements:
  temperature: 0.3
  max_tokens: 500
  model: "gpt-4"</code></pre>

<h3>Fase 4: Service Container Integration (1 uur)</h3>

<p><strong>Deliverable:</strong> Update <code>src/services/container.py</code></p>

<p><strong>Toevoegen:</strong></p>
<pre><code>def ontology_classifier(self):
    """Get or create OntologyClassifierService singleton."""
    if "ontology_classifier" not in self._instances:
        ai_service = AIServiceV2(...)
        self._instances["ontology_classifier"] = OntologyClassifierService(ai_service)
    return self._instances["ontology_classifier"]</code></pre>

<h3>Fase 5: UI Components (2 uur)</h3>

<p><strong>Deliverable:</strong> <code>src/ui/components/ontology_classification_display.py</code></p>

<p><strong>Display Modes:</strong></p>
<ol>
<li>**Full:** Complete weergave met details + warnings</li>
<li>**Compact:** Inline emoji + confidence</li>
<li>**With Prompt:** Transparantie via prompt visibility</li>
</ol>

<p><strong>UI Features:</strong></p>
<ul>
<li>Emoji per categorie (ğŸ“¦ TYPE, âš™ï¸ PROCES, etc.)</li>
<li>Color-coded confidence (groen >0.8, oranje 0.6-0.8, rood <0.6)</li>
<li>Expandable details + validation warnings</li>
<li>Prompt visibility toggle</li>
</ul>

<h3>Fase 6: Unit Tests (3 uur)</h3>

<p><strong>Deliverables:</strong></p>
<ul>
<li>`tests/services/classification/test_ontology_classifier.py`</li>
<li>`tests/services/classification/test_ontology_validator.py`</li>
</ul>

<p><strong>Test Coverage:</strong></p>
<ul>
<li>âœ… Successful classifications (alle levels)</li>
<li>âœ… Context/voorbeelden integratie</li>
<li>âœ… Validation warning triggers</li>
<li>âœ… JSON parsing (valid, markdown, invalid)</li>
<li>âœ… Error handling (API errors â†’ ONBESLIST)</li>
<li>âœ… Batch processing</li>
<li>âœ… Temperature/max_tokens settings</li>
<li>âœ… Pattern matching (alle levels)</li>
<li>âœ… Domain rules</li>
<li>âœ… Anti-indicator detection</li>
</ul>

<h3>Fase 7: Integration & Documentation (2 uur)</h3>

<p><strong>Deliverables:</strong></p>
<ul>
<li>Integration guide: `docs/technisch/ontology_classification_integration.md`</li>
<li>Update `src/ui/tabbed_interface.py` met nieuwe methode</li>
<li>Update `CLAUDE.md` met classificatie info</li>
</ul>

<p><strong>Documentation Inclusief:</strong></p>
<ul>
<li>API specificatie</li>
<li>Gebruik voorbeelden</li>
<li>Display modes</li>
<li>Performance overwegingen</li>
<li>Troubleshooting guide</li>
<li>Migration path van legacy code</li>
</ul>

<h2>Totale Implementatie Tijd</h2>

<p>| Fase | Tijd |</p>
<p>|------|------|</p>
<p>| 1. Core Service | 4u |</p>
<p>| 2. Rules Validator | 2u |</p>
<p>| 3. Prompt Config | 1u |</p>
<p>| 4. Container Integration | 1u |</p>
<p>| 5. UI Components | 2u |</p>
<p>| 6. Unit Tests | 3u |</p>
<p>| 7. Integration & Docs | 2u |</p>
<p>| <strong>TOTAAL</strong> | <strong>15 uur</strong> |</p>

<h2>Architectuur Beslissing: Layer Keuze</h2>

<h3>Gekozen: ServiceAdapter Layer (Optie 2)</h3>

<p><strong>Rationale:</strong></p>

<p>âœ… <strong>Voor ServiceAdapter:</strong></p>
<ul>
<li>Eigen service boundary (single responsibility)</li>
<li>Herbruikbaar voor toekomstige features</li>
<li>Testbaar in isolatie</li>
<li>Dependency injection via container</li>
<li>Niet afhankelijk van orchestrator complexity</li>
</ul>

<p>âŒ <strong>Tegen UI Layer (Optie 1):</strong></p>
<ul>
<li>61 LOC orchestration in tabbed_interface.py = God Object anti-pattern</li>
<li>Business logic gemixed met presentatie</li>
<li>Moeilijk testbaar</li>
<li>Niet herbruikbaar</li>
</ul>

<p>âŒ <strong>Tegen Orchestrator (Optie 3):</strong></p>
<ul>
<li>18u werk voor marginale voordelen</li>
<li>Over-engineered voor current use case</li>
<li>Alleen zinvol als classificatie deel wordt van core workflow</li>
</ul>

<h2>Code Structuur</h2>

<pre><code>src/services/classification/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ ontology_classifier.py          # 150 LOC - LLM classificatie
â””â”€â”€ ontology_validator.py           # 200 LOC - Rules validatie

config/prompts/
â””â”€â”€ ontology_classification.yaml    # Prompt templates

src/ui/components/
â””â”€â”€ ontology_classification_display.py  # 250 LOC - UI component

tests/services/classification/
â”œâ”€â”€ test_ontology_classifier.py     # 300 LOC
â””â”€â”€ test_ontology_validator.py      # 250 LOC

docs/
â”œâ”€â”€ technisch/
â”‚   â””â”€â”€ ontology_classification_integration.md
â””â”€â”€ architectuur/
    â””â”€â”€ ontology_classification_implementation_roadmap.md (dit document)</code></pre>

<h2>Integration Met Bestaande Code</h2>

<h3>Vervangen: QuickAnalyzer Pattern</h3>

<p><strong>Voor (legacy):</strong></p>
<pre><code># OLD: 1054 LOC analyzer met score generatie + classificatie
analyzer = OntologischeAnalyzer()
categorie, analyse = await analyzer.bepaal_ontologische_categorie(...)

# Fallback: QuickAnalyzer
quick_analyzer = QuickOntologischeAnalyzer()
categorie, reasoning = quick_analyzer.quick_categoriseer(begrip)</code></pre>

<p><strong>Na (nieuw):</strong></p>
<pre><code># NEW: Clean service-based approach
classifier = container.ontology_classifier()
result = classifier.classify(begrip, definitie, context, voorbeelden)

# Convert voor backward compatibility
categorie = OntologischeCategorie[result.level]
reasoning = result.rationale</code></pre>

<h3>Backward Compatibility</h3>

<pre><code># Legacy code verwacht scores dict
legacy_scores = {
    "type": 1.0 if result.level == "TYPE" else 0.0,
    "exemplaar": 1.0 if result.level == "EXEMPLAAR" else 0.0,
    "proces": 1.0 if result.level == "PROCES" else 0.0,
    "resultaat": 1.0 if result.level == "RESULTAAT" else 0.0
}</code></pre>

<h2>Performance Profiel</h2>

<h3>LLM Calls</h3>

<ul>
<li>**Frequency:** 1x per begrip classificatie</li>
<li>**Latency:** 1-2 seconden (GPT-4)</li>
<li>**Cost:** ~$0.002 per classificatie</li>
<li>**Caching:** AIServiceV2 cache hergebruikt identical prompts</li>
</ul>

<h3>Optimalisatie</h3>

<ol>
<li>**Session State Caching:**</li>
<pre><code>   cache_key = f"ontology_{begrip}_{hash(definitie)}"
   if cache_key not in st.session_state:
       st.session_state[cache_key] = classifier.classify(...)</code></pre>
</ol>

<ol>
<li>**Batch Processing:**</li>
<pre><code>   results = classifier.classify_batch([
       {"begrip": "appel", "definitie": "..."},
       {"begrip": "plukken", "definitie": "..."}
   ])</code></pre>
</ol>

<ol>
<li>**Skip Re-classification:**</li>
</ol>
<ul>
<li>  - Alleen herdoen als begrip/definitie wezenlijk verandert</li>
</ul>

<h2>Security & Privacy</h2>

<ul>
<li>âœ… Geen sensitive data in prompts (alleen begrip + definitie)</li>
<li>âœ… API key via environment variable</li>
<li>âœ… No PII in classificatie context</li>
<li>âœ… Prompts zijn raadpleegbaar (transparency)</li>
</ul>

<h2>Monitoring Metrics</h2>

<p>| Metric | Target | Alert If |</p>
<p>|--------|--------|----------|</p>
<p>| <strong>Average Confidence</strong> | >0.75 | <0.6 |</p>
<p>| <strong>ONBESLIST Rate</strong> | <10% | >20% |</p>
<p>| <strong>Validation Warning Rate</strong> | <30% | >50% |</p>
<p>| <strong>API Latency P95</strong> | <3s | >5s |</p>
<p>| <strong>API Error Rate</strong> | <1% | >5% |</p>

<h2>Risks & Mitigations</h2>

<p>| Risk | Impact | Mitigation |</p>
<p>|------|--------|------------|</p>
<p>| <strong>LLM Non-determinisme</strong> | Inconsistente classificaties | Temperature=0.3, Validation checks |</p>
<p>| <strong>API Kosten</strong> | Budget overschrijding | Cache results, Monitor usage |</p>
<p>| <strong>API Latency</strong> | Slechte UX | Session state cache, Batch processing |</p>
<p>| <strong>Prompt Drift</strong> | Accuracy degradatie | Version control prompts, A/B testing |</p>
<p>| <strong>Validation Overlap</strong> | Te veel warnings | Tune rules, Feedback loop |</p>

<h2>Success Criteria</h2>

<p>âœ… <strong>Functionaliteit:</strong></p>
<ul>
<li>Classificeert begrippen naar 5 categorieÃ«n (TYPE/EXEMPLAAR/PROCES/RESULTAAT/ONBESLIST)</li>
<li>Confidence scores >0.75 gemiddeld</li>
<li><10% ONBESLIST rate</li>
<li>Validation warnings bij implausibele classificaties</li>
</ul>

<p>âœ… <strong>Performance:</strong></p>
<ul>
<li>Response tijd <3s (P95)</li>
<li>Session state caching werkend</li>
<li><$10/maand API kosten (bij 500 classificaties/maand)</li>
</ul>

<p>âœ… <strong>Kwaliteit:</strong></p>
<ul>
<li>Unit test coverage >80%</li>
<li>Integration tests passing</li>
<li>Documentation compleet</li>
<li>No regression in bestaande features</li>
</ul>

<p>âœ… <strong>Usability:</strong></p>
<ul>
<li>Duidelijke UI weergave met emoji's</li>
<li>Validation warnings actionable</li>
<li>Prompt transparency optie</li>
<li>Backward compatible met legacy code</li>
</ul>

<h2>Next Steps</h2>

<h3>Immediate (Week 1)</h3>

<ol>
<li>âœ… Implementeer Fase 1-3 (Core + Validator + Prompts) - **7 uur**</li>
<li>âœ… Unit tests voor core functionaliteit - **2 uur**</li>
<li>âœ… Container integration - **1 uur**</li>
</ol>

<h3>Short-term (Week 2)</h3>

<ol>
<li>â³ UI component implementatie - **2 uur**</li>
<li>â³ Integration in tabbed_interface.py - **1 uur**</li>
<li>â³ Complete test suite - **2 uur**</li>
</ol>

<h3>Mid-term (Week 3-4)</h3>

<ol>
<li>ğŸ“‹ User acceptance testing</li>
<li>ğŸ“‹ Prompt tuning based on feedback</li>
<li>ğŸ“‹ Performance monitoring setup</li>
<li>ğŸ“‹ Documentation finalization</li>
</ol>

<h3>Long-term (Future Epics)</h3>

<ul>
<li>**Fine-tuned Model:** Train GPT-3.5 fine-tune op NL juridische begrippen</li>
<li>**Ensemble Approach:** Combine LLM + Rules + Linguistic analyzer</li>
<li>**Active Learning:** Feedback loop voor prompt improvement</li>
<li>**Multi-language:** Uitbreiden naar Engels/Frans</li>
</ul>

<h2>Conclusie</h2>

<p>Het <strong>Hybrid Ontology Classification System</strong> lost de volgende problemen op:</p>

<ol>
<li>âœ… **Score Generatie Gap:** LLM doet end-to-end classificatie</li>
<li>âœ… **Flexibiliteit:** LLM kan nuances oppikken</li>
<li>âœ… **Betrouwbaarheid:** Rules valideren LLM output</li>
<li>âœ… **Transparantie:** Prompt visibility + rationale</li>
<li>âœ… **Onderhoudbaarheid:** Prompt tuning > regex updates</li>
<li>âœ… **Service Boundary:** Clean separation of concerns</li>
</ol>

<p><strong>Implementatie tijd:</strong> 15 uur</p>
<p><strong>ROI:</strong> Betere classificatie accuracy + minder onderhoud</p>
<p><strong>Risk Level:</strong> Medium (LLM dependency, API kosten)</p>

<p>---</p>

<p><strong>Status:</strong> Ready for Implementation</p>
<p><strong>Next Action:</strong> Start Fase 1 (Core Service) implementatie</p>

  </div>
</body>
</html>