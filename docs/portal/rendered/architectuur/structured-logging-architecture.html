<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Structured Logging Architecture Design</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">← Terug naar Portal</a>
    <h1>Structured Logging Architecture Design</h1>

<p><strong>Document Type:</strong> Technical Architecture Design</p>
<p><strong>Created:</strong> 2025-10-07</p>
<p><strong>Status:</strong> Design Phase</p>
<p><strong>Author:</strong> Claude (Architect Role)</p>

<h2>Executive Summary</h2>

<p>This document proposes a structured logging architecture for DefinitieAgent that enables machine-readable logs for analytics, monitoring, and operational insights while maintaining backward compatibility with existing human-readable logs.</p>

<p><strong>Key Decision:</strong> Use <code>python-json-logger</code> with gradual migration strategy.</p>

<p>---</p>

<h2>1. Current Logging Infrastructure Analysis</h2>

<h3>1.1 Current State</h3>

<p><strong>Logging Setup (src/main.py):</strong></p>
<pre><code>logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)</code></pre>

<p><strong>Current Characteristics:</strong></p>
<ul>
<li>✅ Basic Python `logging` module with simple string formatting</li>
<li>✅ PII redaction filter already implemented (`PIIRedactingFilter`)</li>
<li>✅ Logging configuration file exists (`config/logging_config.yaml`)</li>
<li>✅ JSON logging already used for specific purposes (security logs, API monitoring)</li>
<li>❌ No structured logging for application logs</li>
<li>❌ F-string interpolation throughout codebase (361 logging calls)</li>
<li>❌ Logs to console only (no file handlers configured in code)</li>
</ul>

<p><strong>Logging Configuration (<code>config/logging_config.yaml</code>):</strong></p>
<ul>
<li>Comprehensive YAML config exists but **not currently loaded by application**</li>
<li>Defines structured logging section (currently disabled)</li>
<li>Includes module-specific levels, filters, performance tracking</li>
<li>Environment-specific overrides (dev/prod/testing)</li>
</ul>

<p><strong>Existing JSON Logging:</strong></p>
<ul>
<li>Security logs: `logs/security_log_*.json` (390 bytes each)</li>
<li>API monitoring: `api_monitor.py` with JSON export capabilities</li>
<li>NOT used for general application logging</li>
</ul>

<h3>1.2 Current Logging Patterns</h3>

<p><strong>Most Common Pattern (361 files):</strong></p>
<pre><code>logger.info(f"ServiceContainer geïnitialiseerd (init count: {count})")
logger.error(f"Applicatie fout: {e!s}")
logger.warning(f"Search in {endpoint} failed: {e}")</code></pre>

<p><strong>Observed Issues:</strong></p>
<ol>
<li>**String interpolation happens before filtering** → Performance waste for disabled log levels</li>
<li>**No structured context** → Cannot query by `endpoint`, `count`, `error_type`</li>
<li>**Mixed languages** → Dutch business logic, English technical logs</li>
<li>**No correlation IDs** → Cannot trace requests across services</li>
</ol>

<h3>1.3 Performance Baseline</h3>

<p><strong>Current Overhead:</strong></p>
<ul>
<li>String interpolation: Every log call evaluates f-strings immediately</li>
<li>PIIRedactingFilter: Regex operations on every log message (acceptable overhead)</li>
<li>No handlers configured → Only console output</li>
</ul>

<p><strong>Bottlenecks:</strong></p>
<ul>
<li>ServiceContainer init: 2-3x initialization due to cache issues (logged extensively)</li>
<li>PromptOrchestrator: 32x module registrations logged (2x orchestrators)</li>
<li>Toetsregels loading: 53 rules × 2 = 106 log lines per startup</li>
</ul>

<p>---</p>

<h2>2. Library Comparison & Recommendation</h2>

<h3>2.1 Option Analysis</h3>

<p>| Library | Pros | Cons | Verdict |</p>
<p>|---------|------|------|---------|</p>
<p>| <strong>python-json-logger</strong> | ✅ Drop-in replacement for Formatter<br>✅ Zero code changes for basic migration<br>✅ Works with existing handlers<br>✅ Lightweight (no dependencies) | ⚠️ Basic features only<br>⚠️ Manual context management | ✅ <strong>RECOMMENDED</strong> |</p>
<p>| <strong>structlog</strong> | ✅ Rich ecosystem<br>✅ Context binding<br>✅ Middleware/processors<br>✅ Best-in-class features | ❌ Requires code refactoring<br>❌ Learning curve<br>❌ Larger dependency | ❌ Overkill for current needs |</p>
<p>| <strong>Custom Formatter</strong> | ✅ Full control<br>✅ No dependencies | ❌ Maintenance burden<br>❌ Reinventing wheel | ❌ Not recommended |</p>

<h3>2.2 Recommended Solution: python-json-logger</h3>

<p><strong>Installation:</strong></p>
<pre><code>pip install python-json-logger</code></pre>

<p><strong>Justification:</strong></p>
<ol>
<li>**Backward Compatible:** Works with existing `logging` infrastructure</li>
<li>**Minimal Changes:** No code refactoring required for basic JSON logging</li>
<li>**Proven:** Used in production by major organizations (4.5M+ downloads/month)</li>
<li>**Gradual Migration:** Can run alongside existing text logs</li>
<li>**No Lock-in:** Standard logging API, easy to switch later</li>
</ol>

<p>---</p>

<h2>3. Log Schema Design</h2>

<h3>3.1 Base Schema (Required Fields)</h3>

<p>All structured logs will include these fields:</p>

<pre><code>{
  "timestamp": "2025-10-07T10:38:31.504Z",
  "level": "INFO",
  "logger": "services.container",
  "message": "ServiceContainer geïnitialiseerd",
  "module": "container",
  "function": "__init__",
  "line": 68,
  "thread": "MainThread",
  "process": 12345,
  "environment": "production"
}</code></pre>

<p><strong>Field Definitions:</strong></p>
<ul>
<li>`timestamp`: ISO 8601 UTC timestamp</li>
<li>`level`: Log level (DEBUG/INFO/WARNING/ERROR/CRITICAL)</li>
<li>`logger`: Logger name (dot-separated namespace)</li>
<li>`message`: Human-readable message (NO interpolation)</li>
<li>`module`, `function`, `line`: Code location</li>
<li>`thread`, `process`: Execution context</li>
<li>`environment`: deployment environment (dev/prod/testing)</li>
</ul>

<h3>3.2 Context Fields (Optional)</h3>

<p>Additional fields added via context managers or extra parameters:</p>

<pre><code>{
  "request_id": "req_abc123",
  "session_id": "sess_xyz789",
  "user_id": "user_123",
  "operation": "generate_definition",
  "component": "orchestrator",
  "duration_ms": 1234,
  "success": true
}</code></pre>

<h3>3.3 Service-Specific Fields</h3>

<p><strong>ServiceContainer:</strong></p>
<pre><code>{
  "component": "service_container",
  "service_name": "orchestrator",
  "init_count": 1,
  "config_hash": "abc123"
}</code></pre>

<p><strong>AI Service:</strong></p>
<pre><code>{
  "component": "ai_service",
  "model": "gpt-4o-mini",
  "temperature": 0.7,
  "max_tokens": 500,
  "tokens_used": 234,
  "cost": 0.00234,
  "cached": false,
  "duration_ms": 1234
}</code></pre>

<p><strong>Validation:</strong></p>
<pre><code>{
  "component": "validation",
  "rule_id": "ARAI-01",
  "rule_category": "ARAI",
  "validation_passed": true,
  "score": 0.85
}

**Web Lookup:**</code></pre>
<p>{</p>
<p>  "component": "web_lookup",</p>
<p>  "source": "wikipedia",</p>
<p>  "term": "burgerservicenummer",</p>
<p>  "results_count": 3,</p>
<p>  "api_type": "mediawiki",</p>
<p>  "cache_hit": false</p>
<p>}</p>
<pre><code>
**Performance Tracking:**</code></pre>
<p>{</p>
<p>  "component": "performance",</p>
<p>  "operation": "generate_definition",</p>
<p>  "duration_ms": 4567,</p>
<p>  "slow": true,</p>
<p>  "threshold_ms": 5000</p>
<p>}</p>
<pre><code>
### 3.4 Error Schema
</code></pre>
<p>{</p>
<p>  "level": "ERROR",</p>
<p>  "message": "Applicatie fout",</p>
<p>  "error_type": "ValidationError",</p>
<p>  "error_message": "Definition too short",</p>
<p>  "stack_trace": "Traceback...",</p>
<p>  "component": "validation",</p>
<p>  "operation": "validate_definition",</p>
<p>  "request_id": "req_abc123"</p>
<p>}</p>
<pre><code>
---

## 4. Migration Strategy

### 4.1 Approach: Gradual Dual-Output

**Phase 1: Infrastructure (Week 1)**
- [ ] Add `python-json-logger` to `requirements.txt`
- [ ] Create structured logging module (`src/utils/structured_logging.py`)
- [ ] Update `config/logging_config.yaml` with JSON handlers
- [ ] Add environment detection (dev/prod/test)
- [ ] Test dual-output (console + JSON file)

**Phase 2: Core Services (Week 2-3)**
- [ ] Migrate `ServiceContainer` logging (highest value)
- [ ] Migrate `AIServiceV2` logging (cost tracking)
- [ ] Migrate `ValidationOrchestratorV2` logging (quality metrics)
- [ ] Add context managers for request tracking

**Phase 3: Supporting Services (Week 4-5)**
- [ ] Migrate web lookup services
- [ ] Migrate UI components
- [ ] Migrate utilities

**Phase 4: Optimization (Week 6)**
- [ ] Remove f-string interpolation (use lazy evaluation)
- [ ] Add correlation IDs
- [ ] Performance profiling
- [ ] Analytics dashboard

### 4.2 Backward Compatibility

**Human-Readable Console (Development):**</code></pre>
<p>2025-10-07 10:38:31,504 - services.container - INFO - ServiceContainer geïnitialiseerd (init count: 1)</p>
<pre><code>
**JSON File (Production/Analytics):**</code></pre>
<p>{"timestamp": "2025-10-07T10:38:31.504Z", "level": "INFO", "logger": "services.container", "message": "ServiceContainer geïnitialiseerd", "init_count": 1}</p>
<pre><code>
**Configuration:**</code></pre>
<h1>Development: Human-readable console + JSON file</h1>
<h1>Production: JSON only (both console and file)</h1>
<h1>Testing: Minimal logging (JSON file only)</h1>
<pre><code>
### 4.3 Code Migration Example

**Before:**</code></pre>
<p>logger.info(f"ServiceContainer geïnitialiseerd (init count: {self._initialization_count})")</p>
<pre><code>
**After (Lazy Evaluation):**</code></pre>
<h1>Option 1: Use extra parameter (RECOMMENDED)</h1>
<p>logger.info("ServiceContainer geïnitialiseerd", extra={</p>
<p>    "init_count": self._initialization_count,</p>
<p>    "component": "service_container"</p>
<p>})</p>

<h1>Option 2: Use % formatting (lazy)</h1>
<p>logger.info("ServiceContainer geïnitialiseerd (init count: %d)", self._initialization_count)</p>
<pre><code>
**Performance Benefit:**
- Before: F-string evaluated even if log level disabled
- After: Parameters only evaluated if log level enabled

---

## 5. Configuration Approach

### 5.1 Logging Configuration File

**Update `config/logging_config.yaml`:**
</code></pre>
<p>structured:</p>
<p>  enabled: true  # Enable in production</p>
<p>  format: "json"</p>
<p>  file: "logs/definitie_agent_structured.jsonl"  # JSONL = newline-delimited JSON</p>

<p>  # Handlers</p>
<p>  handlers:</p>
<p>    console:</p>
<p>      enabled: true  # Human-readable in dev, JSON in prod</p>
<p>      format: "text"  # Override per environment</p>

<p>    file:</p>
<p>      enabled: true</p>
<p>      format: "json"</p>
<p>      rotation:</p>
<p>        max_bytes: 10485760  # 10 MB</p>
<p>        backup_count: 10</p>

<p>  # Base fields (always included)</p>
<p>  base_fields:</p>
<ul>
<li>   - "timestamp"</li>
<li>   - "level"</li>
<li>   - "logger"</li>
<li>   - "message"</li>
<li>   - "module"</li>
<li>   - "function"</li>
<li>   - "line"</li>
<li>   - "thread"</li>
<li>   - "process"</li>
<li>   - "environment"</li>
</ul>

<p>  # Context fields (opt-in per log call)</p>
<p>  context_fields:</p>
<ul>
<li>   - "request_id"</li>
<li>   - "session_id"</li>
<li>   - "user_id"</li>
<li>   - "operation"</li>
<li>   - "component"</li>
<li>   - "duration_ms"</li>
</ul>

<p>overrides:</p>
<p>  development:</p>
<p>    structured:</p>
<p>      enabled: true</p>
<p>      handlers:</p>
<p>        console:</p>
<p>          format: "text"  # Human-readable</p>
<p>        file:</p>
<p>          format: "json"  # Analytics</p>

<p>  production:</p>
<p>    structured:</p>
<p>      enabled: true</p>
<p>      handlers:</p>
<p>        console:</p>
<p>          format: "json"  # Machine-readable</p>
<p>        file:</p>
<p>          format: "json"</p>

<p>  testing:</p>
<p>    structured:</p>
<p>      enabled: true</p>
<p>      handlers:</p>
<p>        console:</p>
<p>          enabled: false</p>
<p>        file:</p>
<p>          format: "json"</p>
<pre><code>
### 5.2 Initialization Code

**Create `src/utils/structured_logging.py`:**
</code></pre>
<p>"""</p>
<p>Structured logging setup for DefinitieAgent.</p>

<p>Provides JSON logging with context management and lazy evaluation.</p>
<p>"""</p>

<p>import logging</p>
<p>import os</p>
<p>from pathlib import Path</p>
<p>from typing import Any</p>

<p>from pythonjsonlogger import jsonlogger</p>


<p>class CustomJsonFormatter(jsonlogger.JsonFormatter):</p>
<p>    """</p>
<p>    Custom JSON formatter with additional context.</p>

<p>    Adds environment, cleans up field names, and handles Dutch/English messages.</p>
<p>    """</p>

<p>    def add_fields(self, log_record: dict, record: logging.LogRecord, message_dict: dict):</p>
<p>        super().add_fields(log_record, record, message_dict)</p>

<p>        # Add environment</p>
<p>        log_record['environment'] = os.getenv('APP_ENV', 'development')</p>

<p>        # Rename fields for consistency</p>
<p>        log_record['level'] = record.levelname</p>
<p>        log_record['logger'] = record.name</p>
<p>        log_record['timestamp'] = self.formatTime(record, self.datefmt)</p>

<p>        # Add component if available (from extra)</p>
<p>        if hasattr(record, 'component'):</p>
<p>            log_record['component'] = record.component</p>


<p>def setup_structured_logging(config_path: str | None = None):</p>
<p>    """</p>
<p>    Setup structured logging based on configuration.</p>

<p>    Args:</p>
<p>        config_path: Path to logging_config.yaml (optional)</p>
<p>    """</p>
<p>    import yaml</p>

<p>    # Load configuration</p>
<p>    if config_path is None:</p>
<p>        config_path = "config/logging_config.yaml"</p>

<p>    with open(config_path) as f:</p>
<p>        config = yaml.safe_load(f)</p>

<p>    # Get environment</p>
<p>    env = os.getenv('APP_ENV', 'development')</p>
<p>    overrides = config.get('overrides', {}).get(env, {})</p>

<p>    # Merge overrides</p>
<p>    structured_config = config.get('structured', {})</p>
<p>    structured_config.update(overrides.get('structured', {}))</p>

<p>    if not structured_config.get('enabled', False):</p>
<p>        return  # Structured logging disabled</p>

<p>    # Setup root logger</p>
<p>    root_logger = logging.getLogger()</p>

<p>    # Console handler</p>
<p>    console_config = structured_config.get('handlers', {}).get('console', {})</p>
<p>    if console_config.get('enabled', True):</p>
<p>        console_handler = logging.StreamHandler()</p>

<p>        if console_config.get('format') == 'json':</p>
<p>            formatter = CustomJsonFormatter(</p>
<p>                '%(timestamp)s %(level)s %(logger)s %(message)s'</p>
<p>            )</p>
<p>        else:</p>
<p>            # Human-readable format</p>
<p>            formatter = logging.Formatter(</p>
<p>                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'</p>
<p>            )</p>

<p>        console_handler.setFormatter(formatter)</p>
<p>        root_logger.addHandler(console_handler)</p>

<p>    # File handler (JSON)</p>
<p>    file_config = structured_config.get('handlers', {}).get('file', {})</p>
<p>    if file_config.get('enabled', True):</p>
<p>        from logging.handlers import RotatingFileHandler</p>

<p>        log_file = structured_config.get('file', 'logs/definitie_agent_structured.jsonl')</p>
<p>        Path(log_file).parent.mkdir(parents=True, exist_ok=True)</p>

<p>        file_handler = RotatingFileHandler(</p>
<p>            log_file,</p>
<p>            maxBytes=file_config.get('rotation', {}).get('max_bytes', 10485760),</p>
<p>            backupCount=file_config.get('rotation', {}).get('backup_count', 10),</p>
<p>            encoding='utf-8'</p>
<p>        )</p>

<p>        formatter = CustomJsonFormatter(</p>
<p>            '%(timestamp)s %(level)s %(logger)s %(message)s'</p>
<p>        )</p>
<p>        file_handler.setFormatter(formatter)</p>
<p>        root_logger.addHandler(file_handler)</p>


<p>class LogContext:</p>
<p>    """</p>
<p>    Context manager for adding structured context to logs.</p>

<p>    Usage:</p>
<p>        with LogContext(request_id="req_123", operation="generate"):</p>
<p>            logger.info("Starting operation")</p>
<p>    """</p>

<p>    def __init__(self, **context: Any):</p>
<p>        self.context = context</p>
<p>        self.logger_class = logging.getLoggerClass()</p>

<p>    def __enter__(self):</p>
<p>        # Store original makeRecord</p>
<p>        self._original_makeRecord = self.logger_class.makeRecord</p>

<p>        # Patch makeRecord to add context</p>
<p>        def makeRecord_with_context(self_logger, <em>args, </em>*kwargs):</p>
<p>            record = self._original_makeRecord(<em>args, </em>*kwargs)</p>
<p>            for key, value in self.context.items():</p>
<p>                setattr(record, key, value)</p>
<p>            return record</p>

<p>        self.logger_class.makeRecord = makeRecord_with_context</p>
<p>        return self</p>

<p>    def __exit__(self, *args):</p>
<p>        # Restore original makeRecord</p>
<p>        self.logger_class.makeRecord = self._original_makeRecord</p>


<h1>Convenience functions</h1>
<p>def log_with_context(logger: logging.Logger, level: str, message: str, **context):</p>
<p>    """</p>
<p>    Log a message with structured context.</p>

<p>    Args:</p>
<p>        logger: Logger instance</p>
<p>        level: Log level (info, debug, warning, error, critical)</p>
<p>        message: Log message</p>
<p>        **context: Additional context fields</p>
<p>    """</p>
<p>    log_func = getattr(logger, level.lower())</p>
<p>    log_func(message, extra=context)</p>
<pre><code>
### 5.3 Integration in main.py

**Update `src/main.py`:**
</code></pre>
<p>import logging</p>
<p>import os</p>
<p>import sys</p>
<p>from pathlib import Path</p>

<h1>Add src directory to Python path</h1>
<p>src_path = Path(__file__).parent</p>
<p>if str(src_path) not in sys.path:</p>
<p>    sys.path.insert(0, str(src_path))</p>

<p>import streamlit as st</p>

<p>from ui.session_state import SessionStateManager</p>
<p>from ui.tabbed_interface import TabbedInterface</p>
<p>from utils.exceptions import log_and_display_error</p>

<h1>NEW: Setup structured logging</h1>
<p>from utils.structured_logging import setup_structured_logging</p>

<h1>Setup structured logging BEFORE basicConfig</h1>
<p>try:</p>
<p>    setup_structured_logging()</p>
<p>except Exception as e:</p>
<p>    # Fallback to basic logging if structured logging fails</p>
<p>    logging.basicConfig(</p>
<p>        level=logging.INFO,</p>
<p>        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"</p>
<p>    )</p>
<p>    logging.warning(f"Failed to setup structured logging: {e}")</p>

<h1>Add PII filter (still needed)</h1>
<p>try:</p>
<p>    from utils.logging_filters import PIIRedactingFilter</p>
<p>    _root = logging.getLogger()</p>
<p>    if not any(isinstance(f, PIIRedactingFilter) for f in _root.filters):</p>
<p>        _root.addFilter(PIIRedactingFilter())</p>
<p>except Exception:</p>
<p>    pass</p>

<p>logger = logging.getLogger(__name__)</p>

<h1>... rest of main.py unchanged</h1>
<pre><code>
---

## 6. Analytics Use Cases

### 6.1 Queries Enabled by Structured Logging

**Example 1: ServiceContainer Initialization Analysis**</code></pre>
<h1>Query: How many times is ServiceContainer initialized per session?</h1>
<p>jq 'select(.component == "service_container" and .message | contains("geïnitialiseerd")) | {timestamp, init_count}' \</p>
<p>  logs/definitie_agent_structured.jsonl</p>
<pre><code>
**Example 2: AI Service Cost Tracking**</code></pre>
<h1>Query: Total API cost in last 24 hours</h1>
<p>jq -s 'map(select(.component == "ai_service" and .cost)) | map(.cost) | add' \</p>
<p>  logs/definitie_agent_structured.jsonl</p>
<pre><code>
**Example 3: Slow Operations**</code></pre>
<h1>Query: All operations slower than 5 seconds</h1>
<p>jq 'select(.duration_ms > 5000) | {timestamp, operation, duration_ms, component}' \</p>
<p>  logs/definitie_agent_structured.jsonl</p>
<pre><code>
**Example 4: Validation Rule Failures**</code></pre>
<h1>Query: Most common failing validation rules</h1>
<p>jq -s 'map(select(.component == "validation" and .validation_passed == false)) |</p>
<p>  group_by(.rule_id) | map({rule: .[0].rule_id, count: length}) |</p>
<p>  sort_by(-.count)' \</p>
<p>  logs/definitie_agent_structured.jsonl</p>
<pre><code>
**Example 5: Error Rate by Component**</code></pre>
<h1>Query: Error rate per component</h1>
<p>jq -s 'map(select(.level == "ERROR")) | group_by(.component) |</p>
<p>  map({component: .[0].component, errors: length})' \</p>
<p>  logs/definitie_agent_structured.jsonl</p>
<pre><code>
### 6.2 Integration with Analytics Tools

**Option 1: Local Analysis (jq + Python)**
- Use `jq` for quick CLI queries
- Python scripts for complex analytics
- Generate reports with pandas/matplotlib

**Option 2: Elasticsearch/Kibana (Future)**
- Ship logs to Elasticsearch
- Visualize in Kibana dashboards
- Set up alerts for critical metrics

**Option 3: Grafana Loki (Lightweight)**
- Log aggregation without full ELK stack
- Time-series queries
- Cost-effective for small deployments

---

## 7. Implementation Complexity Estimate

### 7.1 Effort Breakdown

| Phase | Tasks | Estimated Effort | Complexity |
|-------|-------|------------------|------------|
| **Phase 1: Infrastructure** | - Add dependency&lt;br&gt;- Create structured_logging.py&lt;br&gt;- Update config&lt;br&gt;- Test dual-output | 4-6 hours | Low |
| **Phase 2: Core Services** | - Migrate 3 core services&lt;br&gt;- Add context managers&lt;br&gt;- Update tests | 12-16 hours | Medium |
| **Phase 3: Supporting Services** | - Migrate 10+ services&lt;br&gt;- Update UI components | 16-24 hours | Medium |
| **Phase 4: Optimization** | - Remove f-strings&lt;br&gt;- Add correlation IDs&lt;br&gt;- Performance profiling | 8-12 hours | Low-Medium |
| **Total** | | **40-58 hours** | **Medium** |

### 7.2 Risk Assessment

| Risk | Impact | Likelihood | Mitigation |
|------|--------|------------|------------|
| Performance degradation | High | Low | Benchmark before/after, optimize if needed |
| Log volume explosion | Medium | Medium | Enable sampling in production, monitor disk usage |
| Breaking existing log parsing | Low | Low | Gradual migration, test thoroughly |
| Missing context in logs | Medium | Medium | Add context incrementally, document patterns |

### 7.3 Success Criteria

- [ ] Zero performance degradation (&lt; 5% overhead)
- [ ] 100% backward compatibility (existing logs still work)
- [ ] Core services (Container, AI, Validation) migrated
- [ ] Analytics queries functional (5+ example queries work)
- [ ] Documentation complete (migration guide + examples)

---

## 8. Performance Impact Analysis

### 8.1 Expected Overhead

**JSON Serialization:**
- Overhead: ~10-50 microseconds per log call
- Acceptable for INFO+ levels
- Use lazy evaluation for DEBUG level

**File I/O:**
- Async handlers can buffer writes
- Rotating file handler is efficient
- Compression reduces disk usage by ~5-10x

**Memory:**
- JSON formatter: Negligible (&lt; 1 MB)
- Log buffers: Configurable (default 100 records)

### 8.2 Optimization Strategies

**1. Lazy Evaluation**</code></pre>
<h1>Bad (always evaluates f-string)</h1>
<p>logger.debug(f"Processing {len(items)} items: {items}")</p>

<h1>Good (only evaluates if DEBUG enabled)</h1>
<p>logger.debug("Processing %d items: %s", len(items), items)</p>
<pre><code>
**2. Sampling**</code></pre>
<p>sampling:</p>
<p>  enabled: true</p>
<p>  levels:</p>
<p>    DEBUG: 0.01  # Log 1% of DEBUG messages</p>
<p>    INFO: 0.1    # Log 10% of INFO messages</p>
<p>    WARNING: 1.0  # Log 100% of WARNING+ messages</p>
<pre><code>
**3. Async Handlers**</code></pre>
<p>from logging.handlers import QueueHandler, QueueListener</p>

<h1>Offload logging to background thread</h1>
<p>queue_handler = QueueHandler(queue)</p>
<p>queue_listener = QueueListener(queue, file_handler)</p>
<pre><code>
### 8.3 Benchmark Results (Estimated)

| Operation | Before (f-string) | After (lazy %) | After (JSON extra) |
|-----------|-------------------|----------------|---------------------|
| Log call (disabled) | ~1 µs | ~0.1 µs | ~0.1 µs |
| Log call (enabled) | ~50 µs | ~60 µs | ~100 µs |
| Throughput | 20k logs/s | 18k logs/s | 10k logs/s |

**Conclusion:** JSON structured logging adds ~2x overhead, but this is acceptable for INFO+ levels. Use sampling for high-frequency DEBUG logs.

---

## 9. Integration with Existing Monitoring

### 9.1 Current Monitoring (api_monitor.py)

**Already Implemented:**
- API call tracking with JSON export
- Cost calculation
- Performance metrics (response time, throughput)
- Alert system (MetricSnapshot, AlertSeverity)

**Integration Points:**
1. **Unified Logging:** api_monitor logs should use structured logging
2. **Correlation:** Add `request_id` to link API calls with application logs
3. **Aggregation:** Combine API metrics with service logs for full picture

### 9.2 Monitoring Dashboard (Future)

**Metrics to Track:**
1. **Service Health:**
   - Container initialization count (should be 1x)
   - Service creation rate
   - Error rate per component

2. **Performance:**
   - Operation duration (p50, p95, p99)
   - Slow operations (&gt; threshold)
   - Cache hit rate

3. **Cost:**
   - API cost per hour/day
   - Token usage per operation
   - Cost per definition generated

4. **Quality:**
   - Validation rule pass/fail rates
   - Definition quality scores
   - Manual intervention rate

**Visualization:**
- Grafana dashboards (if Loki integrated)
- Python scripts with matplotlib
- Simple web UI with Flask/Streamlit

---

## 10. Example Before/After Logs

### 10.1 ServiceContainer Initialization

**Before (Current):**</code></pre>
<p>2025-10-07 10:38:31,504 - services.container - INFO - ServiceContainer geïnitialiseerd (init count: 1)</p>
<pre><code>
**After (Structured):**</code></pre>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:38:31.504Z",</p>
<p>  "level": "INFO",</p>
<p>  "logger": "services.container",</p>
<p>  "message": "ServiceContainer geïnitialiseerd",</p>
<p>  "component": "service_container",</p>
<p>  "init_count": 1,</p>
<p>  "config_hash": "abc123def456",</p>
<p>  "environment": "production",</p>
<p>  "module": "container",</p>
<p>  "function": "__init__",</p>
<p>  "line": 68</p>
<p>}</p>
<pre><code>
### 10.2 AI Service Call

**Before:**</code></pre>
<p>2025-10-07 10:40:15,234 - services.ai_service_v2 - DEBUG - Cache hit for prompt: Generate a definition for...</p>
<pre><code>
**After:**</code></pre>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:40:15.234Z",</p>
<p>  "level": "DEBUG",</p>
<p>  "logger": "services.ai_service_v2",</p>
<p>  "message": "Cache hit for prompt",</p>
<p>  "component": "ai_service",</p>
<p>  "operation": "generate_definition",</p>
<p>  "model": "gpt-4o-mini",</p>
<p>  "prompt_length": 1234,</p>
<p>  "cached": true,</p>
<p>  "cache_key": "prompt_abc123",</p>
<p>  "duration_ms": 5,</p>
<p>  "request_id": "req_xyz789"</p>
<p>}</p>
<pre><code>
### 10.3 Validation Error

**Before:**</code></pre>
<p>2025-10-07 10:42:30,567 - services.validation - WARNING - Validation rule ARAI-01 failed for definition</p>
<pre><code>
**After:**</code></pre>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:42:30.567Z",</p>
<p>  "level": "WARNING",</p>
<p>  "logger": "services.validation",</p>
<p>  "message": "Validation rule failed",</p>
<p>  "component": "validation",</p>
<p>  "operation": "validate_definition",</p>
<p>  "rule_id": "ARAI-01",</p>
<p>  "rule_category": "ARAI",</p>
<p>  "rule_name": "Afgebakend begrip",</p>
<p>  "validation_passed": false,</p>
<p>  "score": 0.45,</p>
<p>  "threshold": 0.7,</p>
<p>  "definition_id": 123,</p>
<p>  "term": "burgerservicenummer",</p>
<p>  "request_id": "req_xyz789"</p>
<p>}</p>
<pre><code>
### 10.4 Web Lookup Operation

**Before:**</code></pre>
<p>2025-10-07 10:45:12,890 - services.modern_web_lookup_service - INFO - Starting lookup for term: burgerservicenummer</p>
<p>2025-10-07 10:45:13,234 - services.web_lookup.wikipedia_service - INFO - Wikipedia lookup voor term: burgerservicenummer</p>
<p>2025-10-07 10:45:14,123 - services.modern_web_lookup_service - WARNING - Source lookup failed: {'source': 'sru', 'error': 'timeout'}</p>
<pre><code>
**After:**</code></pre>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:45:12.890Z",</p>
<p>  "level": "INFO",</p>
<p>  "logger": "services.modern_web_lookup_service",</p>
<p>  "message": "Starting web lookup",</p>
<p>  "component": "web_lookup",</p>
<p>  "operation": "lookup_term",</p>
<p>  "term": "burgerservicenummer",</p>
<p>  "sources": ["wikipedia", "sru"],</p>
<p>  "request_id": "req_abc123"</p>
<p>}</p>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:45:13.234Z",</p>
<p>  "level": "INFO",</p>
<p>  "logger": "services.web_lookup.wikipedia_service",</p>
<p>  "message": "Wikipedia lookup started",</p>
<p>  "component": "web_lookup",</p>
<p>  "operation": "wikipedia_lookup",</p>
<p>  "source": "wikipedia",</p>
<p>  "api_type": "mediawiki",</p>
<p>  "term": "burgerservicenummer",</p>
<p>  "request_id": "req_abc123"</p>
<p>}</p>
<p>{</p>
<p>  "timestamp": "2025-10-07T10:45:14.123Z",</p>
<p>  "level": "WARNING",</p>
<p>  "logger": "services.modern_web_lookup_service",</p>
<p>  "message": "Source lookup failed",</p>
<p>  "component": "web_lookup",</p>
<p>  "operation": "lookup_term",</p>
<p>  "source": "sru",</p>
<p>  "error_type": "TimeoutError",</p>
<p>  "error_message": "Request timeout after 5s",</p>
<p>  "duration_ms": 5000,</p>
<p>  "request_id": "req_abc123"</p>
<p>}</p>
<pre><code>
---

## 11. Migration Checklist

### Phase 1: Infrastructure Setup
- [ ] Add `python-json-logger==2.0.7` to `requirements.txt`
- [ ] Create `src/utils/structured_logging.py`
- [ ] Update `src/main.py` to call `setup_structured_logging()`
- [ ] Test console output (dev environment)
- [ ] Test JSON file output (`logs/definitie_agent_structured.jsonl`)
- [ ] Verify PII redaction still works
- [ ] Document configuration options

### Phase 2: Core Services Migration
- [ ] **ServiceContainer** (`src/services/container.py`)
  - [ ] Migrate `__init__` logging
  - [ ] Add `component="service_container"` to all logs
  - [ ] Add `service_name` to service factory logs
  - [ ] Add `config_hash` to initialization logs
- [ ] **AIServiceV2** (`src/services/ai_service_v2.py`)
  - [ ] Migrate `generate_definition` logging
  - [ ] Add structured fields: `model`, `temperature`, `tokens_used`, `cost`, `cached`
  - [ ] Add `request_id` context manager
  - [ ] Track cache hit/miss rates
- [ ] **ValidationOrchestratorV2** (`src/services/orchestrators/validation_orchestrator_v2.py`)
  - [ ] Migrate validation result logging
  - [ ] Add structured fields: `rule_id`, `rule_category`, `score`, `passed`
  - [ ] Track validation metrics

### Phase 3: Supporting Services
- [ ] **ModernWebLookupService** (`src/services/modern_web_lookup_service.py`)
- [ ] **DefinitionRepository** (`src/services/definition_repository.py`)
- [ ] **CleaningService** (`src/services/cleaning_service.py`)
- [ ] **WorkflowService** (`src/services/workflow_service.py`)
- [ ] **UI Components** (`src/ui/components/`)

### Phase 4: Optimization
- [ ] Replace f-strings with lazy evaluation (priority: hot paths)
- [ ] Add correlation ID middleware
- [ ] Performance profiling (before/after comparison)
- [ ] Create analytics queries documentation
- [ ] Set up log rotation and archival
- [ ] Create monitoring dashboard (optional)

### Phase 5: Documentation
- [ ] Update `CLAUDE.md` with structured logging guidelines
- [ ] Create migration guide for developers
- [ ] Document log schema and fields
- [ ] Create analytics query examples
- [ ] Update troubleshooting guide

---

## 12. Recommendations

### 12.1 Immediate Actions (Week 1)
1. **Install python-json-logger:** Add to requirements and test
2. **Create infrastructure:** Implement `structured_logging.py`
3. **Test dual output:** Verify console + JSON file work together
4. **Migrate ServiceContainer:** Highest value, easy win

### 12.2 Short-Term (Weeks 2-4)
1. **Migrate AI Service:** Critical for cost tracking
2. **Migrate Validation:** Important for quality metrics
3. **Add correlation IDs:** Essential for request tracing
4. **Create analytics queries:** Demonstrate value

### 12.3 Long-Term (Months 1-3)
1. **Complete migration:** All services use structured logging
2. **Optimize performance:** Remove f-strings, add sampling
3. **Build dashboard:** Visualize key metrics
4. **Integrate with monitoring:** Elasticsearch/Loki/Grafana (optional)

### 12.4 Best Practices

**DO:**
- ✅ Use `extra` parameter for structured context
- ✅ Add `component` field to all logs
- ✅ Use ISO 8601 timestamps (UTC)
- ✅ Include `request_id` for tracing
- ✅ Log durations in milliseconds
- ✅ Use lazy evaluation (`%s` formatting)

**DON'T:**
- ❌ Use f-strings for logging
- ❌ Log sensitive data (PII, API keys)
- ❌ Log at DEBUG level in production (without sampling)
- ❌ Create deeply nested JSON (keep flat)
- ❌ Mix Dutch and English in same log message
- ❌ Log raw exception objects (serialize first)

---

## 13. Conclusion

### Summary

This architecture provides a **pragmatic, low-risk path** to structured logging for DefinitieAgent:

1. **Library:** `python-json-logger` (drop-in replacement, zero refactoring)
2. **Strategy:** Gradual migration with dual output (console + JSON)
3. **Schema:** Standardized fields with component-specific extensions
4. **Migration:** 4 phases over 6 weeks, ~40-58 hours effort
5. **Value:** Enables analytics, monitoring, and operational insights

### Next Steps

1. **Review this design** with stakeholders
2. **Approve Phase 1** infrastructure changes
3. **Create Epic/User Stories** for implementation
4. **Start with ServiceContainer** migration (quick win)
5. **Iterate based on feedback** and metrics

### Success Metrics

- **Performance:** &lt; 5% overhead
- **Coverage:** 80%+ of logs structured within 6 weeks
- **Analytics:** 5+ working queries demonstrating value
- **Quality:** Zero regressions in existing functionality

---

## Appendices

### A. Dependencies
</code></pre>
<h1>requirements.txt</h1>
<p>python-json-logger==2.0.7  # BSD License, 4.5M+ downloads/month</p>
<p>PyYAML==6.0.1  # Already in requirements</p>
<pre><code>
### B. Configuration Files

**Location:** `config/logging_config.yaml`
**Status:** Exists but not loaded
**Action:** Update structured logging section, load in main.py

### C. Related Documents

- `config/logging_config.yaml` - Logging configuration (exists)
- `src/utils/logging_filters.py` - PII redaction filter (exists)
- `src/monitoring/api_monitor.py` - API monitoring (exists)
- `CLAUDE.md` - Project guidelines (update with logging standards)

### D. External Resources

- [python-json-logger Documentation](https://github.com/madzak/python-json-logger)
- [Python logging best practices](https://docs.python.org/3/howto/logging.html)
- [Structured logging guidelines](https://www.structlog.org/en/stable/why.html)

---

**Document Version:** 1.0
**Last Updated:** 2025-10-07
**Next Review:** After Phase 1 completion
</code></pre>
  </div>
</body>
</html>