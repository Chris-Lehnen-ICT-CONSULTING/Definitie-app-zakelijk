<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>PROMPT V8 IMPLEMENTATION PLAN</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">‚Üê Terug naar Portal</a>
    <h1>PROMPT V8 IMPLEMENTATION PLAN</h1>
<p><strong>Project:</strong> DefinitieAgent Prompt Optimization</p>
<p><strong>Van:</strong> v7 (7.250 tokens) ‚Üí v8 (2.650 tokens)</p>
<p><strong>Timeline:</strong> 3 weken</p>
<p><strong>Effort:</strong> 16 uur totaal</p>

<p>---</p>

<h2>üéØ DOELSTELLINGEN</h2>

<ol>
<li>**Token Reductie:** 7.250 ‚Üí 2.650 (-63%)</li>
<li>**Conflict Resolution:** 10 ‚Üí 0 conflicten</li>
<li>**LLM Compliance:** 60% ‚Üí 90%</li>
<li>**Generatie Snelheid:** 4-5s ‚Üí 2-3s</li>
<li>**Kwaliteit Score:** 6.5/10 ‚Üí 8.5/10</li>
</ol>

<p>---</p>

<h2>üìã FASE 1: QUICK WINS (Week 1, 4 uur)</h2>

<h3>1.1 Verwijder Dubbele Validatieregels</h3>

<p><strong>Bestanden om aan te passen:</strong></p>
<pre><code># src/services/prompts/modules/arai_rules_module.py
# src/services/prompts/modules/con_rules_module.py
# src/services/prompts/modules/ess_rules_module.py
# src/services/prompts/modules/integrity_rules_module.py
# src/services/prompts/modules/sam_rules_module.py
# src/services/prompts/modules/structure_rules_module.py
# src/services/prompts/modules/ver_rules_module.py</code></pre>

<p><strong>Van:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; List[str]:
    manager = get_cached_toetsregel_manager()
    all_rules = manager.get_all_regels()

    for regel_key, regel_data in sorted_rules:
        sections.extend(self._format_rule(regel_key, regel_data))
        # Voegt 50-100 tokens per regel toe</code></pre>

<p><strong>Naar:</strong></p>
<pre><code>def execute(self, context: ModuleContext) -&gt; List[str]:
    # Alleen high-level principes, geen individuele regels
    return [
        "### ‚úÖ Algemene Regels (ARAI):",
        "- Begin met zelfstandig naamwoord (geen werkwoord/koppelwerkwoord)",
        "- Vermijd vage containerbegrippen zonder specificatie",
        "- Essentie beschrijven, niet het doel",
        "- Volledige validatie gebeurt automatisch na generatie",
        ""
    ]</code></pre>

<p><strong>Impact:</strong> -3.500 tokens (48% reductie)</p>

<h3>1.2 Fix Critical Conflicts</h3>

<p><strong>Bestand:</strong> <code>src/services/prompts/modules/error_prevention_module.py</code></p>

<p><strong>Wijziging regel 323-329:</strong></p>
<pre><code># VOOR:
"‚ùå Start niet met 'proces waarbij'",
"‚ùå Start niet met 'handeling die'",

# NA:
"‚ùå Start niet met koppelwerkwoord + categorie:",
"   - 'is een proces waarbij' (FOUT)",
"   - 'betreft een handeling die' (FOUT)",
"‚úÖ WEL toegestaan zonder koppelwerkwoord:",
"   - 'activiteit waarbij' (GOED)",
"   - 'handeling waarin' (GOED)",</code></pre>

<h3>1.3 Consolideer Verboden Lijst</h3>

<p><strong>Bestand:</strong> <code>src/services/prompts/modules/error_prevention_module.py</code></p>

<p><strong>Van:</strong> 42 individuele verboden (regels 294-335)</p>

<p><strong>Naar:</strong></p>
<pre><code>def _build_error_section(self) -&gt; List[str]:
    return [
        "### ‚úÖ APPROVED START PATTERNS:",
        "",
        "**PROCES:** [activiteit/handeling] waarbij [actor] [actie] uitvoert",
        "**TYPE:** [soort/categorie] [bovenbegrip] met kenmerk",
        "**RESULTAAT:** [uitkomst] van [proces] dat [functie]",
        "",
        "üö´ VERMIJD: Koppelwerkwoorden ('is'), lidwoorden ('de/het'), term-herhaling",
        ""
    ]</code></pre>

<p><strong>Impact:</strong> -750 tokens</p>

<h3>1.4 Test & Valideer</h3>

<pre><code># Test script
python scripts/test_prompt_generation.py \
    --begrippen "integriteit,sanctie,toezicht,evaluatie" \
    --compare-versions v7,v8-quick \
    --metrics tokens,conflicts,quality</code></pre>

<p>---</p>

<h2>üìã FASE 2: STRUCTURELE REFACTOR (Week 2, 8 uur)</h2>

<h3>2.1 Implementeer Inverted Pyramid Template</h3>

<p><strong>Nieuw bestand:</strong> <code>src/services/prompts/templates/inverted_pyramid.py</code></p>

<pre><code>class InvertedPyramidTemplate:
    """
    Nieuwe prompt structuur:
    1. Mission Statement (50 tokens)
    2. Golden Rules (300 tokens)
    3. Templates (400 tokens)
    4. Refinement (800 tokens)
    5. Checklist (100 tokens)
    """

    def build(self, context: PromptContext) -&gt; str:
        sections = [
            self._build_mission(context),
            self._build_golden_rules(),
            self._build_templates(context.category),
            self._build_refinement_rules(),
            self._build_checklist()
        ]
        return "\n\n".join(sections)</code></pre>

<h3>2.2 Conditional Module Loading</h3>

<p><strong>Bestand:</strong> <code>src/services/prompts/modules/prompt_orchestrator.py</code></p>

<pre><code>def build_prompt(self, context: ModuleContext) -&gt; str:
    # Filter modules based on context
    active_modules = self._get_active_modules(context)

    def _get_active_modules(self, context: ModuleContext) -&gt; List[str]:
        """Only load modules relevant for this request."""

        # Always include core
        modules = ["expertise", "output_specification", "task"]

        # Conditional modules
        if context.has_context_info():
            modules.append("context_awareness")

        if context.get_complexity() &gt; 0.7:
            modules.append("grammar")
            modules.append("metrics")

        if context.requires_templates():
            modules.append("template")
            modules.append("semantic_categorisation")

        # Only include 2-3 most relevant rule modules
        if context.focus_area == "structure":
            modules.append("structure_rules")
        elif context.focus_area == "integrity":
            modules.append("integrity_rules")
        else:
            modules.append("ess_rules")  # Default to essential rules

        return modules</code></pre>

<h3>2.3 Static Module Caching</h3>

<p><strong>Bestand:</strong> <code>src/services/prompts/cache/module_cache.py</code></p>

<pre><code>import streamlit as st

class ModuleCache:
    """Cache static module outputs that don't change per request."""

    @st.cache_data(ttl=3600)
    def get_grammar_output(self) -&gt; str:
        """Grammar rules don't change - cache for 1 hour."""
        from ..modules.grammar_module import GrammarModule
        return GrammarModule().execute(ModuleContext())

    @st.cache_data(ttl=3600)
    def get_error_prevention_output(self) -&gt; str:
        """Error patterns are static - cache."""
        from ..modules.error_prevention_module import ErrorPreventionModule
        return ErrorPreventionModule().execute(ModuleContext())</code></pre>

<h3>2.4 Implementeer Priority Signaling</h3>

<p><strong>Update alle regel modules met prioriteit:</strong></p>

<pre><code>class EssRulesModule(BasePromptModule):
    def execute(self, context: ModuleContext) -&gt; List[str]:
        return [
            "### üî¥ KRITIEKE REGELS (Must-Have):",
            "- **ESS-02:** Ontologische categorie expliciet",
            "- **ESS-01:** Essentie, niet doel",
            "",
            "### üü° BELANGRIJKE REGELS (Should-Have):",
            "- **ESS-03:** Instanties uniek onderscheidbaar",
            "",
            "### üü¢ NICE-TO-HAVE (Polish):",
            "- **ESS-04:** Toetsbaarheid",
            "- **ESS-05:** Voldoende onderscheidend",
        ]</code></pre>

<p>---</p>

<h2>üìã FASE 3: VALIDATIE & DEPLOYMENT (Week 3, 4 uur)</h2>

<h3>3.1 A/B Testing Framework</h3>

<p><strong>Nieuw:</strong> <code>scripts/ab_test_prompts.py</code></p>

<pre><code>import asyncio
from typing import Dict, List

class PromptABTest:
    def __init__(self):
        self.test_begrippen = [
            # Proces begrippen
            "observatie", "registratie", "evaluatie",
            # Type begrippen
            "sanctie", "maatregel", "voorziening",
            # Resultaat begrippen
            "besluit", "uitspraak", "rapport",
            # Edge cases
            "AVG", "DJI", "re-integratie"
        ]

    async def run_test(self) -&gt; Dict:
        results = {
            "v7": await self.test_version("v7"),
            "v8": await self.test_version("v8")
        }
        return self.compare_results(results)</code></pre>

<h3>3.2 Kwaliteitsmetrics</h3>

<pre><code>class QualityMetrics:
    """Meet definitie kwaliteit volgens standaarden."""

    def measure(self, definition: str, prompt_version: str) -&gt; Dict:
        return {
            "tokens_used": self.count_tokens(prompt_version),
            "generation_time": self.time_generation(),
            "validation_pass": self.run_validation(definition),
            "expert_score": self.get_expert_review(definition),
            "conflicts_detected": self.detect_conflicts(),
            "rule_compliance": self.check_rule_compliance(definition)
        }</code></pre>

<h3>3.3 Rollout Strategy</h3>

<p><strong>Stap 1: Shadow Mode (Week 3, Dag 1-2)</strong></p>
<pre><code># Beide versies draaien, v8 alleen voor metrics
if FEATURE_FLAGS.get("prompt_v8_shadow"):
    v7_result = generate_with_v7(begrip)
    v8_result = generate_with_v8(begrip)
    log_comparison(v7_result, v8_result)
    return v7_result  # Gebruik nog v7</code></pre>

<p><strong>Stap 2: Canary Release (Week 3, Dag 3-4)</strong></p>
<pre><code># 10% van requests gebruikt v8
if random.random() &lt; 0.1:
    return generate_with_v8(begrip)
else:
    return generate_with_v7(begrip)</code></pre>

<p><strong>Stap 3: Full Rollout (Week 3, Dag 5)</strong></p>
<pre><code># 100% v8 met fallback
try:
    return generate_with_v8(begrip)
except Exception as e:
    logger.warning(f"V8 failed, falling back: {e}")
    return generate_with_v7(begrip)</code></pre>

<p>---</p>

<h2>üß™ TEST SCENARIOS</h2>

<h3>Scenario 1: Basis Proces Definitie</h3>
<pre><code>test_case = {
    "begrip": "integriteit",
    "context": {"organisatorisch": "test"},
    "expected_start": "activiteit waarbij",
    "max_tokens": 3000,
    "must_validate": ["ESS-02", "STR-01", "INT-01"]
}</code></pre>

<h3>Scenario 2: Complex met Juridische Context</h3>
<pre><code>test_case = {
    "begrip": "sanctie",
    "context": {
        "juridisch": "Wetboek van Strafrecht",
        "wettelijk": "Art. 9 Sr"
    },
    "expected_category": "resultaat",
    "max_tokens": 3500
}</code></pre>

<h3>Scenario 3: Edge Case - Afkorting</h3>
<pre><code>test_case = {
    "begrip": "AVG",
    "expected_contains": "Algemene Verordening Gegevensbescherming",
    "max_chars": 350
}</code></pre>

<p>---</p>

<h2>üìä SUCCESS CRITERIA</h2>

<h3>Go/No-Go Decision Matrix</h3>

<p>| Criterium | Target | No-Go Threshold | Measurement |</p>
<p>|-----------|--------|-----------------|-------------|</p>
<p>| Token Reductie | >50% | <30% | Automated |</p>
<p>| Conflicten | 0 | >2 | Automated |</p>
<p>| Validatie Success | >85% | <70% | Automated |</p>
<p>| Expert Score | >8.0 | <7.0 | Manual (3 experts) |</p>
<p>| Generatie Tijd | <3s | >5s | Automated |</p>
<p>| Error Rate | <5% | >10% | Automated |</p>

<h3>Rollback Triggers</h3>
<ul>
<li>Expert score < 7.0</li>
<li>Validatie success < 70%</li>
<li>Error rate > 10%</li>
<li>User complaints > 3 binnen 24 uur</li>
</ul>

<p>---</p>

<h2>üöÄ DEPLOYMENT CHECKLIST</h2>

<h3>Pre-Deployment (Week 2, Dag 5)</h3>
<ul>
<li>[ ] Code review door senior developer</li>
<li>[ ] Unit tests voor alle nieuwe modules</li>
<li>[ ] Integration tests voor prompt building flow</li>
<li>[ ] Performance benchmarks uitgevoerd</li>
<li>[ ] A/B test framework operational</li>
</ul>

<h3>Deployment Day (Week 3, Dag 5)</h3>
<ul>
<li>[ ] Feature flags configured</li>
<li>[ ] Rollback procedure documented</li>
<li>[ ] Monitoring dashboard actief</li>
<li>[ ] Hotfix procedure ready</li>
<li>[ ] Team briefing completed</li>
</ul>

<h3>Post-Deployment (Week 4)</h3>
<ul>
<li>[ ] Monitor metrics dagelijks</li>
<li>[ ] Collect user feedback</li>
<li>[ ] Fine-tune edge cases</li>
<li>[ ] Document lessons learned</li>
<li>[ ] Plan v8.1 improvements</li>
</ul>

<p>---</p>

<h2>üìà EXPECTED OUTCOMES</h2>

<h3>Week 1 (Quick Wins)</h3>
<ul>
<li>**Tokens:** 7.250 ‚Üí 5.000 (-31%)</li>
<li>**Conflicts:** 10 ‚Üí 0</li>
<li>**Effort:** 4 uur</li>
<li>**Risk:** Laag</li>
</ul>

<h3>Week 2 (Structural)</h3>
<ul>
<li>**Tokens:** 5.000 ‚Üí 3.000 (-58%)</li>
<li>**Module efficiency:** +40%</li>
<li>**Effort:** 8 uur</li>
<li>**Risk:** Medium</li>
</ul>

<h3>Week 3 (Optimization)</h3>
<ul>
<li>**Tokens:** 3.000 ‚Üí 2.650 (-63%)</li>
<li>**Quality score:** 6.5 ‚Üí 8.5</li>
<li>**Effort:** 4 uur</li>
<li>**Risk:** Laag</li>
</ul>

<p>---</p>

<h2>üîß TECHNICAL DEPENDENCIES</h2>

<h3>Required Updates</h3>
<ol>
<li>`CachedToetsregelManager` - Ensure cache works with summary mode</li>
<li>`ModularValidationService` - Verify works without prompt rules</li>
<li>`PromptServiceV2` - Support both v7 and v8 templates</li>
<li>`SessionStateManager` - Store prompt version preference</li>
</ol>

<h3>New Components</h3>
<ol>
<li>`InvertedPyramidTemplate` - New prompt structure</li>
<li>`ModuleCache` - Static content caching</li>
<li>`PromptABTest` - Testing framework</li>
<li>`QualityMetrics` - Measurement system</li>
</ol>

<p>---</p>

<h2>üë• TEAM & RESPONSIBILITIES</h2>

<h3>Development Team</h3>
<ul>
<li>**Lead Developer:** Implement Phase 1 & 2</li>
<li>**QA Engineer:** Design test scenarios, run A/B tests</li>
<li>**Domain Expert:** Review generated definitions, score quality</li>
</ul>

<h3>Stakeholders</h3>
<ul>
<li>**Product Owner:** Go/No-Go decision</li>
<li>**End Users:** Feedback tijdens canary release</li>
</ul>

<p>---</p>

<h2>üìù NOTES & RISKS</h2>

<h3>Risks</h3>
<ol>
<li>**Kwaliteit degradatie** - Mitigatie: Extensive A/B testing</li>
<li>**Unexpected conflicts** - Mitigatie: Shadow mode first</li>
<li>**Performance regression** - Mitigatie: Cache static content</li>
<li>**User resistance** - Mitigatie: Gradual rollout</li>
</ol>

<h3>Opportunities</h3>
<ol>
<li>**Further optimization** - Track which modules are most valuable</li>
<li>**Personalization** - User-specific prompt configurations</li>
<li>**Learning system** - Use validation results to improve prompts</li>
</ol>

<p>---</p>

<p><strong>Document Status:</strong> Ready for Review</p>
<p><strong>Next Step:</strong> Technical Review Meeting</p>
<p><strong>Decision Needed:</strong> Approve Phase 1 Quick Wins</p>
  </div>
</body>
</html>