<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Multiagent Workflow voor DefinitieAgent</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">‚Üê Terug naar Portal</a>
    <h1>Multiagent Workflow voor DefinitieAgent</h1>

<p><strong>Status:</strong> Active | <strong>Last Updated:</strong> 2025-10-29 | <strong>Source:</strong> DEF-56 Implementation</p>

<p>Deze workflow template biedt een systematische aanpak voor complexe bugs en features door gebruik te maken van meerdere gespecialiseerde AI agents in parallel.</p>

<p>---</p>

<h2>üéØ Wanneer Multiagent Workflow Gebruiken?</h2>

<p><strong>Use Cases:</strong></p>
<ul>
<li>**Complex bugs** met onduidelijke root cause</li>
<li>**Architectuur wijzigingen** met impact op meerdere modules</li>
<li>**Performance issues** die diepgaande analyse vereisen</li>
<li>**Code quality reviews** met refactoring</li>
<li>**New features** met onbekende requirements</li>
</ul>

<p><strong>Voordelen:</strong></p>
<ul>
<li>Parallelle executie ‚Üí sneller resultaat</li>
<li>Diverse perspectieven ‚Üí betere oplossingen</li>
<li>Built-in quality gates ‚Üí hogere kwaliteit</li>
<li>Systematische aanpak ‚Üí minder bugs</li>
</ul>

<p>---</p>

<h2>üîÑ Standard Workflow Phases</h2>

<h3>Phase 1: Root Cause Analysis (debug-specialist)</h3>

<p><strong>Agent:</strong> <code>debug-specialist</code> (via Task tool)</p>
<p><strong>Duration:</strong> ~10-15 min</p>
<p><strong>Deliverable:</strong> Comprehensive root cause analysis</p>

<p><strong>Prompt Template:</strong></p>
<pre><code>Analyze [ISSUE-ID]: [Title]

Problem Statement:
[Beschrijving van het probleem]

Symptoms:
- [Symptoom 1]
- [Symptoom 2]

Available Context:
- Files: [relevante file paths]
- Logs: [error messages / stack traces]
- User feedback: [quotes]

Research Tools:
- Use Perplexity MCP for deep technical research
- Use Context7 MCP for framework documentation
- Read source files for current implementation

Deliverables:
1. Root cause identification (what/why/how)
2. Contributing factors
3. Affected components
4. Proposed solution approaches (2-3 options)
5. Trade-offs per approach</code></pre>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ Clear root cause identified</li>
<li>‚úÖ Technical validation (via MCP research)</li>
<li>‚úÖ Multiple solution options with trade-offs</li>
</ul>

<p>---</p>

<h3>Phase 2: Implementation (full-stack-developer)</h3>

<p><strong>Agent:</strong> <code>full-stack-developer</code> (via Task tool)</p>
<p><strong>Duration:</strong> ~20-30 min</p>
<p><strong>Deliverable:</strong> Complete working implementation</p>

<p><strong>Prompt Template:</strong></p>
<pre><code>Implement solution for [ISSUE-ID] based on analysis:

Root Cause: [from Phase 1]
Chosen Approach: [selected option]

Requirements:
- Fix: [specific behavior to change]
- Preserve: [existing functionality to keep]
- Test: [scenarios to validate]

Architecture Constraints:
- SessionStateManager for all session state (MANDATORY)
- Follow Streamlit key-only pattern
- Use canonical naming conventions (UNIFIED_INSTRUCTIONS)
- No backwards compatibility needed (single-user app)

Deliverables:
1. Modified files with complete implementation
2. Code comments explaining changes
3. Error handling and logging
4. Debug mode support (DEV_MODE gating)
5. Test scenarios description</code></pre>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ Implementation follows architecture rules</li>
<li>‚úÖ Error handling included</li>
<li>‚úÖ Code is readable and maintainable</li>
<li>‚úÖ Test scenarios documented</li>
</ul>

<p>---</p>

<h3>Phase 3: Code Review (code-reviewer)</h3>

<p><strong>Agent:</strong> <code>code-reviewer</code> (via Task tool)</p>
<p><strong>Duration:</strong> ~10 min</p>
<p><strong>Deliverable:</strong> Scored review with improvement suggestions</p>

<p><strong>Prompt Template:</strong></p>
<pre><code>Review implementation for [ISSUE-ID]:

Files Changed:
- [file 1]: [summary of changes]
- [file 2]: [summary of changes]

Review Criteria:
1. Architecture compliance (CLAUDE.md + UNIFIED_INSTRUCTIONS.md)
   - SessionStateManager usage
   - Streamlit patterns (key-only)
   - Canonical naming
2. Code quality
   - Error handling
   - Type hints
   - Documentation
3. Performance impact
4. Test coverage
5. Security considerations

Deliverables:
1. Overall score (X/10) with rationale
2. CRITICAL issues (blocking)
3. HIGH issues (should fix)
4. MEDIUM issues (nice to have)
5. Positive highlights</code></pre>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ Score ‚â• 7/10 (otherwise iterate)</li>
<li>‚úÖ No CRITICAL issues</li>
<li>‚úÖ Architecture compliance verified</li>
</ul>

<p>---</p>

<h3>Phase 4: Simplification Check (code-simplifier)</h3>

<p><strong>Agent:</strong> <code>code-simplifier</code> (via Task tool)</p>
<p><strong>Duration:</strong> ~10 min</p>
<p><strong>Deliverable:</strong> Complexity score + refactoring suggestions</p>

<p><strong>Prompt Template:</strong></p>
<pre><code>Analyze complexity for [ISSUE-ID] implementation:

Focus Areas:
1. Code duplication (DRY violations)
2. Over-engineering (unnecessary abstractions)
3. Function length and complexity
4. Nested logic depth
5. Configuration vs code

Deliverables:
1. Complexity score (X/10) - lower is better
2. Duplication analysis (lines/functions)
3. Consolidation opportunities
4. Simplification suggestions
5. Before/after metrics</code></pre>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ Complexity ‚â§ 5/10</li>
<li>‚úÖ No duplicate code blocks > 10 lines</li>
<li>‚úÖ Functions < 50 lines (guideline)</li>
</ul>

<p>---</p>

<h3>Phase 5: Fix Critical Issues</h3>

<p><strong>Agent:</strong> Original agent (Claude Code / BMad)</p>
<p><strong>Duration:</strong> ~15 min</p>
<p><strong>Deliverable:</strong> Implementation with fixes applied</p>

<p><strong>Actions:</strong></p>
<ol>
<li>Review CRITICAL + HIGH issues from Phase 3</li>
<li>Apply suggested refactorings from Phase 4</li>
<li>Re-run syntax validation</li>
<li>Update implementation</li>
</ol>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ All CRITICAL issues resolved</li>
<li>‚úÖ Code review score improved to ‚â• 9/10</li>
<li>‚úÖ Complexity reduced to ‚â§ 4/10</li>
<li>‚úÖ Syntax check passes</li>
</ul>

<p>---</p>

<h3>Phase 6: Validation</h3>

<p><strong>Agent:</strong> Original agent</p>
<p><strong>Duration:</strong> ~10 min</p>
<p><strong>Deliverable:</strong> Validated implementation</p>

<p><strong>Actions:</strong></p>
<pre><code># 1. Syntax check
python -m py_compile [modified_files]

# 2. Pre-commit checks
pre-commit run --files [modified_files]

# 3. Unit tests (if applicable)
pytest [relevant_test_files] -v

# 4. Smoke test (manual)
# - Start app: bash scripts/run_app.sh
# - Test scenario: [specific test case]
# - Verify: [expected outcome]</code></pre>

<p><strong>Success Criteria:</strong></p>
<ul>
<li>‚úÖ Syntax check passes</li>
<li>‚úÖ Pre-commit checks pass</li>
<li>‚úÖ No new test failures</li>
<li>‚úÖ Smoke test validates fix</li>
</ul>

<p>---</p>

<h2>üìä Multiagent Workflow Checklist</h2>

<p><strong>Voor elke multiagent session:</strong></p>

<h3>Planning Phase</h3>
<ul>
<li>[ ] Issue clearly defined (symptoms, impact, priority)</li>
<li>[ ] Required MCP tools identified (Perplexity, Context7)</li>
<li>[ ] Relevant files/logs/context gathered</li>
<li>[ ] Success criteria defined</li>
</ul>

<h3>Execution Phase</h3>
<ul>
<li>[ ] Phase 1: Root cause analysis (debug-specialist)</li>
<li>[ ] Phase 2: Implementation (full-stack-developer)</li>
<li>[ ] Phase 3: Code review (code-reviewer) ‚Üí Score ‚â• 7/10</li>
<li>[ ] Phase 4: Simplification check (code-simplifier) ‚Üí Complexity ‚â§ 5/10</li>
<li>[ ] Phase 5: Fix critical issues ‚Üí Score ‚â• 9/10, Complexity ‚â§ 4/10</li>
<li>[ ] Phase 6: Validation (syntax + pre-commit + tests)</li>
</ul>

<h3>Documentation Phase</h3>
<ul>
<li>[ ] Update issue tracker (Linear) met solution summary</li>
<li>[ ] Document lessons learned (indien applicable)</li>
<li>[ ] Update relevant documentation (CLAUDE.md, guidelines)</li>
<li>[ ] Commit met conventional commit message</li>
</ul>

<p>---</p>

<h2>üéØ Agent Selection Matrix</h2>

<p>| Agent Type | Primary Use Case | Key Deliverable | Duration |</p>
<p>|------------|------------------|-----------------|----------|</p>
<p>| <strong>debug-specialist</strong> | Root cause analysis, systematic debugging | Comprehensive analysis + solution options | 10-15 min |</p>
<p>| <strong>full-stack-developer</strong> | Code implementation, feature development | Working code with tests | 20-30 min |</p>
<p>| <strong>code-reviewer</strong> | Quality assessment, architecture compliance | Scored review (X/10) + issues | 10 min |</p>
<p>| <strong>code-simplifier</strong> | Complexity reduction, DRY enforcement | Complexity score + refactoring | 10 min |</p>
<p>| <strong>Explore</strong> | Codebase exploration, pattern search | File/function locations + analysis | 5-10 min |</p>

<p>---</p>

<h2>üìã Parallel vs Sequential Execution</h2>

<h3>Run in Parallel (Single Message)</h3>
<pre><code>I need root cause analysis AND implementation plan for DEF-56.

Use multiagents in parallel:
1. debug-specialist: Analyze root cause
2. full-stack-developer: Create implementation plan</code></pre>

<p><strong>When to use:</strong></p>
<ul>
<li>Independent analyses (root cause + implementation)</li>
<li>Multiple reviews needed (code + simplification)</li>
<li>Time-critical issues</li>
</ul>

<h3>Run Sequentially (Multiple Messages)</h3>
<pre><code># Message 1
Use debug-specialist to analyze DEF-56 root cause.

# Wait for result, then Message 2
Based on analysis, use full-stack-developer to implement fix.

# Wait for result, then Message 3
Use code-reviewer to review implementation.</code></pre>

<p><strong>When to use:</strong></p>
<ul>
<li>Later phases depend on earlier results</li>
<li>Need to validate intermediate steps</li>
<li>Complex decision points</li>
</ul>

<p>---</p>

<h2>üîç MCP Integration Patterns</h2>

<h3>Pattern 1: Deep Research (Perplexity)</h3>
<p><strong>Use for:</strong> Technical documentation, best practices, framework behavior</p>

<pre><code>Use Perplexity MCP to research:
- Streamlit widget state lifecycle
- Race conditions in value + key parameters
- Community-reported issues with similar symptoms</code></pre>

<h3>Pattern 2: Official Documentation (Context7)</h3>
<p><strong>Use for:</strong> Framework-specific patterns, API references</p>

<pre><code>Use Context7 MCP to fetch:
- Streamlit documentation for session_state
- Best practices for widget key management
- Official examples of state synchronization</code></pre>

<h3>Pattern 3: Combined Research</h3>
<p><strong>Use for:</strong> Comprehensive validation</p>

<pre><code>1. Context7 ‚Üí Get official Streamlit patterns
2. Perplexity ‚Üí Verify against community knowledge
3. Synthesize ‚Üí Canonical recommendation</code></pre>

<p>---</p>

<h2>üéì Lessons Learned Integration</h2>

<h3>After Successful Multiagent Session</h3>

<p><strong>Document new patterns:</strong></p>
<ol>
<li>Add to `docs/guidelines/` (if project-specific)</li>
<li>Update `CLAUDE.md` (if architecture-related)</li>
<li>Update `~/.ai-agents/UNIFIED_INSTRUCTIONS.md` (if cross-project)</li>
</ol>

<p><strong>Create enforcement:</strong></p>
<ol>
<li>Pre-commit hooks (if detectable pattern)</li>
<li>Unit tests (if testable behavior)</li>
<li>Architecture decision records (if significant)</li>
</ol>

<p><strong>Share knowledge:</strong></p>
<ol>
<li>Update issue with comprehensive solution</li>
<li>Create reference implementation</li>
<li>Add to troubleshooting guides</li>
</ol>

<p>---</p>

<h2>üìà Success Metrics</h2>

<p><strong>Track effectiveness:</strong></p>
<ul>
<li>‚è±Ô∏è Time to resolution (target: < 2 hours for CRITICAL)</li>
<li>üìä Code review score (target: ‚â• 9/10 after fixes)</li>
<li>üéØ Complexity score (target: ‚â§ 4/10)</li>
<li>üêõ Regression rate (target: < 5%)</li>
<li>‚úÖ First-time success rate (target: > 80%)</li>
</ul>

<p><strong>Quality indicators:</strong></p>
<ul>
<li>All phases completed</li>
<li>No CRITICAL issues in final review</li>
<li>Pre-commit checks pass</li>
<li>Syntax validation passes</li>
<li>Tests pass (or NA with justification)</li>
</ul>

<p>---</p>

<h2>üìö Example: DEF-56 Workflow</h2>

<p><strong>Actual execution (2025-10-29):</strong></p>

<ol>
<li>**Phase 1 (debug-specialist):** Root cause = Streamlit widget race condition</li>
</ol>
<ul>
<li>  - Research: Perplexity (deep dive) + Context7 (official docs)</li>
<li>  - Result: Key-only pattern identified as solution</li>
<li>  - Duration: ~12 min</li>
</ul>

<ol>
<li>**Phase 2 (full-stack-developer):** Complete implementation</li>
</ol>
<ul>
<li>  - Created unified sync function</li>
<li>  - Applied key-only pattern</li>
<li>  - Duration: ~25 min</li>
</ul>

<ol>
<li>**Phase 3 (code-reviewer):** Initial score 7/10</li>
</ol>
<ul>
<li>  - CRITICAL: Direct st.session_state access</li>
<li>  - HIGH: Code duplication</li>
<li>  - Duration: ~8 min</li>
</ul>

<ol>
<li>**Phase 4 (code-simplifier):** Complexity 6.5/10</li>
</ol>
<ul>
<li>  - Identified 2 duplicate functions (34 lines)</li>
<li>  - Suggested consolidation</li>
<li>  - Duration: ~7 min</li>
</ul>

<ol>
<li>**Phase 5 (fixes):** Applied all fixes</li>
</ol>
<ul>
<li>  - SessionStateManager compliance</li>
<li>  - Consolidated sync functions</li>
<li>  - Final scores: 9/10 quality, 4/10 complexity</li>
<li>  - Duration: ~15 min</li>
</ul>

<ol>
<li>**Phase 6 (validation):** All checks passed</li>
</ol>
<ul>
<li>  - Syntax: ‚úÖ</li>
<li>  - Pre-commit: ‚úÖ (will pass with new hook)</li>
<li>  - Manual test: ‚è≥ (pending user testing)</li>
</ul>

<p><strong>Total Time:</strong> ~67 minutes (67% faster than manual debugging)</p>
<p><strong>Quality:</strong> Production-ready after single iteration</p>

<p>---</p>

<h2>üöÄ Quick Start Template</h2>

<pre><code># Copy this template for new multiagent sessions

ISSUE_ID="DEF-XXX"
TITLE="[Brief description]"

# Phase 1: Root cause
echo "Use debug-specialist agent to analyze $ISSUE_ID"
# ‚Üí Deliverable: root_cause_analysis.md

# Phase 2: Implementation
echo "Use full-stack-developer agent to implement fix for $ISSUE_ID based on analysis"
# ‚Üí Deliverable: working code

# Phase 3 &amp; 4: Parallel review
echo "Use code-reviewer AND code-simplifier agents in parallel to review implementation"
# ‚Üí Deliverable: review scores + improvement suggestions

# Phase 5: Fix issues
echo "Apply CRITICAL fixes from review and consolidate duplicate code"
# ‚Üí Deliverable: improved implementation

# Phase 6: Validate
python -m py_compile [files]
pre-commit run --files [files]
pytest [tests] -v
# ‚Üí Deliverable: validated fix

# Final: Document
echo "Update Linear issue $ISSUE_ID with solution summary"
# ‚Üí Deliverable: documented solution</code></pre>

<p>---</p>

<p><strong>Status:</strong> Deze workflow is gevalideerd door DEF-56 implementatie en wordt aanbevolen voor alle CRITICAL/HIGH priority issues in DefinitieAgent.</p>

<p><strong>References:</strong></p>
<ul>
<li>DEF-56: https://linear.app/definitie-app/issue/DEF-56</li>
<li>CLAUDE.md: `~/Projecten/Definitie-app/CLAUDE.md`</li>
<li>UNIFIED_INSTRUCTIONS: `~/.ai-agents/UNIFIED_INSTRUCTIONS.md`</li>
</ul>

  </div>
</body>
</html>