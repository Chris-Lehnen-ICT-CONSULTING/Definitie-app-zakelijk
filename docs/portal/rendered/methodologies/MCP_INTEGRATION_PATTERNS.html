<!doctype html>
<html lang="nl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>MCP Integration Best Practices</title>
  <link rel="stylesheet" href="../portal.css" />
  <style>
    .doc { max-width: 900px; margin: 16px auto 48px auto; padding: 0 16px; }
    .doc h1,.doc h2,.doc h3,.doc h4{ color:#223 }
    .doc p{ line-height:1.6; color:#222 }
    .doc a{ color:#1d4ed8; text-decoration: underline; }
    .doc pre{ background:#0b1020; color:#e6edf3; padding:12px; overflow:auto; border-radius:8px }
    .doc code{ background:#f0f2f5; padding:2px 6px; border-radius:4px }
    .back{ display:inline-block; margin:12px 0; padding:6px 10px; border:1px solid #ccd; border-radius:6px; text-decoration:none; color:#223; background:#f8f9fb }
  </style>
</head>
<body>
  <div class="doc">
    <a class="back" href="../../index.html">â† Terug naar Portal</a>
    <h1>MCP Integration Best Practices</h1>

<p><strong>Status:</strong> Active | <strong>Last Updated:</strong> 2025-10-29 | <strong>Source:</strong> DEF-56 Research Phase</p>

<p>Model Context Protocol (MCP) servers bieden gespecialiseerde tools voor deep research, documentation retrieval en external integrations. Deze patterns zijn gevalideerd tijdens DEF-56 root cause analysis.</p>

<p>---</p>

<h2>ğŸ¯ Available MCP Servers in DefinitieAgent</h2>

<p>| MCP Server | Primary Use Case | Best For | Response Time |</p>
<p>|------------|------------------|----------|---------------|</p>
<p>| <strong>Perplexity</strong> | Deep technical research, community knowledge | Root cause analysis, framework behavior | ~15-30s |</p>
<p>| <strong>Context7</strong> | Official documentation retrieval | API references, best practices | ~5-10s |</p>
<p>| <strong>Linear</strong> | Issue tracking, project management | Task updates, issue search | ~2-5s |</p>
<p>| <strong>GitHub</strong> | Code search, repository analysis | Codebase exploration, PR/issue management | ~3-8s |</p>

<p>---</p>

<h2>ğŸ“‹ Pattern 1: Deep Research (Perplexity)</h2>

<h3>When to Use</h3>
<ul>
<li>**Root cause analysis** voor onbekende bugs</li>
<li>**Framework behavior** verification (Streamlit, FastAPI, etc.)</li>
<li>**Community knowledge** (Stack Overflow, GitHub issues)</li>
<li>**Performance optimization** patterns</li>
<li>**Security best practices**</li>
</ul>

<h3>How to Use</h3>
<pre><code>Use Perplexity MCP to research:

Query: "Streamlit widget state race condition when using value and key parameters together"

Context:
- Framework: Streamlit 1.x
- Symptom: Text areas not updating after st.rerun()
- Current implementation: st.text_area(value=data, key="my_key")

Focus:
1. Widget lifecycle and state management
2. Known issues with value + key combination
3. Recommended patterns from community
4. Root cause explanation</code></pre>

<h3>Expected Output</h3>
<ul>
<li>**Technical explanation** (what/why/how)</li>
<li>**Citations** (links to sources)</li>
<li>**Code examples** (good/bad patterns)</li>
<li>**Recommended solutions** (2-3 options with trade-offs)</li>
</ul>

<h3>Success Criteria</h3>
<ul>
<li>âœ… Root cause identified with technical validation</li>
<li>âœ… Multiple credible sources cited</li>
<li>âœ… Actionable recommendations provided</li>
<li>âœ… Response time < 30 seconds</li>
</ul>

<p>---</p>

<h2>ğŸ“‹ Pattern 2: Official Documentation (Context7)</h2>

<h3>When to Use</h3>
<ul>
<li>**API reference** lookup</li>
<li>**Official best practices** verification</li>
<li>**Framework-specific patterns** (idiomatic usage)</li>
<li>**Migration guides** (version differences)</li>
<li>**Configuration options** (complete list)</li>
</ul>

<h3>How to Use</h3>
<pre><code>Use Context7 MCP to fetch Streamlit documentation:

Library: streamlit (resolve via resolve-library-id)
Topic: "session state and widget keys"
Tokens: 5000

Focus:
- Widget key parameter behavior
- Session state synchronization
- Recommended patterns for state management</code></pre>

<h3>Expected Output</h3>
<ul>
<li>**Official documentation** (exact text from docs)</li>
<li>**Code examples** (from official docs)</li>
<li>**Version-specific info** (if applicable)</li>
<li>**API signatures** (parameters, return types)</li>
</ul>

<h3>Success Criteria</h3>
<ul>
<li>âœ… Official source confirmed (not community interpretation)</li>
<li>âœ… Current version documentation (not outdated)</li>
<li>âœ… Complete context provided</li>
<li>âœ… Response time < 10 seconds</li>
</ul>

<p>---</p>

<h2>ğŸ“‹ Pattern 3: Combined Research (Perplexity + Context7)</h2>

<h3>When to Use</h3>
<ul>
<li>**Comprehensive validation** needed</li>
<li>**Conflicting information** in community vs official docs</li>
<li>**Complex architectural decisions**</li>
<li>**Performance-critical implementations**</li>
</ul>

<h3>How to Use</h3>
<pre><code># Step 1: Official docs first (Context7)
Use Context7 to get Streamlit official documentation on session_state

# Step 2: Deep dive (Perplexity)
Use Perplexity to research:
- Community experiences with Streamlit widget state
- Known race conditions
- Performance implications

# Step 3: Synthesize
Compare official recommendations vs community knowledge
Identify canonical best practice</code></pre>

<h3>Expected Output</h3>
<ul>
<li>**Canonical recommendation** (official + validated by community)</li>
<li>**Trade-offs** (official approach vs alternatives)</li>
<li>**Confidence level** (high if aligned, medium if divergent)</li>
</ul>

<h3>Example: DEF-56 Research</h3>

<p><strong>Context7 Result:</strong></p>
<blockquote>"Streamlit recommends using only the `key` parameter for widgets that sync with session state. The `value` parameter should be used only for widgets without `key`."</blockquote>

<p><strong>Perplexity Result:</strong></p>
<blockquote>"Multiple users report race conditions when using both `value` and `key` parameters. Widget internal state takes precedence over `value` parameter after first render, causing stale data display."</blockquote>

<p><strong>Synthesis:</strong></p>
<p>âœ… <strong>Canonical Pattern:</strong> Key-only approach (officially recommended + community validated)</p>
<p>âŒ <strong>Anti-Pattern:</strong> value + key combination (causes race condition)</p>

<p>---</p>

<h2>ğŸ“‹ Pattern 4: Issue Tracking Integration (Linear)</h2>

<h3>When to Use</h3>
<ul>
<li>**Search for related issues** (duplicates, dependencies)</li>
<li>**Update issue status** after implementation</li>
<li>**Create follow-up tasks**</li>
<li>**Link PRs to issues**</li>
</ul>

<h3>How to Use</h3>
<pre><code># Search issues
Use Linear search_issues: query="voorbeelden generation"

# Update issue with solution
Use Linear create_comment:
  issueId: [from search result]
  body: "## âœ… OPLOSSING GEÃMPLEMENTEERD\n\n[comprehensive summary]"</code></pre>

<h3>Best Practices</h3>
<ul>
<li>âœ… Update issue IMMEDIATELY after fix</li>
<li>âœ… Include code references (file:line)</li>
<li>âœ… Document acceptance criteria status</li>
<li>âœ… Link related issues/PRs</li>
<li>âŒ Don't create duplicate issues (search first!)</li>
</ul>

<p>---</p>

<h2>ğŸ“‹ Pattern 5: Codebase Exploration (GitHub + Grep)</h2>

<h3>When to Use</h3>
<ul>
<li>**Find similar implementations** in codebase</li>
<li>**Identify affected components**</li>
<li>**Search for anti-patterns**</li>
<li>**Locate documentation**</li>
</ul>

<h3>How to Use</h3>
<pre><code># Option 1: GitHub code search (cross-repo)
Use GitHub search_code:
  query: "st.text_area value key repo:definitie-app"

# Option 2: Local grep (faster, more control)
Use Grep:
  pattern: "st\.text_area.*value.*key"
  path: "src/ui"
  output_mode: "files_with_matches"</code></pre>

<h3>When to Use Each</h3>

<p><strong>GitHub search_code:</strong></p>
<ul>
<li>Cross-repository search</li>
<li>Looking for examples in other projects</li>
<li>Searching public codebases for patterns</li>
</ul>

<p><strong>Local Grep:</strong></p>
<ul>
<li>âœ… Faster for single repository</li>
<li>âœ… More control over regex</li>
<li>âœ… Better for iterative refinement</li>
<li>âœ… Works offline</li>
</ul>

<p>---</p>

<h2>ğŸ¯ MCP Selection Decision Tree</h2>

<pre><code>START: Need external information

â”œâ”€ Official API/docs needed?
â”‚  â”œâ”€ YES â†’ Use Context7
â”‚  â”‚  â””â”€ Not found? â†’ Add Perplexity for alternatives
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Root cause unknown?
â”‚  â”œâ”€ YES â†’ Use Perplexity (deep research)
â”‚  â”‚  â””â”€ Need validation? â†’ Add Context7 for official stance
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Need to update issue/project?
â”‚  â”œâ”€ YES â†’ Use Linear
â”‚  â””â”€ NO â†’ Continue
â”‚
â”œâ”€ Looking for code examples?
â”‚  â”œâ”€ In this repo â†’ Use Grep/Read
â”‚  â””â”€ Cross-repo â†’ Use GitHub search_code
â”‚
â””â”€ General question â†’ Use Perplexity</code></pre>

<p>---</p>

<h2>ğŸš€ Performance Optimization</h2>

<h3>Parallel MCP Calls</h3>
<p><strong>When safe:</strong></p>
<pre><code>Use Perplexity AND Context7 in parallel:
1. Perplexity: Research Streamlit widget race conditions
2. Context7: Fetch official Streamlit session_state docs</code></pre>

<p><strong>When NOT safe:</strong></p>
<ul>
<li>Context7 requires resolve-library-id first (sequential!)</li>
<li>Need to process result before next query</li>
</ul>

<h3>Caching Strategy</h3>
<p><strong>MCP responses zijn niet gecached</strong> - gebruik local caching:</p>

<pre><code># Cache expensive MCP calls in session
if "mcp_streamlit_docs" not in st.session_state:
    st.session_state.mcp_streamlit_docs = context7_fetch()

docs = st.session_state.mcp_streamlit_docs</code></pre>

<h3>Token Management</h3>
<p><strong>Context7 token limits:</strong></p>
<ul>
<li>Default: 5000 tokens</li>
<li>Range: 1000-10000 tokens</li>
<li>Strategy: Start small (2000), increase if insufficient</li>
</ul>

<p><strong>Perplexity best practices:</strong></p>
<ul>
<li>Be specific in query (reduces response time)</li>
<li>Use structured prompts (better parsing)</li>
<li>Limit scope (focus on specific aspect)</li>
</ul>

<p>---</p>

<h2>ğŸ“Š Quality Assessment Checklist</h2>

<p><strong>Voor elke MCP call:</strong></p>

<h3>Pre-Call Validation</h3>
<ul>
<li>[ ] Right tool for job? (see decision tree)</li>
<li>[ ] Query is specific enough?</li>
<li>[ ] Scope is appropriately narrow?</li>
<li>[ ] Expected output clearly defined?</li>
</ul>

<h3>Post-Call Validation</h3>
<ul>
<li>[ ] Response is relevant to query?</li>
<li>[ ] Sources are credible?</li>
<li>[ ] Information is current (not outdated)?</li>
<li>[ ] Actionable recommendations provided?</li>
</ul>

<h3>Integration</h3>
<ul>
<li>[ ] MCP result validated against codebase?</li>
<li>[ ] Conflicts with existing patterns addressed?</li>
<li>[ ] Documentation updated if new pattern?</li>
<li>[ ] Team aware of changes (if significant)?</li>
</ul>

<p>---</p>

<h2>ğŸ“ Lessons Learned from DEF-56</h2>

<h3>What Worked Well âœ…</h3>

<ol>
<li>**Combined Research (Context7 + Perplexity)**</li>
</ol>
<ul>
<li>  - Context7 confirmed official key-only pattern</li>
<li>  - Perplexity explained WHY race condition occurs</li>
<li>  - Synthesis â†’ High confidence canonical solution</li>
</ul>

<ol>
<li>**Sequential Research Flow**</li>
</ol>
<ul>
<li>  - Step 1: Official docs (Context7) â†’ Baseline understanding</li>
<li>  - Step 2: Deep dive (Perplexity) â†’ Root cause explanation</li>
<li>  - Step 3: Validation â†’ Community experiences align with docs</li>
</ul>

<ol>
<li>**Issue Update (Linear)**</li>
</ol>
<ul>
<li>  - Comprehensive solution summary in Linear comment</li>
<li>  - Immediate update after implementation</li>
<li>  - Clear acceptance criteria status</li>
</ul>

<h3>What Could Be Improved ğŸ”„</h3>

<ol>
<li>**Token Optimization**</li>
</ol>
<ul>
<li>  - Initial Context7 call used 5000 tokens (default)</li>
<li>  - Could have started with 2000 tokens (sufficient for this query)</li>
<li>  - Savings: ~60% tokens for similar quality</li>
</ul>

<ol>
<li>**Caching Strategy**</li>
</ol>
<ul>
<li>  - MCP calls repeated during analysis iterations</li>
<li>  - Should have cached Context7 docs in session</li>
<li>  - Time savings: ~20 seconds</li>
</ul>

<ol>
<li>**Query Specificity**</li>
</ol>
<ul>
<li>  - Initial Perplexity query too broad</li>
<li>  - Refined to "Streamlit value+key race condition"</li>
<li>  - Response quality improved significantly</li>
</ul>

<p>---</p>

<h2>ğŸ“š Common Use Cases & Templates</h2>

<h3>Use Case 1: Debug Unknown Framework Behavior</h3>
<pre><code># Template
Use Perplexity to research:

Framework: [name + version]
Behavior: [unexpected outcome]
Expected: [what should happen]
Context: [relevant code snippet]

Focus:
1. Known issues or bugs
2. Framework lifecycle explanation
3. Workarounds or solutions
4. Version-specific behavior</code></pre>

<h3>Use Case 2: Validate Architecture Decision</h3>
<pre><code># Template
Use Context7 for official [framework] docs on [topic]
Use Perplexity to research community experiences with [pattern]

Synthesis:
- Official recommendation: [from Context7]
- Community consensus: [from Perplexity]
- Decision: [chosen approach with rationale]</code></pre>

<h3>Use Case 3: Find Similar Implementations</h3>
<pre><code># Template
Use Grep to find:
  pattern: [function/class name]
  path: src/
  output_mode: files_with_matches

Then use Read to analyze top 3 matches for patterns</code></pre>

<p>---</p>

<h2>ğŸ”’ Security & Privacy</h2>

<p><strong>NEVER send to MCP:</strong></p>
<ul>
<li>âŒ API keys or credentials</li>
<li>âŒ User data or PII</li>
<li>âŒ Proprietary business logic</li>
<li>âŒ Sensitive configuration</li>
</ul>

<p><strong>Safe to send:</strong></p>
<ul>
<li>âœ… Framework/library names</li>
<li>âœ… Generic code patterns</li>
<li>âœ… Error messages (sanitized)</li>
<li>âœ… Public documentation queries</li>
</ul>

<p>---</p>

<h2>ğŸ“ˆ Success Metrics</h2>

<p><strong>Track MCP effectiveness:</strong></p>

<p>| Metric | Target | Measurement |</p>
<p>|--------|--------|-------------|</p>
<p>| <strong>Response Relevance</strong> | > 90% | Useful answers / total queries |</p>
<p>| <strong>Time to Solution</strong> | < 30 min | From query to validated answer |</p>
<p>| <strong>Citation Quality</strong> | > 80% | Official sources / total sources |</p>
<p>| <strong>Action Success Rate</strong> | > 85% | Solutions that work / implemented |</p>

<p><strong>DEF-56 Results:</strong></p>
<ul>
<li>Response Relevance: 100% (all MCP calls provided useful info)</li>
<li>Time to Solution: ~12 min (Context7 + Perplexity)</li>
<li>Citation Quality: 100% (official Streamlit docs + reputable sources)</li>
<li>Action Success Rate: 100% (fix validated by syntax check + review)</li>
</ul>

<p>---</p>

<h2>ğŸš€ Quick Reference Card</h2>

<pre><code># Deep Research
perplexity_research: "[detailed technical query]"

# Official Docs
context7_resolve: "[library name]" â†’ library_id
context7_get_docs: library_id, topic="[specific area]"

# Issue Management
linear_search: query="[keywords]"
linear_comment: issueId, body="[markdown]"

# Code Search (local)
grep: pattern="[regex]", path="src/"

# Code Search (cross-repo)
github_search_code: query="[code] repo:[name]"</code></pre>

<p>---</p>

<p><strong>Status:</strong> Deze patterns zijn gevalideerd door DEF-56 research phase en worden aanbevolen voor alle complex debugging/research tasks in DefinitieAgent.</p>

<p><strong>References:</strong></p>
<ul>
<li>DEF-56: https://linear.app/definitie-app/issue/DEF-56</li>
<li>Multiagent Workflow: `docs/methodologies/MULTIAGENT_WORKFLOW.md`</li>
<li>CLAUDE.md: `~/Projecten/Definitie-app/CLAUDE.md`</li>
</ul>

  </div>
</body>
</html>