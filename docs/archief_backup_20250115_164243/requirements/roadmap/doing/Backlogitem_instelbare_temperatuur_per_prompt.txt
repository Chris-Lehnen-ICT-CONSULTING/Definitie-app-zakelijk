Backlogitem: Instelbare temperatuur per prompt (slotadvies + UI-parameter)

Status: To do

Beschrijving / doel:
Het systeem hanteert nu een vaste temperatuurwaarde bij GPT-aanroepen voor strikte toetsing, logging en validatie. Dit waarborgt voorspelbare, reproduceerbare resultaten. Het slotadvies benadrukt echter dat een vaste temperatuur ook ten koste kan gaan van variatie en nuance in de gegenereerde output.
Doel van dit backlogitem is:
- Het mogelijk maken om de temperatuur per aanroep (d.w.z. per definitieopdracht) vanuit de UI dynamisch in te stellen.
- Gebruikers kunnen hiermee de mate van creativiteit/variatie eenvoudig aanpassen, afhankelijk van de behoefte aan striktheid versus nuance.
- De gekozen temperatuurinstelling wordt automatisch gelogd.
- Slotadvies: deze flexibiliteit is verstandig, mits goed vastgelegd en inzichtelijk in de logs.

Acceptatiecriteria:
- [ ] In de UI (webinterface) is een slider, dropdown of invulveld zichtbaar waarmee de gebruiker de temperatuur voor elke opdracht kan instellen (range: 0.0â€“2.0, standaardwaarde: huidig projectdefault).
- [ ] Elke GPT-aanroep gebruikt de geselecteerde temperatuurwaarde, die wordt meegestuurd naar de API.
- [ ] De gekozen temperatuur wordt zichtbaar gelogd bij elke opdracht/toetsing.
- [ ] In de logging en in eventuele exports (.txt, .jsonl, .xlsx, .pdf) wordt de gebruikte temperatuur getoond bij het resultaat.
- [ ] De temperatuurkeuze werkt zowel voor het genereren van nieuwe definities als bij het opnieuw toetsen van aangepaste definities.
- [ ] Gebruiker kan het logbestand direct als .txt downloaden vanuit de chat/UI.
- [ ] Alle wijzigingen zijn voorzien van groene uitlegregels in de code.
- [ ] Functionele test: wijziging van temperatuur heeft direct zichtbaar effect op outputvariatie.

Eventuele links of referenties:
- Slotadvies (zie chatbericht)
- Uitgebreide werkafspraak voor backlogitems en kwaliteitsstructuur (zie projectcontext)
- https://platform.openai.com/docs/api-reference/chat/create#chat-create-temperature
